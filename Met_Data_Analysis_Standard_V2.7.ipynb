{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5b12b7",
   "metadata": {},
   "source": [
    "# Metabolomics Data Analysis - FT-ICR-MS-Lisboa\n",
    "\n",
    "This notebook provides a template for standard metabolomics data analysis whether or not you already annoted your data with names and/or chemical formulas with other software.\n",
    "\n",
    "This allows you to annotate, treat, see common and exclusive metabolites, perform multivariate unsupervised and supervised statistical analysis, univariate statistical analysis, produce Van Krevelen diagrams, Kendrick Mass Defect plots and chemical composition series. It also has compound finders that allow you to search for specific compounds using their names, chemical formulas, _m/z_'s or neutral masses.\n",
    "\n",
    "A wide variety of data pre-treatments is provided with easily customizable functions and instructions to do that are provided.\n",
    "\n",
    "**Warning**: Reading files is very dependent on the format of the file, you'll have to see and adapt that part and not just press run all on the notebook.\n",
    "\n",
    "**Please inform us if you encounter any bugs and errors so that we can correct in future versions.**\n",
    "\n",
    "### References\n",
    "\n",
    "A lot of materials (Python functions) from the following paper were used for this pipeline:\n",
    "\n",
    "- Traquete, F.; Luz, J.; Cordeiro, C.; Sousa Silva, M.; Ferreira, A.E.N. Binary Simplification as an Effective Tool in Metabolomics Data Analysis. _Metabolites_ 2021, 11, doi:10.3390/metabo11110788.\n",
    "\n",
    "Apart from this, 3 specific Python libraries that are used should also be mentioned:\n",
    "\n",
    "- Metabolinks (our in-house Python library) - https://zenodo.org/record/5336951#.Y-TbpnbP1D8.\n",
    "- UpSetPlot (to make the UpSetPlots only) - https://pypi.org/project/UpSetPlot/0.8.0/.\n",
    "- Pyvenn (to make the Venn Diagrams only) - https://github.com/tctianchi/pyvenn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8af115",
   "metadata": {},
   "source": [
    "# Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "\n",
    "- **[Step 0: Installing Metabolinks and other packages](#step-0)**\n",
    "- **[Step 1: Upload your data](#step-1)**\n",
    "  - **[Step 1.1: Define your groups and see data characterization](#step-1_1)**\n",
    "  - **[Step 1.2: Annotate with Database(s)](#step-1_2)**\n",
    "  - **[Step 1.3: Formula Assignment](#step-1_3)**\n",
    "  - **[Step 1.4: De-duplicating annotations](#step-1_4)**\n",
    "- **[Step 2: Basic processing and pre-treatment](#step-2)**\n",
    "- **[Step 3: Find Common and Exclusive metabolites between the classes](#step-3)**\n",
    "- **[Step 4: Unsupervised Statistical Analysis (PCA and HCA)](#step-4)**\n",
    "- **[Step 5: Supervised Statistical Analysis (Random Forest and PLS-DA)](#step-5)**\n",
    "  - **[Step 5.1: Random Forest](#step-5_1)**\n",
    "  - **[Step 5.2: PLS-DA (Partial Least Squares - Discriminant Analysis)](#step-5_2)**\n",
    "  - **[Step 5.3: XGBoost (eXtreme Gradient Boosting)](#step-5_3)**\n",
    "- **[Step 6: Univariate Analysis and Fold-Change Analysis](#step-6)**\n",
    "  - **[Step 6.1: 2-class Univariate Statistical Analysis](#step-6_1)**\n",
    "  - **[Step 6.2: Multi-class Univariate Statistical Analysis](#step-6_2)**\n",
    "- **[Step 7: Make Van Krevelen Diagrams, Kendrick Mass Defect Plots and Chemical Composition series for your samples](#step-7)**\n",
    "- **[Step 8: Pathways Assignment of HMDB Annotated Metabolites](#step-8)**\n",
    "  - **[Step 8.1: Pathway Over-Representation Analysis](#step-8_1)**\n",
    "- **[Step 9: KEGG Colour Mapping](#step-9)**\n",
    "- **[Step 10: BinSim Specific Analysis](#step-10)**\n",
    "- **[Step 11: Find Specific Compounds](#step-11)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a369c",
   "metadata": {},
   "source": [
    "### Some common needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d575684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import math\n",
    "from fractions import Fraction\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import itertools\n",
    "\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hier\n",
    "import scipy.stats as stats\n",
    "\n",
    "import sklearn.ensemble as skensemble\n",
    "from sklearn.metrics import (roc_auc_score, roc_curve, auc,\n",
    "                             f1_score, precision_score, recall_score)\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import ticker\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import upsetplot\n",
    "from upsetplot import from_contents\n",
    "from upsetplot import UpSet\n",
    "\n",
    "# Our Python package\n",
    "import metabolinks as mtl\n",
    "import metabolinks.transformations as transf\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# venn.py file  (has to be in the same folder)\n",
    "import venn as venn\n",
    "# metanalysis_standard.py file  (has to be in the same folder)\n",
    "import metanalysis_standard as metsta\n",
    "# some functions from interface_aux_functions  (has to be in the same folder)\n",
    "from interface_aux_functions import create_element_counts\n",
    "# multianalysis.py file (has to be in the same folder)\n",
    "from multianalysis import p_adjust_bh, fit_PLSDA_model, _calculate_vips, _generate_y_PLSDA\n",
    "# form_assign_func.py file (has to be in the same folder)\n",
    "import form_assign_func as form_afunc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ad46ed",
   "metadata": {},
   "source": [
    "# Step 0: Installing Metabolinks and other packages<a class=\"anchor\" id=\"step-0\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "**Metabolinks and UpSetPlot**\n",
    "\n",
    "- Open 'Command Line' or 'Linha de comandos' on your pc.\n",
    "- Run the line 'pip install metabolinks'.\n",
    "- Run the line 'pip install UpSetPlot'.\n",
    "- Run the line 'conda install -c conda-forge py-xgboost'.\n",
    "- Restart jupyter.\n",
    "\n",
    "**pyvenn**\n",
    "\n",
    "- Go to https://github.com/tctianchi/pyvenn/blob/master/venn.py.\n",
    "- Over 'Raw' (see where 'Watch' is on the upper left and move look down), click 'Save link as...'.\n",
    "- Save it on the same folder you have the rest of the files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed7c53",
   "metadata": {},
   "source": [
    "# Step 1: Upload your data <a class=\"anchor\" id=\"step-1\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "Your initial input data may consist of either unaligned lists of m/z-intensity pairings (`aligned_samples = False`) or a table of previously aligned samples (`aligned_samples = True`).\n",
    "\n",
    "\n",
    "**Always check the first lines of each cell to see if there are parameters that you might want to change.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose whether you have samples that need to be aligned or a data matrix with the samples already aligned\n",
    "# If your samples are aligned put True, if your samples are not aligned and you wish to align them put False.\n",
    "aligned_samples = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec105ce",
   "metadata": {},
   "source": [
    "### Data Alignment Section\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "If your data consists of unaligned samples, you should start with this section. Otherwise, you can skip it.\n",
    "\n",
    "The mass lists from all your samples should be in a single excel file. This file should contain exactly **one sample per sheet**. The name of the sheet should correspond to the name of the sample. The sheet itself should have two columns: the first column should be the **m/z** column while the second column should be the corresponding **Intensity** values detected. See the 'spectra alignement solvent optimization Kilgour.xlsx' file as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Section\n",
    "\n",
    "# File with the non-aligned samples\n",
    "samples_file = 'spectra alignement solvent optimization Kilgour.xlsx'\n",
    "\n",
    "if not aligned_samples:\n",
    "\n",
    "    # Some necessary import specifically for the alignment\n",
    "    from metabolinks import add_labels, read_data_from_xcel, align\n",
    "\n",
    "    # Reading the file\n",
    "    data = read_data_from_xcel(samples_file, header=[0])\n",
    "\n",
    "    # Editing the file format a bit\n",
    "    full_data = []\n",
    "    for i in range(len(data)):\n",
    "        single_sample = list(data.values())[i][0]\n",
    "        single_sample.columns = [list(data.keys())[i],]\n",
    "        full_data.append(single_sample)\n",
    "    # Erase data to release memory\n",
    "    data = []\n",
    "\n",
    "# Example of the samples data - see if everything is as it should\n",
    "#full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389cec3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameter Section\n",
    "ppmtol = 1.0 # PPM Deviation Tolerance to make the aligned buckets\n",
    "min_samples = 2 # Minimum number of samples an aligned metabolic feature must appear to not be discarded\n",
    "\n",
    "\n",
    "desc = []\n",
    "file = []\n",
    "if not aligned_samples:\n",
    "    \n",
    "    results = {}\n",
    "    print(f'------ Aligning tables ...')\n",
    "    aligned, desc = align(full_data,\n",
    "                          min_samples=min_samples, \n",
    "                          ppmtol=ppmtol,\n",
    "                          return_alignment_desc=True,\n",
    "                          verbose=True)\n",
    "\n",
    "\n",
    "    print('\\n--- Result: --------------------')\n",
    "    print(aligned)\n",
    "    # keep results in a dictionary\n",
    "    file = aligned\n",
    "    target_in_file = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54473a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0b3700",
   "metadata": {},
   "source": [
    "### Data Matrix (Aligned Samples) Reading Section\n",
    "\n",
    "If your data consists of previously aligned samples, you should start with this section. Otherwise, return to the previous one.\n",
    "\n",
    "This section is made for csv and excel files. If you have a target in the first row of your data below the name of the columns, set `target_in_file` to True.\n",
    "\n",
    "The following code is made to read matrices with the samples on the columns and metabolic features on the rows. The first column should be the mass or _m/z_ identifiers of each metabolic feature.\n",
    "\n",
    "Select if the masses in the first column of your data (idx_masses) are Neutral masses ('Neutral'), _m/z_ values obtained from positive ionization mode ('Positive') or negative ionization mode ('Negative') or if the values cannot be interpreted as masses ('None' - this will not allow you to perform data annotation and formula assignment downstream).\n",
    "\n",
    "What does this do?\n",
    "- Produces a pandas DataFrame with your spectral data.\n",
    "- Renames the columns to obtain \"clean\" sample names (if necessary).\n",
    "- Replaces 0 values with numpy null objects (nan). This is necessary to know how many metabolites each sample has and to allow further data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For .csv or .xlsx following similar formatting to '5yeasts_notnorm.csv' example\n",
    "\n",
    "# Example\n",
    "filename = '5yeasts_notnorm.csv' # Name of your file\n",
    "# Indicate if the file read includes the target (sample classes) in its first row\n",
    "target_in_file = False\n",
    "\n",
    "# Samples names frequently have 00000. Use this code to make them 'cleaner'.\n",
    "def renamer(colname):\n",
    "    return ''.join(colname.split('00000'))\n",
    "\n",
    "\n",
    "# Reading the file\n",
    "if aligned_samples:\n",
    "    # If it is a .csv file\n",
    "    if filename.endswith('csv'):\n",
    "        if target_in_file: # If you have the target in the file\n",
    "            file = pd.read_csv(filename, header=[0,1])\n",
    "            colnames = [renamer(i) for i in file.columns.get_level_values(0)]\n",
    "            target_file = dict(zip(colnames, file.columns.get_level_values(1)))\n",
    "            file.columns = colnames\n",
    "\n",
    "        else: # If you do not have the target in the file\n",
    "            file = pd.read_csv(filename)\n",
    "            file.columns = [renamer(i) for i in file.columns]\n",
    "\n",
    "    # If it is a .xlsx file\n",
    "    elif filename.endswith('xlsx'):\n",
    "        if target_in_file: # If you have the target in the file\n",
    "            file = pd.read_excel(filename, header=[0,1])\n",
    "            colnames = [renamer(i) for i in file.columns.get_level_values(0)]\n",
    "            target_file = dict(zip(colnames, file.columns.get_level_values(1)))\n",
    "            file.columns = colnames\n",
    "\n",
    "        else: # If you do not have the target in the file\n",
    "            file = pd.read_excel(filename)\n",
    "            file.columns = [renamer(i) for i in file.columns]    \n",
    "    else:\n",
    "        raise ValueError('Provided file is not an Excel or a csv file.')\n",
    "\n",
    "    file = file.set_index(file.columns[0])\n",
    "\n",
    "else:\n",
    "    # Just to make sure it is False when performing Data Alignment\n",
    "    target_in_file = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da5f264",
   "metadata": {},
   "source": [
    "### Identifying and Creating (if possible) a column with mass values (for Data Annotation downstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_masses = 'Neutral' # 'Neutral' (neutral masses), 'Positive' (Obtained from ESI+), 'Negative' (Obtained from ESI-)\n",
    "# or 'None' (mass column cannot be inferred)\n",
    "\n",
    "\n",
    " # Important for database match - calculating Neutral Mass / Probable m/z column if possible\n",
    "if idx_masses != 'None':\n",
    "    # If the masses in the index are Neutral\n",
    "    if idx_masses == 'Neutral':\n",
    "        file.insert(0, 'Neutral Mass', file.index.astype('str').str.replace('Da', '').astype('float'))\n",
    "    # If the masses are m/z values obtained in Positive Ionization Mode\n",
    "    if idx_masses == 'Positive':\n",
    "        file.insert(0, 'Probable m/z', file.index.astype('str').str.replace('Da', '').astype('float'))\n",
    "    # If the masses are m/z values obtained in Negative Ionization Mode\n",
    "    elif idx_masses == 'Negative':\n",
    "        file.insert(0, 'Probable m/z', file.index.astype('str').str.replace('Da', '').astype('float'))\n",
    "\n",
    "file.index.name = 'Bucket label'\n",
    "\n",
    "# Select the column with the masses to compare\n",
    "if idx_masses == 'Neutral':\n",
    "    mass_val_col = 'Neutral Mass'\n",
    "else:\n",
    "    mass_val_col = 'Probable m/z'\n",
    "\n",
    "# Replaces zeros with numpy nans. Essential for data processing\n",
    "file = file.replace({0.0:np.nan})\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86adf86",
   "metadata": {},
   "source": [
    "### Identifying Metadata and Sample columns\n",
    "\n",
    "**Modify based on your data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1661827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify metadata columns\n",
    "prev_annotations_cols = ['Name', ] # Select columns which contain compound annotations\n",
    "prev_formula_cols = ['Formula', ] # Select columns which contain formula assignments\n",
    "\n",
    "other_metadata_columns = ['m/z', ] # Select other metadata columns in the dataset which will not be used for any specific\n",
    "# analysis but are not sample columns\n",
    "\n",
    "mass_val_col = mass_val_col # If instead of the mass column created, you have another column with masses you prefer to use\n",
    "# change this mass_val_col to the name of that columns\n",
    "\n",
    "if aligned_samples == False:\n",
    "    prev_annotations_cols = []\n",
    "    prev_formula_cols = []\n",
    "    other_metadata_columns = []\n",
    "    \n",
    "# Identify QC samples\n",
    "qc_sample_cols = []\n",
    "\n",
    "##########\n",
    "\n",
    "metadata_cols = prev_annotations_cols + prev_formula_cols + [mass_val_col,] + other_metadata_columns\n",
    "\n",
    "# Identify sample columns - automatic based on metadata columns selected\n",
    "sample_cols = []\n",
    "for c in file.columns:\n",
    "    if c not in metadata_cols:\n",
    "        if c not in qc_sample_cols:\n",
    "            sample_cols.append(c)\n",
    "print(sample_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43692a7b",
   "metadata": {},
   "source": [
    "If you are working with a regression problem (labels are numerical values in a scale), set the regression parameter to True. Otherwise, it is assumed that you are working with a classification problem (label are categories). If you pick regression, please make sure that the \"class\" labels are numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9fbc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501dbee8",
   "metadata": {},
   "source": [
    "# Step 1.1: Define your groups and see data characterization <a class=\"anchor\" id=\"step-1_1\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "Here, we will define our groups (yeast strains in our example), so that we can obtain merged dataframes for each one of them and define colours to help us visualise them in later figures.\n",
    "\n",
    "If your read file already included the target, we will use that one, confirm if it is correct. If the file included the target but you want to change it, write the target you want and set `target_overwrite` to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your groups in the \"target_temp\" list by the exact order in which they appear in the dataframe.\n",
    "# Remember that each group must appear as many times as there are samples belonging to that group.\n",
    "# If your target was in the file you provided, you do not need to update this list\n",
    "target_temp = ['WT', 'WT', 'WT', 'dGRE3', 'dGRE3', 'dGRE3', 'dENO1', 'dENO1', 'dENO1', 'dGLO1', 'dGLO1', 'dGLO1',\n",
    "          'dGLO2', 'dGLO2', 'dGLO2']\n",
    "\n",
    "target_overwrite = False # Change in case you want to overwrite the target in file given\n",
    "\n",
    "target = target_temp # Default target\n",
    "\n",
    "if target_in_file:\n",
    "    target = [target_file[s] for s in sample_cols] # Update to target present in file provided\n",
    "\n",
    "    if target_overwrite:\n",
    "        target = target_temp # Overwrite target to the one defined by you\n",
    "\n",
    "\n",
    "# See if the classes are those that you want\n",
    "classes = list(pd.unique(pd.Series(target)))\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab535e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Colours for plots to ensure consistency\n",
    "\n",
    "Play around with colours to get the ones you want. \n",
    "\n",
    "- Colormaps like the tab10 used below: https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "- List of names of individual colours: https://matplotlib.org/stable/gallery/color/named_colors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed722fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize label colors\n",
    "\n",
    "colours = sns.color_palette('tab10', 10) # Only room for 10 classes in this case, choose your colours\n",
    "#colours = ('coral', 'turquoise', 'gold', 'indigo', 'lightgreen') # Example for using named colours\n",
    "ordered_labels = classes # Put the classes, you can choose the order\n",
    "\n",
    "label_colours = {lbl: c for lbl, c in zip(ordered_labels, colours)}\n",
    "sample_colours = [label_colours[lbl] for lbl in target]\n",
    "\n",
    "# See the colours for each class\n",
    "sns.palplot(label_colours.values())\n",
    "new_ticks = plt.xticks(range(len(ordered_labels)), ordered_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27054335",
   "metadata": {},
   "source": [
    "## Metabolic Feature Filtering\n",
    "\n",
    "This section performs Data Filtering through a succession of 4 different stages, each with their own purpose and objective. Many of these stages include multiple options. Individual stages can be skipped, and we may even recommend skipping some of them depending on the type of data you are utilizing. The output of the cell is the filtered dataframe.\n",
    "\n",
    "Each stage (and options within each) are now presented.\n",
    "\n",
    "**1) Filtering based on the number of samples each feature appears in. basic_filt: 'total_samples' (_default_), 'class_samples', None.**\n",
    "\n",
    "This will only include features that appear in a determined number or percentage (`n_min_samples_feature_appear` parameter) of either the total samples of the dataset or of at least the samples of one class. (Filter experimental artifacts, for example).\n",
    "\n",
    "**2) Filtering based on intensity values. int_based_filter: True or False.**\n",
    "\n",
    "This will filter metabolic features based on their intensity values as calculated by the `mean` or `median` over the samples they appear in (selected by `intensity_calculation`), removing lower intensity features. The `int_threshold_type` parameter determines whether a hard threshold with a set intensity value is used ('Intensity value') or a percentage based threshold where the lowest intensity X % of features are removed ('% Based'). The intensity value or percentage thresholds are set using the parameter `int_threshold_value`.\n",
    "\n",
    "**3) Filtering based on the feature variance of Quality Control samples. QC_filter: True or False.**\n",
    "\n",
    "Only available if you have at least three QC samples as selected in _qc_sample_cols_. This will eliminate features that have a variance in the quality control samples (where they should be equal) as estimated by the relative standard deviation (standard deviation / mean) above a determined threshold, since that points that they are not reproducible. The threshold is controlled by the `rsd_threshold` parameter (initially set up to 0.2). Features that do not appear in the QC samples are assumed to have 0 variance.\n",
    "\n",
    "**4) Filtering based on the feature variance of analysed samples. var_based_filter: True or False.**\n",
    "\n",
    "This filtering is not recommended if you are looking for exclusive metabolic features in the classes of your datasets or if you aim to use feature occurrence data. It will filter out the lowest variance features across the samples since their intensity patterns would not be informative. The ways to calculate variance allowed and selected by the `variance_calculation_type` parameter are: 'Inter-Quartile Range', 'Standard Deviation' (std), 'Relative Standard Deviation' (std/mean), 'Median Absolute Deviation' (MAD) and 'Relative Median Absolute Deviation' (MAD/mean). The percentage of features with lowest variance to remove is set in `feat_to_remove_percent`.\n",
    "\n",
    "**If you have a reference feature in your data, filtering may remove it, especially at stage 4. Use the parameter `always_keep_feat` to select indexes in a list that you want to preserve even if they would be filtered out. After filtering they are re-added to the data (if they would be removed by the filtering, they are put in the end of the DataFrame; if not, they are kept where they originally are).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f61b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Data Filtering\n",
    "filt_file = metsta.filtering_data_metabolomics(file, sample_cols, # DataFrame, Columns of Samples\n",
    "                                   qc_sample_cols, target, # Columns of QC samples and the target\n",
    "\n",
    "                               # Filter 1: Filter based on the number of samples features appear in\n",
    "                               basic_filt='total_samples', # 'total_samples', 'class_samples', None\n",
    "                               n_min_samples_feature_appear=2, # Min. number of samples a feature must appear in data/class\n",
    "\n",
    "                               # Filter 2: Intensity based filter\n",
    "                               int_based_filter=False, # True or False whether you apply it\n",
    "                               intensity_calculation='mean', # 'median'\n",
    "                               threshold_type='Intensity value', # '% Based'\n",
    "                               threshold_value=5*10**5, # Fraction such as 0.1 for % Based\n",
    "\n",
    "                               # Filter 3: QC sample feature variation based filter\n",
    "                               QC_filter=False, # True or False whether you apply it\n",
    "                               rsd_threshold=0.3, # Relative std threshold to remove features above said threshold\n",
    "\n",
    "                               # Filter 4: Sample feature variance based filter\n",
    "                               var_based_filter=False, # True or False whether you apply it\n",
    "                               variance_calculation_type='Relative Standard Deviation', # 'Inter-Quartile Range',\n",
    "                                #'Standard Deviation', 'Relative Standard Deviation', 'Median Absolute Deviation',\n",
    "                                #'Relative Median Absolute Deviation'\n",
    "                               feat_to_remove_percent=0.10, # Fraction of features to remove in this check\n",
    "\n",
    "                               # Features to keep independent of filtering\n",
    "                               feats_to_keep=[]\n",
    "                               )\n",
    "filt_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c9901",
   "metadata": {},
   "source": [
    "**See Data Characteristics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5a8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See data characterization\n",
    "data_characteristics = metsta.characterize_data(filt_file[sample_cols].T, target=target)\n",
    "data_characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f3967",
   "metadata": {},
   "source": [
    "**Remove the reference feature if you have already normalized your data by the reference feature previously**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_feat_lbl = ''\n",
    "\n",
    "if ref_feat_lbl != '':\n",
    "    filt_file = filt_file.drop(index=ref_feat_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290aead",
   "metadata": {},
   "source": [
    "# Step 1.2: Annotate with Database(s) <a class=\"anchor\" id=\"step-1_2\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "This is where you upload your database(s) to annotate your experimental dataset. \n",
    "\n",
    "Make sure that your file contains at least the following columns:\n",
    "- One with the databases accession label. This will serve as the index. In case you are a masochist and have opted to create your own database, make sure you give each compound an accession label (eg. DB0001, DB0002, DB0003, etc.)\n",
    "- One with the compounds' monoisotopic molecular masses (make sure that they are neutral masses). If **None**, masses will be calculated based on the compounds' chemical formula.\n",
    "- One with the compounds' names\n",
    "- One with the compounds' chemical formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d384026c",
   "metadata": {},
   "source": [
    "For the sake of simplicity, the lists of compound IDs, names and formulas will be placed in different columns. Just remember that they will be added by the same order, so the first ID in the IDs column corresponds to the first name in the names column and the first formula in the formulas column.\n",
    "\n",
    "**You can use multiple databases at the same time but we recommend against it since it will cause issues for data de-duplication.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = { # How you want the database to be called in the data: 'HMDB', ' PCY', 'DBK'\n",
    "    'HMDB': {'File': 'hmdb_complete.xlsx', # The name of each file\n",
    "             'Index_name': 'accession', # The name of the index in each database\n",
    "             'Name_col': 'name', # The name column in each database\n",
    "             'Mass_col': None, # The mass column in each database. Can be None\n",
    "             'Formula_col': 'chemical_formula', # The formula column in each database\n",
    "             'Class_col': 'class'}, # If there is a column indicating the class of each compound, indicate here, optional\n",
    "\n",
    "    'LTS': {'File': 'LOTUS_DB_Ver2.xlsx',\n",
    "             'Index_name': 'Wikidata_ID',\n",
    "             'Name_col': 'Name',\n",
    "             'Mass_col': 'Mass',\n",
    "             'Formula_col': 'Formula'},\n",
    "\n",
    "    'DBK': {'File': 'Drugbank_small_molecules_labeled.csv',\n",
    "             'Index_name': 'accession',\n",
    "             'Name_col': 'Name',\n",
    "             'Mass_col': None,\n",
    "             'Formula_col': 'Formula'}\n",
    "}\n",
    "\n",
    "for d in dbs:\n",
    "    print(d, ' -> ', dbs[d]['File'], '|', dbs[d]['Index_name'],'|', dbs[d]['Mass_col'],'|', \n",
    "          dbs[d]['Name_col'],'|', dbs[d]['Formula_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload databases\n",
    "for d in dbs:\n",
    "    print('Processing '+d)\n",
    "    if dbs[d]['File'].endswith('.csv'):\n",
    "        db = pd.read_csv(dbs[d]['File']).set_index(dbs[d]['Index_name'])\n",
    "        # Specific HMDB Fix\n",
    "        if d == 'HMDB':\n",
    "            db['name'] = db['name'].str.replace(\"b'\", \"\")\n",
    "            for i in  db.index:\n",
    "                name = db.loc[i, 'name']\n",
    "                if type(name) == str:\n",
    "                    db.loc[i, 'name'] = name[:-1]\n",
    "    elif dbs[d]['File'].endswith('.xlsx'):\n",
    "        db = pd.read_excel(dbs[d]['File']).set_index(dbs[d]['Index_name'])\n",
    "        # Specific HMDB Fix\n",
    "        if d == 'HMDB':\n",
    "            db['name'] = db['name'].str.replace(\"b'\", \"\")\n",
    "            for i in  db.index:\n",
    "                name = db.loc[i, 'name']\n",
    "                if type(name) == str:\n",
    "                    db.loc[i, 'name'] = name[:-1]\n",
    "            #db['name'] = db['name'].str.replace(\"'\", \"\")\n",
    "    else:\n",
    "        raise ValueError('File Format not accepted. Only csv and xlsx files are accepted.')\n",
    "    ##\n",
    "    if dbs[d]['Mass_col'] == None:\n",
    "        db['Calculated Mass'] = db[dbs[d]['Formula_col']].dropna().apply(metsta.calculate_monoisotopic_mass)\n",
    "        dbs[d]['Mass_col'] = 'Calculated Mass'\n",
    "\n",
    "    dbs[d]['DB'] = db\n",
    "    print(d,'->', len(db.index), 'compounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_db = metsta.joining_databases(dbs)\n",
    "full_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b2b9e",
   "metadata": {},
   "source": [
    "#### Select which adducts you want to search for in the analysis\n",
    "\n",
    "- Select adduct name and adduct mass shift in the dictionary - **At least one has to be selected to perform data annotation.**\n",
    "\n",
    "This will calculate a mass based on the shift provided for each compound in the selected databases, which will then be used to search for and match to the _m/z_ or Neutral masses in your dataset.\n",
    "\n",
    "Below, there are some examples for each of the 3 cases (we will use Fraction for better accuracy in calculation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c018c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_mass = Fraction(0.000548579909065)\n",
    "\n",
    "if idx_masses == 'Neutral':\n",
    "    adducts_to_consider = {\n",
    "        'M': 0}\n",
    "elif idx_masses == 'Positive':\n",
    "    adducts_to_consider = {\n",
    "        # Some common positive adducts to consider\n",
    "        'H+': Fraction(metsta.chemdict['H']) - electron_mass,\n",
    "        'Na+': Fraction(metsta.chemdict['Na']) - electron_mass,\n",
    "        'K+': Fraction(metsta.chemdict['K']) - electron_mass,\n",
    "    }\n",
    "elif idx_masses == 'Negative':\n",
    "    adducts_to_consider = {\n",
    "        # Some common negative adducts to consider - Confirm if these are correct\n",
    "        'H-': Fraction(- metsta.chemdict['H']) + electron_mass,\n",
    "        'Cl-': Fraction(metsta.chemdict['Cl']) + electron_mass,\n",
    "    }\n",
    "else:\n",
    "    adducts_to_consider = {} # No annotation is possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2c63b",
   "metadata": {},
   "source": [
    "You can tune the parameter **ppm_margin** (first line of next cell) to select the maximum deviation you want for annotation.\n",
    "\n",
    "We give an overview of the annotation here that can be changed with posterior de-duplication and filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25383963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppm_margin = 1\n",
    "only_select_min_ppm = False # If True, when there are candidates for annotation with different ppm deviations, return only\n",
    "# The ones with the lowest ppm deviation\n",
    "\n",
    "# Annotation\n",
    "annotated_data = filt_file.copy()\n",
    "\n",
    "metsta.metabolite_annotation(annotated_data, full_db, ppm_margin, mass_val_col,\n",
    "                             adducts_to_consider=adducts_to_consider, only_select_min_ppm=only_select_min_ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f8b7b5",
   "metadata": {},
   "source": [
    "# Step 1.3: Formula Assignment <a class=\"anchor\" id=\"step-1_3\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "Formula Assignment can be performed here. We have a pre-prepared Formula Database, but you may choose to override it by creating a new one with other parameters in the `FormulaDatabaseCreator.ipynb` jupyter notebook.\n",
    "\n",
    "Here, individual masses can be assigned up to 1250 Da. Unlike the Data Annotation step, only one formula will be chosen in each case, the one that most closely follows the rules specified by the algorithm. Check the functions at `form_assign_afunc.py` for more details.\n",
    "\n",
    "Choosing to perform formula assignment will lead to the creation of a column named `Mean Intensity` which has, as the name entails, the mean intensity of the corresponding metabolic features on the the whole dataset considering only the samples where the feature appears. This value will be used to pinpoint possible isotopic peaks.\n",
    "\n",
    "Whenever a metabolic feature has a compound annotated with any of the databases, the formula of that compound will have precedence over the assigned formula and will override it. In cases the annotated metabolites have more than one possible formula, whether from the same database or from different databases, those formulas will go through the assignment process and the most likely one will be selected based on the delineated rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b851f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide if you want to perform formula assignment\n",
    "perform_formula_assignment = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9cbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And Import the formula database\n",
    "formulas = {}\n",
    "if perform_formula_assignment:\n",
    "    for i in range(0,1250,250):\n",
    "        formulas[i] = pd.read_csv(f'formulas_improved_dict{str(i)}.csv').set_index('Unnamed: 0')\n",
    "\n",
    "# Import the coefficients needed for Formula Assignment\n",
    "if perform_formula_assignment:\n",
    "    with open('poly_coefs.json') as fp:\n",
    "        short_range_eq = json.load(fp)\n",
    "formulas.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ab32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some parameters for our assignment thresholds\n",
    "if perform_formula_assignment:\n",
    "    threshppm = ppm_margin # Same as for Data Annotation\n",
    "    int_col = 'Mean Intensity'\n",
    "\n",
    "    # Details for the short range check\n",
    "    sr_ratios = {'H/C': [short_range_eq['H/C']['0.2'], short_range_eq['H/C']['0.99']],\n",
    "                'O/C': [0, short_range_eq['O/C']['0.75']],\n",
    "                'N/C': [0, short_range_eq['N/C']['0.7']],\n",
    "                'P/C': [0, short_range_eq['P/C']['0.99']],\n",
    "                'S/C': [0, short_range_eq['S/C']['0.7']],\n",
    "                'F/C': [0, 0],\n",
    "                'Cl/C': [0, 0]}\n",
    "\n",
    "    # Get the file to be used for formula_assignment ready\n",
    "    ann_data_copy = annotated_data.sort_values(by=mass_val_col).copy()\n",
    "    # Create a column with mean intensities to judge for isotopes\n",
    "    ann_data_copy[int_col] = ann_data_copy.loc[:, sample_cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e094fd",
   "metadata": {},
   "source": [
    "Formula Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chemdict = {'H':(1.007825031898, 0.99984426),\n",
    "            'C':(12.000000000, 0.988922),\n",
    "            'N':(14.00307400425, 0.996337),\n",
    "            'O':(15.99491461926, 0.9976206),\n",
    "            'Na':(22.98976928195, 1.0),\n",
    "            'P':(30.97376199768, 1.0),\n",
    "            'S':(31.97207117354, 0.9504074),\n",
    "            'Cl':(34.968852694, 0.757647),\n",
    "            'F':(18.99840316207, 1.0),\n",
    "            'K':(38.96370648482, 0.932581),\n",
    "            'C13':(13.00335483534, 0.011078),\n",
    "            'H2': (2.014101777844, 0.00015574),\n",
    "            'O18':(17.99915961214, 0.0020004),\n",
    "            'N15':(15.00010889827, 0.003663),\n",
    "            'S34':(33.967867011, 0.0419599),\n",
    "            'Cl37': (36.965902573, 0.242353)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec10dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to store the results\n",
    "forma = pd.DataFrame(columns = ['Form_give','Theo_mass', 'Adduct', 'Score', 'All Scores'])\n",
    "if perform_formula_assignment:\n",
    "\n",
    "    dict_iso = {} # Store the results from an Isotope Checker\n",
    "    scores = {}\n",
    "\n",
    "    max_mass_in_data = ann_data_copy[mass_val_col].iloc[-1]\n",
    "\n",
    "    # Assign Formulas\n",
    "    i = 0 # Start with mass 0\n",
    "    while i < max_mass_in_data:\n",
    "        # Minor intervals of 50 Da\n",
    "        # Use the correct Formula databases (split in intervals of 50 m/z) for the correct masses\n",
    "        for split in tqdm(range(0,250,50)):\n",
    "\n",
    "            teste = ann_data_copy[ann_data_copy[mass_val_col] <= i+split+50]\n",
    "            teste = teste[teste[mass_val_col] > i+split]\n",
    "\n",
    "            # Now for each metabolic feature in our data\n",
    "            for j in range(len(teste)):\n",
    "                mass = teste.iloc[j].loc[mass_val_col]\n",
    "                idx = teste.index[j]\n",
    "                # form checker ratios\n",
    "                if i>= 1250:\n",
    "                    forma.loc[idx] = np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                tup = form_afunc.form_scoring(teste, idx, int_col, mass_val_col, threshppm, formulas,\n",
    "                                   adducts_to_consider=adducts_to_consider, dict_iso={}, deviation_in_ppm=True,\n",
    "                                   isotope_check=True, s34_check=True, common_range_check=True, in_pubchem_check=False,\n",
    "                                   valency_check=True, heteroatom_check=True, normalize_scores=True,\n",
    "                                   short_range_eq=sr_ratios)\n",
    "\n",
    "                score_dict = {}\n",
    "                if len(tup[-1]) > 0:\n",
    "                    for f_mass in tup[-1]['Final Score'].sort_values(ascending=False).index[1:]:\n",
    "                        for a in range(250, 1251, 250):\n",
    "                            if f_mass < a:\n",
    "                                d  = a-250\n",
    "                                break\n",
    "                        f_df = formulas[d].loc[f_mass]\n",
    "                        formula = form_afunc.formulator(f_df.loc['C'], f_df.loc['H'], f_df.loc['O'], f_df.loc['N'],\n",
    "                                        f_df.loc['S'], f_df.loc['P'], f_df.loc['F'], f_df.loc['Cl'], False)\n",
    "                        score_dict[formula] = np.round(tup[-1].loc[f_mass, 'Final Score'], 4) \n",
    "                \n",
    "                scores[idx] = tup[-1]\n",
    "                # Store results\n",
    "                forma.loc[teste.index[j]] = tup[1], tup[2], tup[3], tup[4], score_dict\n",
    "                dict_iso = tup[-2]\n",
    "\n",
    "\n",
    "        print(i, 'major split complete')\n",
    "\n",
    "        # Major intervals of 250 Da\n",
    "        i += 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emptying the formula database to save up memory storage\n",
    "formulas = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f04b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metabolic Features with Formula Assignments\n",
    "forma.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f12936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Formula Assignments by adducts considered\n",
    "forma['Adduct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e89475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the formula assignment to your dataset\n",
    "form_col = 'Formula_Assignment' # Name of the Column that will have the formula assignments\n",
    "\n",
    "if perform_formula_assignment:\n",
    "    annotated_data[form_col] = forma['Form_give']\n",
    "    annotated_data[form_col + ' Adduct'] = forma['Adduct']\n",
    "    annotated_data[form_col + ' Score'] = forma['Score']\n",
    "    annotated_data[form_col + ' Other Opt.'] = forma['All Scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e33d00",
   "metadata": {},
   "source": [
    "Roundup of Annotation and Formula Assignment Section Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a41613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_cols = [i for i in annotated_data.columns if i not in sample_cols]\n",
    "meta_cols_ids = [i for i in meta_cols if 'IDs' in i]\n",
    "meta_cols_names = [i for i in meta_cols if 'names' in i]\n",
    "meta_cols_formulas = [i for i in meta_cols if 'formulas' in i]\n",
    "meta_cols_mcounts = [i for i in meta_cols if 'match count' in i]\n",
    "print(meta_cols)\n",
    "print('------------')\n",
    "print(meta_cols_ids)\n",
    "print('------------')\n",
    "print(meta_cols_names)\n",
    "print('------------')\n",
    "print(meta_cols_formulas)\n",
    "print('------------')\n",
    "print(meta_cols_mcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44acb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_formula_assignment:\n",
    "    # Comparing Formula Assignment with annotations\n",
    "    form_assigned_ann = 0\n",
    "    form_assigned_not_ann = 0\n",
    "    no_form_assigned = 0\n",
    "    no_annot_but_form_assigned = 0\n",
    "    no_annot_or_form_assigned = 0\n",
    "\n",
    "\n",
    "    if len(dbs) != 0:\n",
    "        for idx in annotated_data.index:\n",
    "            forms = []\n",
    "            for col in meta_cols_formulas:\n",
    "                form = annotated_data.loc[idx, col]\n",
    "                if type(form) == list:\n",
    "                    forms.extend(annotated_data.loc[idx, col])\n",
    "            forms = list(set(forms))\n",
    "            #print(forms)\n",
    "            assigned_form = annotated_data.loc[idx, form_col]\n",
    "            if len(forms) > 0:\n",
    "                if type(assigned_form) == str:\n",
    "                    if assigned_form in forms:\n",
    "                        form_assigned_ann += 1\n",
    "                    else:\n",
    "                        form_assigned_not_ann += 1\n",
    "                else:\n",
    "                    no_form_assigned += 1\n",
    "            else:\n",
    "                if type(assigned_form) == str:\n",
    "                    no_annot_but_form_assigned += 1\n",
    "                else:\n",
    "                    no_annot_or_form_assigned += 1\n",
    "\n",
    "        print('Assigned formula matches one of the Annotated formulas:', form_assigned_ann)\n",
    "        print('Assigned formula does not match any of the Annotated formulas:', form_assigned_not_ann)\n",
    "        print('There was no Formula Assignment in an Annotated compound:', no_form_assigned)\n",
    "        print('There was no Annotation in compound with an Assigned formula', no_annot_but_form_assigned)\n",
    "        print('There was no Annotation or Formula Assignment', no_annot_or_form_assigned)\n",
    "\n",
    "    else:\n",
    "        print('No Data Annotation was performed')\n",
    "else:\n",
    "    print('No Formula Assignment was performed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470cf2d0",
   "metadata": {},
   "source": [
    "# Step 1.4: De-duplicating annotations <a class=\"anchor\" id=\"step-1_4\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "Due to the proximity of some m/z peaks, they can have the same exact compound annotation.\n",
    "\n",
    "The following section merges peaks that have the same compound annotation on the different databases into one single peak. Usually there is one peak that is the 'main' one with much higher intensities across the samples, although some cases this does not happen with the two _m/z_ peaks have or the annotation comes from multiple adducts.\n",
    "\n",
    "There is however a lot of problems in this process. In general, our procedure is the following:\n",
    "\n",
    "1) See peaks that have the same metabolite annotation by a database.\n",
    "\n",
    "2) See if the other compound annotations do not have different annotations for those peaks.\n",
    "\n",
    "3) If not, save the meta data of the compound and formula annotations by the different databases.\n",
    "\n",
    "4) **Situation Trouble - If yes, then we may have a problem. If for example, HMDB puts two different compounds for the 2 _m/z_ peaks and LOTUS puts the same compound, it is fair to treat them as different peaks. HOWEVER, if there are more than two peaks assigned with the same formula, the following can happen. Let's imagine a scenario where HMDB puts the same compound for 4 _m/z_ peaks and LOTUS assigns to one of them one compound, to a second one a different compound and the last two ones does not assign a compound. What is the correct course of action? Right now, it just does not merge any of these peaks, but we could merge the two peaks that do not have an annotation by LOTUS. Would that be correct? Or should we merge with one of the two other peaks which have annotations by LOTUS. After all, they would normally be merged if not for the existence of two different LOTUS annotations. Hence, the problem and why we advocate against using multiple databases at once.**\n",
    "\n",
    "4) Then create the new peak, by keeping the highest intensity value in each sample from the different peaks if they belong to the same adducts (intensity values come from the maximum value in the peak and not peak area) and summing the intensities of the peaks if they belong to different adducts. If both cases simultaneously happen for an annotation, same adduct peaks are first merged by keeping the highest intensity and then summing the intensities of peaks from different adducts.\n",
    "\n",
    "4.1) If peaks come from different adducts based on the Probable _m/z_ column, then, the peak 'bucket label' and 'Neutral Mass'/'Probable _m/z_' columns become identical to the peak which has the highest average intensity of all the peaks with the same annotation.\n",
    "\n",
    "4.2) If the peaks are all from the same adduct and all highest intensity values come from one _m/z_ peak, then the 'bucket label' and 'Neutral Mass'/'Probable _m/z_' columns become identical to that peak.\n",
    "\n",
    "4.3) If the peaks are all from the same adduct and the highest intensity comes from at least two different peaks, then, the peak 'bucket label', 'Neutral Mass' or 'Probable _m/z_' columns become the weighted average (based on the average intensity of the peaks) of all the peaks with the same annotation.\n",
    "\n",
    "5) This process is repeated for all annotations and then formula assignment. **Usually the number of de-duplications made by each database should decrease since when you de-duplciate duplicate assignments by one database, you are usually de-duplicating in others.**\n",
    "\n",
    "\n",
    "**ALWAYS check the merge_problems variable. If it is NOT empty, then those merge problems issues might exist. We do not currently have an automatic answer for them. They should be seen on a case by case basis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c497399",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dbs.keys()) > 0:\n",
    "    if len(prev_annotations_cols) > 0:\n",
    "        mcid = prev_annotations_cols + ['Matched IDs', ]\n",
    "\n",
    "    else:\n",
    "        mcid = ['Matched IDs', ]\n",
    "\n",
    "if form_col in annotated_data.columns:\n",
    "    mcid.append(form_col)\n",
    "\n",
    "if len(prev_formula_cols) > 0:\n",
    "    mcid = mcid + prev_formula_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b0f96e",
   "metadata": {},
   "source": [
    "Duplicate (or more) annotations report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe689d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_an_form_cols = prev_annotations_cols + prev_formula_cols\n",
    "\n",
    "for col in mcid:\n",
    "    n_duplicates = []\n",
    "    if col == form_col:\n",
    "        col_alt = form_col\n",
    "    elif col == 'Matched IDs':\n",
    "        col_alt = col\n",
    "    else:\n",
    "        col_alt = col\n",
    "        col = 'Prev. Annotation: ' + col\n",
    "    for i in annotated_data[annotated_data[col_alt].notnull()][col_alt]:\n",
    "        a = 0\n",
    "        for j in annotated_data[annotated_data[col_alt].notnull()][col_alt]:\n",
    "            if i==j:\n",
    "                if a == 1:\n",
    "                    #print(i)\n",
    "                    n_duplicates.append(i)\n",
    "                    break\n",
    "                a+=1\n",
    "    print(col)\n",
    "    print('N of same annotations on multiple peaks:        ', len(n_duplicates))\n",
    "    print('Total number of annotations for these cases:     ', len(pd.Series(n_duplicates, dtype='object').value_counts()))\n",
    "    if len(pd.Series(n_duplicates, dtype='object').value_counts()) == 0:\n",
    "        print('Maximum number of peaks with the same annotation:', 0)\n",
    "    else:\n",
    "        print('Maximum number of peaks with the same annotation:', pd.Series(n_duplicates).value_counts().iloc[0])\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data = annotated_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a686d1",
   "metadata": {},
   "source": [
    "Select if you want to perform de-duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_deduplication = True # False\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de85c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_adds = True if len(adducts_to_consider) > 1 else False\n",
    "prev_an_form_cols = prev_annotations_cols + prev_formula_cols\n",
    "\n",
    "if perform_deduplication:\n",
    "    annotated_data,mergings_performed,merging_situations,merge_description,merge_problems = metsta.duplicate_disambiguator(\n",
    "        annotated_data, # Our data\n",
    "        sample_cols, # Columns where the samples are\n",
    "        mcid=mcid,\n",
    "        mass_col=mass_val_col,\n",
    "        prev_an_form_cols=prev_an_form_cols + [form_col,], # Previous Annotation and Formula Columns and Formula Assignment\n",
    "        multiple_adds=multiple_adds, # If you have an m/z column\n",
    "        verbose=verbose) # If you want a more detailed output while the function runs\n",
    "else:\n",
    "    mergings_performed, merging_situations, merge_description, merge_problems = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9906ed",
   "metadata": {},
   "source": [
    "### Seeing problems in merging\n",
    "\n",
    "**Example for this specific dataset**\n",
    "\n",
    "In this case, there are fifteen of them, although one is repeating.\n",
    "\n",
    "Most of these are however due to incompatibilities between the annotations made and formula assignments made. Since annotation generally is more reliable we can merge them by forcing the Formula to be the one from the peak with the highest average intensity as performed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2227cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_df = pd.DataFrame(merge_problems)\n",
    "problem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a00385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force merging the cases where the problem is the Formula\n",
    "# The Formula that remains is the one corresponding to the peak with the highest average intensity\n",
    "k_to_remove = []\n",
    "\n",
    "prev_an_form_cols = prev_annotations_cols + prev_formula_cols\n",
    "\n",
    "if len(problem_df)>0: \n",
    "    for k, v in merge_problems.items():\n",
    "        if v['Poss. Reason'] in prev_formula_cols + [form_col,]:\n",
    "            problem_case = v\n",
    "            if problem_case['Col Id.'] not in prev_an_form_cols + [form_col,]:\n",
    "                db_problem = 'Matched '+problem_case['Col Id.']+' IDs'\n",
    "            elif problem_case['Col Id.'] in prev_formula_cols + [form_col,]:\n",
    "                # Incompatibility between formula assignments\n",
    "                continue\n",
    "            else:\n",
    "                db_problem = problem_case['Col Id.']\n",
    "            idx_to_merge = list(k)\n",
    "\n",
    "            if len(idx_to_merge)>1:\n",
    "                # Section to see if the idx to merge are still present in annotated_data. If not, skip\n",
    "                skip = False\n",
    "                for idx in idx_to_merge:\n",
    "                    if idx not in annotated_data.index:\n",
    "                        print(f'{idx} not in annotatd_data. It was probably already merged in this cell.')\n",
    "                        print(f'Cannot perform merging of {idx_to_merge} peaks.')\n",
    "                        print('----------')\n",
    "                        skip=True\n",
    "                        break\n",
    "                if skip:\n",
    "                    continue\n",
    "\n",
    "                # Perform individual merging\n",
    "                annotated_data, desc = metsta.individually_merging(\n",
    "                    annotated_data, # Data\n",
    "                    idx_to_merge, # Your idx to merge\n",
    "                    sample_cols, mass_val_col, mcid, prev_annotations_cols,\n",
    "                    prev_formula_cols + [form_col,],\n",
    "                    multiple_adds=multiple_adds)\n",
    "\n",
    "                desc[list(desc.keys())[0]]['Situation'] = desc[list(desc.keys())[0]]['Situation'] + ' - Formula Problem'\n",
    "                # See if the description of the merging is what you wanted to achieve\n",
    "\n",
    "                # Supplementing the information to merging descriptors\n",
    "                merge_description[list(desc.keys())[0]] = desc[list(desc.keys())[0]]\n",
    "                if desc[list(desc.keys())[0]]['Situation'] in merging_situations:\n",
    "                    merging_situations[desc[list(desc.keys())[0]]['Situation']] += 1\n",
    "                else:\n",
    "                    merging_situations[desc[list(desc.keys())[0]]['Situation']] = 1\n",
    "                mergings_performed[desc[list(desc.keys())[0]]['DB']] += 1\n",
    "                k_to_remove.append(k)\n",
    "\n",
    "for k in k_to_remove:\n",
    "    merge_problems.pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a351104",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(merging_situations)>0:\n",
    "    merging_situations['Problems'] = len(merge_problems)\n",
    "problem_df = pd.DataFrame(merge_problems)\n",
    "problem_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26901baa",
   "metadata": {},
   "source": [
    "Now we have 9 remaining problems, from which 8 of them come from incompatibilities between formula assignment done in the data beforehand and this software, which can mostly be ignored. \n",
    "\n",
    "The problem is only really real when there are more than 2 different peaks, so in this case, there is not a real problem case. Still, let's see the only peak with incompatibilities between annotations more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca5e55",
   "metadata": {},
   "source": [
    "**1) L-Cystathionine (column 1)**\n",
    "\n",
    "You can see L-Cystathionine formula is C24H48NO7P.\n",
    "\n",
    "The problem comes from an extra annotation in HMDB in one of the peaks: 'Acetamiprid' (in both cases). Different annotations so no need to individually merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894611aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ex = pd.DataFrame()\n",
    "if aligned_samples:\n",
    "    if filename == '5yeasts_notnorm.csv':\n",
    "        if aligned_samples:\n",
    "            ex = annotated_data[annotated_data['Name'] == 'L-Cystathionine'][meta_cols]\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aebe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.DataFrame()\n",
    "if aligned_samples:\n",
    "    if filename == '5yeasts_notnorm.csv':\n",
    "        if aligned_samples:\n",
    "            if 'Matched HMDB names' in annotated_data.columns:\n",
    "                ex = annotated_data[annotated_data['Name'] == 'L-Cystathionine']['Matched HMDB names'].values\n",
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4094fc88",
   "metadata": {},
   "source": [
    "### Description of merging process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8240f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_desc = pd.DataFrame(merge_description)\n",
    "m_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(m_desc)>0:\n",
    "    print('N of Mergings:            ', len(m_desc.columns))\n",
    "    print('N of Peaks merged:        ', m_desc.loc['N merged peaks'].sum())\n",
    "    print('N of Peaks dropped:       ', m_desc.loc['N merged peaks'].sum() - len(m_desc.columns))\n",
    "    print('N of Peaks after merging: ', len(annotated_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74aa683",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergings_performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff52343",
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_situations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5972568e",
   "metadata": {},
   "source": [
    "##### Confirm results of annotation procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking all matches')\n",
    "\n",
    "cols_to_see = []\n",
    "for i in prev_annotations_cols:\n",
    "    if i in annotated_data.columns:\n",
    "        cols_to_see.append(i)\n",
    "\n",
    "if len(dbs) != 0:\n",
    "    cols_to_see = cols_to_see + meta_cols_ids\n",
    "annotated_data['Has Match?'] = np.nan\n",
    "for i in tqdm(annotated_data.index):\n",
    "    df = annotated_data.loc[[i]]\n",
    "    hasmatch = df[cols_to_see].notnull().values.any()\n",
    "    annotated_data.at[i, 'Has Match?'] = hasmatch\n",
    "print('N of Annotated Compounds:', (annotated_data['Has Match?'] == True).sum())\n",
    "print('---------------')\n",
    "\n",
    "annotated_data.index = annotated_data.index.astype(str)\n",
    "metadata_cols.append('Has Match?')\n",
    "annotated_data.info(verbose= True)\n",
    "annotated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ba34a",
   "metadata": {},
   "source": [
    "# Step 2: Basic processing and pre-treatment <a class=\"anchor\" id=\"step-2\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "These functions are compilations from the pre-treatments available in the **Metabolinks** Python package.\n",
    "\n",
    "Each step of this process has a different associated function that explain different methods available to do those steps that are included in the big all-including `filtering_pretreatment` function. By our experience, the default option in the different functions are the most common ones to use. There are more options to use for all these steps, for example, for Missing Value Imputation that can be applied that are not present here and would have to be implemented.\n",
    "\n",
    "This returns five DataFrames:\n",
    "- **treated_data** - Data after filtering and pre-treatment with the samples ready for statistical analysis.\n",
    "- **processed_data** - Data after filtering and only normalization with samples and meta data used for compound finding and distinguishing between common and exclusive metabolites.\n",
    "- **univariate_data** - Data after filtering, imputation and only normalization used for fold change calculation in univariate analysis.\n",
    "- **meta_data** - Meta data with compound annotation and formulas for later.\n",
    "- **bin_data** - treated_data but with BinSim pre-treatment.\n",
    "\n",
    "**The procedures to be used need to be chosen by the user.**\n",
    "\n",
    "### Data Pre-Treatment\n",
    "\n",
    "There are many different ways these can be used but in general there are four categories: 'Missing Value Imputation', 'Normalization', 'Transformations' and 'Scaling' each with their options. If you do not want some types of pre-treatment, select None for that specific category (except missing value imputation, that HAS to be done).\n",
    "\n",
    "##### Note: If data was already normalized, skip normalization by making _norm_ argument in `filtering_pretreatment` function to None and remember to remove the reference feature peak if you have it (see cell imediately above step 1.2).\n",
    "\n",
    "Each different method for each category is explained in their respective functions. Each category has also a keyword (kw) that can be added since many methods have one parameter that can be changed. That keyword becomes that parameter.\n",
    "\n",
    "**Missing Value Imputation** (`missing_value_imputer`): 'min_sample' (_Default_), 'min_feat', 'min_data', 'zero'.\n",
    "\n",
    "**Normalization** by (`normalizer`): 'ref_feat' (_Default_), 'total_sum', 'PQN', 'Quantile', None.\n",
    "\n",
    "**Transformation** (`transformer`): 'glog' (_Default_), None.\n",
    "\n",
    "**Scaling** (`scaler`): 'pareto' (_Default_), 'mean_center', 'auto', 'range', 'vast', 'level', None.\n",
    "\n",
    "Furthermore, **Binary Simplification** (BinSim) is also returned as well and kept in bin_data.\n",
    "\n",
    "**TODO: Change extra_filt to work with new general frame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd943413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering based on number of times features appear - Filtering done prior\n",
    "filt_method='total_samples' # 'total_samples', 'class_samples', None\n",
    "filt_kw=2 # N of minimum samples of the dataset ('total_samples') or class ('class_samples') features have to appear in\n",
    "extra_filt=None # Filtering based on annotation of features 'Formula', 'Name' or None - currently not implemented\n",
    "\n",
    "# Missing Value Imputations\n",
    "mvi='min_sample' # 'min_sample' (Default), 'min_feat', 'min_data', 'zero'\n",
    "mvi_kw=1/5 # Specific Keyword for MVI method\n",
    "\n",
    "# Normalization\n",
    "norm='total_sum' # 'ref_feat' (Default), 'total_sum', 'PQN', 'Quantile', None\n",
    "norm_kw='555.2692975341 Da' # Specific keyword for Normalization method\n",
    "\n",
    "# Transformation\n",
    "tf='glog' # 'glog' (Default), None\n",
    "tf_kw=None # Specific keyword for Transformation\n",
    "\n",
    "# Scaling\n",
    "scaling='pareto' # 'pareto' (Default), 'mean_center', 'auto', 'range', 'vast', 'level', None\n",
    "scaling_kw=None # Specific keyword for Scaling\n",
    "\n",
    "# Change the parameters in the variables above\n",
    "treated_data, processed_data, univariate_data, meta_data, bin_data = metsta.filtering_pretreatment(\n",
    "                  annotated_data, target,sample_cols,\n",
    "                  filt_method, filt_kw, extra_filt, # Filtering \n",
    "                  mvi, mvi_kw, # Missing value imputation\n",
    "                  norm, norm_kw, # Normalization\n",
    "                  tf, tf_kw, # Transformation\n",
    "                  scaling, scaling_kw) # Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_data.info()\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3077116",
   "metadata": {},
   "source": [
    "#### Export treated DataFrames (as Excel), target (as txt) and processed data (as pickle).\n",
    "\n",
    "This file can then be used as a direct input to analysis modules separated from this notebook such as the `sMDiN_analysis_module.ipynb` or others than can be created.\n",
    "\n",
    "The first sheet includes the processed_data with metadata and normalized (without missing value imputation) data and the second sheet has the treated data. Remaining sheets contain the data in different formats that might be useful such as the sample data after BinSim pre-treatment or after missing value imputation and normalization only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pretreated_data = False\n",
    "# Filename for the exported data\n",
    "filename_TreatedData = 'Export_TreatedData.xlsx'\n",
    "# Filename for the exported data pickle\n",
    "filename = 'Export_TreatedData.pickle'\n",
    "filename = 'Export_ProcData.pickle'\n",
    "# Filename for the exported target\n",
    "filename = 'Export_Target.txt'\n",
    "\n",
    "if save_pretreated_data:\n",
    "    # Saving data\n",
    "    with pd.ExcelWriter(filename_TreatedData) as writer:\n",
    "        processed_data.to_excel(writer, sheet_name='Metadata+Normalized Data')\n",
    "        treated_data.T.to_excel(writer, sheet_name='Fully Treated Data')\n",
    "        bin_data.T.to_excel(writer, sheet_name='BinSim Treated Data')\n",
    "        univariate_data.to_excel(writer, sheet_name='MVI+Norm Data')\n",
    "\n",
    "    # Saving data\n",
    "    treated_data.to_pickle('Export_TreatedData.pickle')\n",
    "    processed_data.to_pickle('Export_ProcData.pickle')\n",
    "\n",
    "    # Saving data\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('\\n'.join(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85794166",
   "metadata": {},
   "source": [
    "# Step 3: Find Common and Exclusive metabolites between the classes <a class=\"anchor\" id=\"step-3\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample specific data frames\n",
    "groups = {}\n",
    "group_dfs = {}\n",
    "\n",
    "group_dfs_ids = {}\n",
    "\n",
    "for cl in classes:\n",
    "    groups[cl] = []\n",
    "    \n",
    "for c, t in zip(processed_data[sample_cols].columns, target):\n",
    "    for g in groups:\n",
    "        if g == t:\n",
    "            groups[g].append(c)\n",
    "            \n",
    "for g in groups:\n",
    "    for c, t in zip(processed_data[sample_cols].columns, target):\n",
    "        if g == t:\n",
    "            group_dfs[g] = processed_data.dropna(subset= groups[g], thresh=1)\n",
    "            group_dfs_ids[g] = group_dfs[g].iloc[[\n",
    "                i for i in range(len(group_dfs[g]['Has Match?'])) if group_dfs[g]['Has Match?'].iloc[i]]]\n",
    "\n",
    "for df in group_dfs:\n",
    "    print(df,  '------>', len(group_dfs[df]), 'metabolites from which', len(group_dfs_ids[df]), f'have matches')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc1358a",
   "metadata": {},
   "source": [
    "Now you have a specific dataframe for each individual group in your samples. They are all in a dictionary called group_dfs with the format name : dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed19235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example...\n",
    "print(f\"Here's the dataframe for one of the classes: {list(group_dfs.keys())[0]}\")\n",
    "group_dfs[list(group_dfs.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb7139e",
   "metadata": {},
   "source": [
    "We can now see the common and exclusive metabolites between these DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common to all\n",
    "common_all = metsta.common(group_dfs.values())\n",
    "common_all_id = metsta.common(group_dfs_ids.values())\n",
    "print(len(common_all.index), f'metabolites are common to all group, {len(common_all_id.index)} with matches.')\n",
    "\n",
    "print('')\n",
    "\n",
    "# Common to two or more - Might become unintelligible if you have too many classes (stops if you have more than 7 classes)\n",
    "if len(classes) <= 7:\n",
    "    for n in range(2, len(group_dfs)+1):\n",
    "        for comb in itertools.combinations(group_dfs, n):\n",
    "            df_list = []\n",
    "            labels_list = []\n",
    "            df_id_list = []\n",
    "            for c in comb:\n",
    "                labels_list.append(c)\n",
    "                df = group_dfs[c]\n",
    "                df_list.append(df)\n",
    "                df_id_list.append(group_dfs_ids[c])\n",
    "            df_common = metsta.common(df_list)\n",
    "            df_id_common = metsta.common(df_id_list)\n",
    "            for s in group_dfs:\n",
    "                if s not in labels_list:\n",
    "                    exclude = group_dfs[s]\n",
    "                    df_common = df_common.loc[~(df_common.index.isin(exclude.index))]\n",
    "                    df_id_common = df_id_common.loc[~(df_id_common.index.isin(group_dfs_ids[s].index))]\n",
    "            print(len(df_common.index), f'metabolites ({len(df_id_common.index)} with matches) are common to {comb}.') \n",
    "\n",
    "print('')\n",
    "\n",
    "# Exclusive to only one group\n",
    "exclusives = metsta.exclusive(group_dfs.values())\n",
    "exclusives_id = metsta.exclusive(group_dfs_ids.values())\n",
    "exc_id = dict(zip(group_dfs, exclusives_id))\n",
    "exc = dict(zip(group_dfs, exclusives))\n",
    "for g in group_dfs:\n",
    "    print(len(exc[g].index), f'metabolites are exclusive to {g}, {len(exc_id[g].index)} with matches.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c01a88",
   "metadata": {},
   "source": [
    "**Venn Diagram**\n",
    "\n",
    "Plots made using the pyvenn git-hub repository (https://github.com/tctianchi/pyvenn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Venn diagram\n",
    "labels = venn.get_labels([group_dfs[i].index for i in group_dfs], fill=['number'])\n",
    "labels_ids = venn.get_labels([group_dfs_ids[i].index for i in group_dfs_ids], fill=['number'])\n",
    "\n",
    "labels_all = {}\n",
    "for i, j in labels.items():\n",
    "    labels_all[i] = j + f' ({labels_ids[i]})'\n",
    "    \n",
    "c = [(c[0], c[1], c[2], 0.3) for c in colours]\n",
    "\n",
    "if len(classes) == 2:\n",
    "    fig, ax = venn.venn2(\n",
    "        labels_all, names=classes, figsize=(8,8), fontsize=11, colors=c, constrained_layout=True) # 2 Classes\n",
    "    plt.text(0.5,0, 'N of peaks (N of matched compounds)', fontsize=12, horizontalalignment='center')\n",
    "elif len(classes) == 3:\n",
    "    fig, ax = venn.venn3(\n",
    "        labels_all, names=classes, figsize=(8,8), fontsize=11, colors=c, constrained_layout=True) # 3 Classes\n",
    "    plt.text(0.5,-0.05, 'N of peaks (N of matched compounds)', fontsize=12, horizontalalignment='center')\n",
    "elif len(classes) == 4:\n",
    "    fig, ax = venn.venn4(\n",
    "        labels_all, names=classes, figsize=(8,8), fontsize=11, colors=c, constrained_layout=True) # 4 Classes\n",
    "    plt.text(0.5,0.05, 'N of peaks (N of matched compounds)', fontsize=12, horizontalalignment='center')\n",
    "elif len(classes) == 5:\n",
    "    fig, ax = venn.venn5(\n",
    "        labels_all, names=classes, figsize=(8,8), fontsize=11, colors=c, constrained_layout=True) # 5 Classes\n",
    "    plt.text(0.5,0, 'N of peaks (N of matched compounds)', fontsize=12, horizontalalignment='center')\n",
    "elif len(classes) == 6:\n",
    "    fig, ax = venn.venn6(\n",
    "        labels_all, names=classes, figsize=(8,8), fontsize=11, colors=c, constrained_layout=True) # 6 Classes\n",
    "    plt.text(0.5,0.2, 'N of peaks (N of matched compounds)', fontsize=12, horizontalalignment='center') \n",
    "else:\n",
    "    print(f'Venn Diagram can currently only be made with 2 to 6 different classes. You currently have {len(classes)} classes.')\n",
    "\n",
    "# Save the Venn Diagram\n",
    "#if len(classes) < 7:\n",
    "#    fig.savefig('VennDiagram_plot.png', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3375d1",
   "metadata": {},
   "source": [
    "**Intersection Plot** (not recommended for more than 6 classes also)\n",
    "\n",
    "Intersection Plots made using the package UpSetPlot (https://pypi.org/project/UpSetPlot/0.8.0/)\n",
    "\n",
    "**Intersection Plot with All detected peaks**\n",
    "\n",
    "Can color section regarding annotated compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cdb821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "counts = True # Show absolute counts of metabolites on top of bars\n",
    "percentages = False # Show percentage of metabolites on top of bars\n",
    "include_annotated = False # Include annotated compounds as a bar of a different colour\n",
    "annotated_colour = 'Red' # Choose the color for the bar\n",
    "annotated_counts = False # Show absolute counts of annotated metabolites on top of the annotated metabolites bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d785ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display \n",
    "# Suppress Warnings due to upsetplot package using deprecated pandas packages\n",
    "# Make an upsetplot\n",
    "groups_dict = {}\n",
    "for df in group_dfs:\n",
    "    groups_dict[df] = group_dfs[df].index\n",
    "ups = from_contents(groups_dict)\n",
    "\n",
    "# Plotting Intersection Plot\n",
    "f,ax = plt.subplots(1,1, constrained_layout=True)\n",
    "ax.axis('Off')\n",
    "\n",
    "# Plot Main Intersection Plot\n",
    "ax_dict = upsetplot.plot(ups, f, subset_size='count', show_counts=counts, show_percentages=percentages,\n",
    "                         sort_categories_by='input', include_empty_subsets=include_annotated)\n",
    "\n",
    "# Put counts of only annotated features if include_annotated = True\n",
    "if include_annotated:\n",
    "    groups_dict_id = {}\n",
    "    for df in group_dfs_ids:\n",
    "        groups_dict_id[df] = group_dfs_ids[df].index\n",
    "    ups_id = from_contents(groups_dict_id)\n",
    "    UpSet(ups_id, subset_size='count',facecolor=annotated_colour, sort_categories_by='input',\n",
    "          include_empty_subsets=include_annotated).plot_intersections(ax_dict['intersections'])\n",
    "    a=0\n",
    "    # Put the counts over the red, you might have to adjust the +15 part to something else depending on the counts you have\n",
    "    if annotated_counts:\n",
    "        for i in upsetplot.query(ups_id,sort_categories_by='input', include_empty_subsets=True).subset_sizes:\n",
    "            #print()\n",
    "            ax_dict['intersections'].text(\n",
    "                a,i+15, i, color='red', fontsize=10, zorder=15, horizontalalignment='center', weight=\"bold\")\n",
    "            a +=1\n",
    "\n",
    "# Save the Intersection Plot\n",
    "#f.savefig('IntersectionPlot_plot.png', dpi=400, bbox_inches='tight', pad_inches=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6867dd",
   "metadata": {},
   "source": [
    "**UpSetPlot with only ANNOTATED compounds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08275e9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture --no-display \n",
    "# Suppress Warnings due to upsetplot package using deprecated pandas packages\n",
    "# Make an Intersection plot\n",
    "groups_dict_ids = {}\n",
    "for df in group_dfs:\n",
    "    groups_dict_ids[df] = group_dfs_ids[df].index\n",
    "ups = from_contents(groups_dict_ids)\n",
    "\n",
    "# Plotting Intersection Plot\n",
    "f,ax = plt.subplots(1,1, constrained_layout=True)\n",
    "ax.axis('Off')\n",
    "\n",
    "# Plot Main Intersection Plot\n",
    "ax_dict = upsetplot.plot(ups, f, subset_size='count', show_counts=counts, show_percentages=percentages,\n",
    "                         sort_categories_by='input', include_empty_subsets=False)\n",
    "\n",
    "\n",
    "# Save the Intersection Plot\n",
    "#f.savefig('IntersectionPlot_annotated_only_plot.png', dpi=400, bbox_inches='tight', pad_inches=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3ab4fd",
   "metadata": {},
   "source": [
    "**UpSetPlot with only CHEMICAL CLASSES of ANNOTATED compounds**\n",
    "\n",
    "Instead of only considering annotations, it considers their chemical classes. Thus, if a peak has multiple annotations with different classes, they all count. However, each peak is only counted for each chemical class once.\n",
    "\n",
    "Color sections by class of compound if database used includes compound class. Since classes vary between databases it will only accept results from a single database at a time. Change with parameters.\n",
    "\n",
    "See parameters for control. Put `database_with_class_info` equal to **None** to skip this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0b61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_with_class_info = 'HMDB'\n",
    "\n",
    "# Parameters\n",
    "ann_counts = True # Show absolute counts of metabolites on top of bars\n",
    "ann_percentages = False # Show percentage of metabolites on top of bars\n",
    "\n",
    "color_sequence = [(0,0,0)] + list(sns.color_palette('tab10', 10)) # Color sequence from most to less populated class\n",
    "# Depending on how many classes you wish to see, you may need to add colours\n",
    "# The colours should all be names/hex codes or should all be RGB. Do not mix RGB formatting with other.\n",
    "colored_classes = 7 # Choose the top number of populated classes to be shown\n",
    "# This number has to be equal or lower than the number of colors in color_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a13107",
   "metadata": {},
   "outputs": [],
   "source": [
    "if database_with_class_info:\n",
    "    # DF to keep only annotated compounds\n",
    "    only_ann_df = processed_data.loc[processed_data['Has Match?']]\n",
    "    # Create a DataFrame for the class information\n",
    "    class_df = pd.DataFrame(index=only_ann_df.index, columns=['Class'])\n",
    "    # Go through the annotated compounds\n",
    "    if database_with_class_info in dbs:\n",
    "        for i in only_ann_df.index:\n",
    "            ann_ids = only_ann_df.loc[i, 'Matched '+ database_with_class_info + ' IDs']\n",
    "            # Get the IDS from them\n",
    "            classes_associated = []\n",
    "            if type(ann_ids) == list:\n",
    "                for ids in ann_ids:\n",
    "                    # Get the class of each HMDB ID\n",
    "                    cl = dbs[database_with_class_info]['DB'].loc[ids, dbs[database_with_class_info]['Class_col']]\n",
    "                    # If not added, add it to a list\n",
    "                    if cl not in classes_associated:\n",
    "                        classes_associated.append(cl)\n",
    "                # Save classes obtained\n",
    "                class_df.at[i, 'Class'] = classes_associated\n",
    "    # Explode to count each class identified for a peak as individual\n",
    "    class_df_temp = class_df\n",
    "    class_df = class_df.explode('Class')\n",
    "    # Give unique IDs to each one\n",
    "    class_df['ID'] = range(len(class_df))\n",
    "    ## See the more represented classes\n",
    "    print('Classes to individually show in the UpSetPlot')\n",
    "    print(class_df['Class'].value_counts().head(colored_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d01467",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display \n",
    "# Suppress Warnings due to upsetplot package using deprecated pandas packages\n",
    "\n",
    "if database_with_class_info:\n",
    "    # Create Dict to feed to upsetplot - With the combined numbers of every single class\n",
    "    groups_dict_id = {}\n",
    "    for df in group_dfs_ids:\n",
    "        groups_dict_id[df] = class_df.loc[group_dfs_ids[df].index].dropna()['ID']\n",
    "    # Feed the Dict to the upsetplot package\n",
    "    ups = from_contents(groups_dict_id)\n",
    "\n",
    "    # Plotting Intersection Plot\n",
    "    f,ax = plt.subplots(1,1, constrained_layout=True)\n",
    "    ax.axis('Off')\n",
    "\n",
    "    # Change colours from rgb to hex if needed\n",
    "    if type(color_sequence[0]) == tuple:\n",
    "        new_colors = []\n",
    "        for i in color_sequence:\n",
    "            new_colors.append(metsta.RGB(np.array(i)*255))\n",
    "    else:\n",
    "        new_colors = color_sequence\n",
    "\n",
    "    # Plot Main Intersection Plot - With the combined numbers of every single class\n",
    "    ax_dict = upsetplot.plot(ups, f, subset_size='count', facecolor=new_colors[0], show_counts=ann_counts,\n",
    "                             show_percentages=ann_percentages,\n",
    "                             sort_categories_by='input', include_empty_subsets=True)\n",
    "    max_x_axis = ups.reset_index().iloc[:,:-1].sum().max()\n",
    "\n",
    "    # To set up the legend\n",
    "    patches = []\n",
    "\n",
    "    # Plotting the different Intersection plot numbers for the different classes\n",
    "    n_ser = 1\n",
    "    # Iteratively go for each class to represent and\n",
    "    for i in class_df['Class'].value_counts().index[:colored_classes]:\n",
    "        # Remove the counts for that specific class\n",
    "        ups = ups.iloc[\n",
    "            [a for a in range(len(ups.index)) if ups.iloc[a, 0] not in class_df.loc[class_df['Class'] == i]['ID'].values]]\n",
    "\n",
    "        # Then overlay the current Intersection Plots with the Updated values, basically, since we are removing this \n",
    "        # specific class the space between the previously plotted Intersection Plot and this one corresponds to the number\n",
    "        # of compounds of that class for the specific group\n",
    "        UpSet(ups, subset_size='count',facecolor=new_colors[n_ser], sort_categories_by='input',\n",
    "              include_empty_subsets=True).plot_intersections(ax_dict['intersections'])\n",
    "        UpSet(ups, subset_size='count',facecolor=new_colors[n_ser], sort_categories_by='input',\n",
    "              include_empty_subsets=True).plot_totals(ax_dict['totals'])\n",
    "\n",
    "        # So for the horizontal bars to not look weird the first number needs to be bigger than the biggest number on the\n",
    "        # 1st Intersection Plot\n",
    "        ax_dict['totals'].set_xlim([max_x_axis*1.2,0])\n",
    "        # Control the legend - technically the class colour corresponds to the previously plotted UpSetPlot\n",
    "        patches.append(mpatches.Patch(color=new_colors[n_ser-1], label=i))\n",
    "        n_ser+=1\n",
    "\n",
    "    patches.append(mpatches.Patch(color=new_colors[n_ser-1], label='All Other Classes')) # For All Other Classes\n",
    "    # Plot the legend\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1,1))\n",
    "    plt.show()\n",
    "\n",
    "# Save the Intersection Plot\n",
    "#f.savefig('IntersectionPlot_annotated_classes_only_plot.png', dpi=400, bbox_inches='tight', pad_inches=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f978f",
   "metadata": {},
   "source": [
    "#### Setting an Excel file with the common and exclusive (to each class) annotated compounds\n",
    "\n",
    "Change **GENERATE_Excel_file** to True if you want to generate the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc722dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the excel files for exclusive compounds\n",
    "exclusive_dfs = {}\n",
    "for i in exc_id.keys():\n",
    "    df_temp = pd.DataFrame(index=exc_id[i].index)\n",
    "    df_temp['Appear in Class Samples'] = exc_id[i].loc[:, sample_cols].notnull().sum(axis=1)\n",
    "    df_temp['% of Class Samples'] = (exc_id[i].loc[:, sample_cols].notnull().sum(axis=1)) / target.count(i) * 100\n",
    "\n",
    "    for an in prev_annotations_cols:\n",
    "        if an in exc_id[i].columns:\n",
    "            df_temp['Prev. Match - ' + an] = exc_id[i][an]\n",
    "\n",
    "    for form in prev_formula_cols:\n",
    "        if form in exc_id[i].columns:\n",
    "            df_temp['Prev. Form. - ' + form] = exc_id[i][form]\n",
    "\n",
    "    for col in meta_cols:\n",
    "        if col not in metadata_cols:\n",
    "            df_temp[col] = exc_id[i][col]\n",
    "    exclusive_dfs[i] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Exclusive df, ordered by the number of samples of that class they appear in\n",
    "print('Example for:', classes[0])\n",
    "exclusive_dfs[classes[0]].sort_values(by='Appear in Class Samples', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f21cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the excel files for common compounds\n",
    "common_temp = pd.DataFrame(index=common_all_id.index)\n",
    "common_temp['Appear in Samples'] = common_all_id.loc[:, sample_cols].notnull().sum(axis=1)\n",
    "common_temp['% of Samples'] = (common_all_id.loc[:, sample_cols].notnull().sum(axis=1)) / len(target) * 100\n",
    "\n",
    "for an in prev_annotations_cols:\n",
    "    if an in common_all_id.columns:\n",
    "        common_temp['Prev. Match - ' + an] = common_all_id[an]\n",
    "for form in prev_formula_cols:\n",
    "    if form in common_all_id.columns:\n",
    "        common_temp['Prev. Form. - ' + form] = common_all_id[form]\n",
    "for col in meta_cols:\n",
    "    if col not in metadata_cols:\n",
    "        common_temp[col] = common_all_id[col]\n",
    "common_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d916ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_Excel_file = False # Change to True if you want to generate the file\n",
    "if GENERATE_Excel_file:\n",
    "    writer = pd.ExcelWriter('Common_Exclusive_Compounds.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    common_temp.to_excel(writer, sheet_name='Common')\n",
    "\n",
    "    text_format = writer.book.add_format({'text_wrap' : True, 'valign': 'top'})\n",
    "    for i in range(1, len(common_temp.columns)+1):\n",
    "        width=18\n",
    "        if i in [1,2]:\n",
    "            width=8\n",
    "        elif common_temp.columns[i-1].endswith('IDs'):\n",
    "            width=15\n",
    "        elif common_temp.columns[i-1].endswith('count'):\n",
    "            width=8\n",
    "        elif common_temp.columns[i-1].endswith('names') or common_temp.columns[i-1].endswith('Name'):\n",
    "            width=40\n",
    "        writer.sheets['Common'].set_column(i,i,width,text_format)\n",
    "\n",
    "    header_format = writer.book.add_format({'bold': True, 'text_wrap': True, 'valign': 'top'})\n",
    "    # Overwrite both the value and the format of each header cell\n",
    "    for col_num, value in enumerate(common_temp.columns.values):\n",
    "        writer.sheets['Common'].write(0, col_num + 1, value, header_format)\n",
    "\n",
    "    for a in exclusive_dfs.keys():\n",
    "        exclusive_dfs[a].to_excel(writer, sheet_name=str(a)+' Exclusive')\n",
    "\n",
    "        text_format = writer.book.add_format({'text_wrap' : True, 'valign': 'top'})\n",
    "        for i in range(1, len(exclusive_dfs[a].columns)+1):\n",
    "            width=18\n",
    "            if i in [1,2]:\n",
    "                width=8\n",
    "            elif exclusive_dfs[a].columns[i-1].endswith('IDs'):\n",
    "                width=15\n",
    "            elif exclusive_dfs[a].columns[i-1].endswith('count'):\n",
    "                width=8\n",
    "            elif exclusive_dfs[a].columns[i-1].endswith('names') or exclusive_dfs[a].columns[i-1].endswith('Name'):\n",
    "                width=40\n",
    "            writer.sheets[str(a)+' Exclusive'].set_column(i,i,width,text_format)\n",
    "\n",
    "        header_format = writer.book.add_format({'bold': True, 'text_wrap': True, 'valign': 'top'})\n",
    "        # Overwrite both the value and the format of each header cell\n",
    "        for col_num, value in enumerate(exclusive_dfs[a].columns.values):\n",
    "            writer.sheets[str(a)+' Exclusive'].write(0, col_num + 1, value, header_format)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d4073",
   "metadata": {},
   "source": [
    "# Step 4: Unsupervised Statistical Analysis <a class=\"anchor\" id=\"step-4\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "Unsupervised analysis means that the algorithms here do not receive the information of the different class labels.\n",
    "\n",
    "Here, we show PCA and Hierarchical Clustering (HCA) Analysis.\n",
    "\n",
    "The following functions were adapted from the code git-hub repository 'binsim_paper' (from the files 'paper_binsim_data_prep.ipynb' and 'paper_binsim_unsupervised.ipynb')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004abe3",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65884c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(6,6)) # Change the size of the figure\n",
    "\n",
    "see_comps = (1,2) # Select which components to see in the projection\n",
    "n_comp = 5 # Select number of components to calculate\n",
    "\n",
    "principaldf, var, loadings = metsta.compute_df_with_PCs_VE_loadings(treated_data, \n",
    "                                       n_components=n_comp,\n",
    "                                       whiten=True, labels=target, return_var_ratios_and_loadings=True)\n",
    "\n",
    "# Plot PCA\n",
    "ax.axis('equal')\n",
    "lcolors = label_colours\n",
    "\n",
    "metsta.plot_PCA(principaldf, lcolors, \n",
    "         components=see_comps, # Select components to see\n",
    "         title='', # Select title of plot\n",
    "         ax=ax)\n",
    "\n",
    "# Remove ellipses by putting a # before the next line\n",
    "metsta.plot_ellipses_PCA(principaldf, \n",
    "                  lcolors, \n",
    "                  components=see_comps, # Select components to see\n",
    "                  ax=ax, \n",
    "                  q=0.95) # Confidence ellipse with 95% (q) confidence\n",
    "\n",
    "ax.set_xlabel(f'PC {see_comps[0]} ({var[see_comps[0]-1] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "ax.set_ylabel(f'PC {see_comps[1]} ({var[see_comps[1]-1] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "\n",
    "plt.legend(fontsize=15) # Set the size of labels\n",
    "plt.grid() # If you want a grid or not\n",
    "plt.show()\n",
    "#f.savefig('Name_PCAplot.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95347504",
   "metadata": {},
   "source": [
    "#### TODO: Include loading arrows in the PCA plot of the most relevant metabolites?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6bbce9",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering Analysis (HCA)\n",
    "\n",
    "Performing Hierarchical Clustering.\n",
    "\n",
    "Distance metrics: 'euclidean' is the default, others are in https://docs.scipy.org/doc/scipy/reference/spatial.distance.html.\n",
    "\n",
    "Linkage metrics: **'ward', 'average'**, 'centroid', 'single', 'complete', 'weighted', 'median'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'euclidean' # Select distance metric\n",
    "method = 'ward' # Select linkage method\n",
    "\n",
    "distances = dist.pdist(treated_data, metric=metric)\n",
    "Z = hier.linkage(distances, method=method)\n",
    "\n",
    "hca_res = {'Z': Z, 'distances': distances}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot HCA\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 4), constrained_layout=True) # Set Figure Size\n",
    "    metsta.plot_dendogram(hca_res['Z'], \n",
    "                   target, ax=ax,\n",
    "                   label_colors=label_colours,\n",
    "                   title='', # Select title\n",
    "                   color_threshold=0) # Select a distance threshold from where different sets of lines are coloured\n",
    "\n",
    "    plt.show()\n",
    "    #f.savefig('Name_HCAplot.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3878de3",
   "metadata": {},
   "source": [
    "If you want a version of a dendrogram more easy to change parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "# Plotting the dendrogram, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n",
    "# For details on how you can change different aspects of the dendrograms\n",
    "dn = hier.dendrogram(hca_res['Z'], labels=target,\n",
    "                     leaf_font_size=13,\n",
    "                     above_threshold_color='b')\n",
    "# Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "# Coloring the labels with their specific colours\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl_text = lbl.get_text()\n",
    "    if type(list(label_colours)[0]) == np.float64:\n",
    "        lbl_text = float(lbl_text)\n",
    "    lbl.set_color(label_colours[lbl_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ddf141",
   "metadata": {},
   "source": [
    "# Step 5: Supervised Statistical Analysis <a class=\"anchor\" id=\"step-5\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "Supervised analysis means that the algorithms have access to label information. This means they are **not** indicated for the purpose of seeing if there are differences between classes/samples, only for seeing which metabolites are most important for those differences.\n",
    "\n",
    "The supervised statistical analysis methods currently implemented in this notebook are:\n",
    "- Random Forest Models (RFs)\n",
    "- Partial Least Squares (PLS)\n",
    "- Extreme Gradient Boosting (XGBoost)\n",
    "\n",
    "They all support both regression and classification problems, but may not be equally suitable for all use cases.\n",
    "\n",
    "XGBoost has thus far performed poorly in Binary classification problems, and both XGBoost and Random Forests may take a long time to run for regression problems, depending on the hyperparameters chosen.\n",
    "\n",
    "**Functions for this step are in metanalysis_standard.py and are an adaptation of functions from the BinSim paper.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4e9d1",
   "metadata": {},
   "source": [
    "## Step 5.1: Random Forest <a class=\"anchor\" id=\"step-5_1\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "First: Minor optimization of the number of trees (200 is a good number to use though) - see when the accuracy of the model stops increasing and starts fluctuating around a certain value (that should be the minimum number of trees to use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random seed (number between the ()) if you don't want the results to change every time you run the code\n",
    "np.random.seed()\n",
    "\n",
    "# See maximum number of trees to search\n",
    "top_tree_in_grid=300\n",
    "\n",
    "# Vector with values for the parameter n_estimators\n",
    "# Models will be built from 10 to 300 trees in 5 tree intervals\n",
    "values = {'n_estimators': range(10,top_tree_in_grid,5)}\n",
    "\n",
    "if regression:\n",
    "    rf = skensemble.RandomForestRegressor(n_estimators=200)\n",
    "else:\n",
    "    rf = skensemble.RandomForestClassifier(n_estimators=200)\n",
    "    \n",
    "clf = GridSearchCV(rf, values, cv=3, n_jobs=-1) # Change cv to change cross-validation\n",
    "\n",
    "print('Fitting RFs...', end=' ')\n",
    "\n",
    "RF_optim = {'Treated':{}, 'BinSim':{}}\n",
    "clf.fit(treated_data, target) # Fitting the data to RF models with all the different number of trees\n",
    "\n",
    "# Storing results\n",
    "RF_optim['Treated']['scores'] = list(clf.cv_results_['mean_test_score'])\n",
    "RF_optim['Treated']['n_trees'] = list(clf.cv_results_['param_n_estimators'])\n",
    "\n",
    "# BinSim turn\n",
    "clf.fit(bin_data, target) # Fitting the data to RF models with all the different number of trees\n",
    "\n",
    "# Storing results\n",
    "RF_optim['BinSim']['scores'] = list(clf.cv_results_['mean_test_score'])\n",
    "RF_optim['BinSim']['n_trees'] = list(clf.cv_results_['param_n_estimators'])\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee46f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results and adjusting parameters of the plot\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(6,6), constrained_layout=True) # Set Figure Size\n",
    "\n",
    "        c_map = sns.color_palette('tab10', 10)\n",
    "\n",
    "        for treatment, c in zip(RF_optim.keys(), c_map):\n",
    "            ax.plot(RF_optim[treatment]['n_trees'], [s*100 for s in RF_optim[treatment]['scores']], label=treatment, color=c)\n",
    "        \n",
    "        ax.set_ylabel('Random Forest CV Mean Accuracy (%)', fontsize=15) # Set the y_label and size\n",
    "        ax.set_title('RF Optimization', fontsize=18) # Set the title and size\n",
    "        ax.set_ylim([30,101]) # Set the limits on the y axis\n",
    "\n",
    "        #f.suptitle('Optimization of the number of trees')\n",
    "        ax.legend(fontsize=15) # Set the legend and size\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d97947",
   "metadata": {},
   "source": [
    "### Fitting the RF model\n",
    "\n",
    "**See details of `RF_model` function (model fitting AND evaluation) in metanalysis_standard.py.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a number for the seed for consistent results\n",
    "np.random.seed()\n",
    "\n",
    "n_trees=200 # Number of trees in the model\n",
    "# Select other parameters in the function itself\n",
    "\n",
    "RF_results = metsta.RF_model(treated_data, target, regression, # Data, labels and if it's a regression or classification\n",
    "                return_cv=True, iter_num=5, # If you want cross validation results and number of iterations for it\n",
    "                n_trees=n_trees, # Number of trees in the model\n",
    "                cv=None, n_fold=3, random_state=None, # Choose a method of cross-validation (None is stratified cv),\n",
    "                                                    # the number of folds and a stable random_state for CV only if cv none\n",
    "    \n",
    "        # For Classification Problems\n",
    "         metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted')) # Choose the performance metrics\n",
    "\n",
    "        # For Regression problems\n",
    "        #metrics = ('neg_mean_squared_error',), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048978b5",
   "metadata": {},
   "source": [
    "Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84915b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in RF_results.items():\n",
    "    if k != 'model' and k != 'imp_feat':\n",
    "        rf_results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(rf_results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5aa74",
   "metadata": {},
   "source": [
    "**Important Feature analysis**\n",
    "\n",
    "See the most important features for class discrimination (sorted by importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe328269",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_rf = meta_data.copy()\n",
    "imp_feats_rf.insert(0,'Bucket label', imp_feats_rf.index)\n",
    "imp_feats_rf.insert(1,'Gini Importance', '')\n",
    "for n in range(len(RF_results['imp_feat'])):\n",
    "    imp_feats_rf['Gini Importance'].iloc[RF_results['imp_feat'][n][0]] = RF_results['imp_feat'][n][1]\n",
    "imp_feats_rf = imp_feats_rf.sort_values(by='Gini Importance', ascending=False)\n",
    "imp_feats_rf.index = range(1, len(imp_feats_rf)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91729756",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_rf.head(20) # Select number of features to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = False\n",
    "\n",
    "# Saving the most important features by their fraction 'frac_feat_impor'.\n",
    "# If None, saving the most important features based on a threshold 'VIP_Score_threshold'.\n",
    "# If also None, save the full dataset of all features\n",
    "frac_feat_impor = 0.02 # Fraction of features to save, If None the variable in the next line is used.\n",
    "score_threshold = None # Only used if variable above is None, threshold of score to consider a feature important.\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    if frac_feat_impor:\n",
    "        max_idx = int(frac_feat_impor*len(imp_feats_rf))\n",
    "        filt_imp_feats_rf = imp_feats_rf.iloc[:max_idx]\n",
    "        filt_imp_feats_rf.to_excel(f'RF_ImpFeat_{frac_feat_impor*100}%.xlsx')\n",
    "    elif score_threshold:\n",
    "        filt_imp_feats_rf = imp_feats_rf[imp_feats_rf['Gini Importance'] > score_threshold]\n",
    "        filt_imp_feats_rf.to_excel(f'RF_ImpFeat_GiniImpgreater{score_threshold}.xlsx')\n",
    "    else:\n",
    "        imp_feats_rf.to_excel(f'RF_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78821c14",
   "metadata": {},
   "source": [
    "### RF Permutation Test\n",
    "\n",
    "This is a test to observe if the model performance is significant, that is, if it is better than a random model. If it is, then the remaining results from the important features give meaningful information, if not, then you cannot use the important features results since they essentially mean nothing.\n",
    "\n",
    "The permutation test will permutate the class labels of your samples, that is, all classes will be randomized while maintaining the same number of samples per class and classes. Then, for each permutation it will see the model performance. \n",
    "\n",
    "The default metric for model performance is `accuracy`. If you have an imbalanced model, accuracy is not a good metric, so you should change to another such as `f1_weighted`.\n",
    "\n",
    "**Note: Permutation tests take a while to do, thus the default is False in the beginning so you can make a first analysis on your dataset. If you then want to use the results of a supervised model, run a permutation test to check if your model is significant.**\n",
    "\n",
    "_p_-value calculation: (1 + n of times permutated model has better performance than non-permutated model)/n of permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1938e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GENERATE = False # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random_state parameter in the function)\n",
    "\n",
    "    perm_results_RF = metsta.permutation_RF(\n",
    "        treated_data, target, regression,  # data, labels and if it's a regression\n",
    "        iter_num=500, # N of permutations to do in your test - around 500 should be enough\n",
    "        n_trees=200, # Number of trees in the model\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        metric=('accuracy')) # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab861ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(treated_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_RF\n",
    "\n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='RF Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "\n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('N of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('Random Forest Permutation Test', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_RF_PermutationTest.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8bd088",
   "metadata": {},
   "source": [
    "### ROC curves (Receiver Operating Characteristic)\n",
    "\n",
    "This gives you an area under curve that the closer it is to 1, the better our model. We also iterate this n_iter times so we have a softer curve and to give as a better indication of the actual area under curve (AUC). This plots the true positive rate against the false positive rate.\n",
    "\n",
    "**Only possible for when your datasets have 2 classes. Choose the class which is considered the 'positive' class.**\n",
    "\n",
    "If you do not have 2 classes, skip ahead this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_RF = metsta.RF_ROC_cv(treated_data, target, regres=regression, # Data, target and if it's a regression\n",
    "                                        pos_label=pos_label, # Positive label\n",
    "                                        n_trees=200, # Number of trees of RF\n",
    "                                        n_iter=15, # Number of iterations to repeat \n",
    "                                        cv=None, n_fold=3, random_state=None) # Method of CV (None is stratified cv), the n\n",
    "                                                                              # of folds and stable random_state for CV only\n",
    "                                                                              # if cv none\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        # Plot the ROC curves \n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_RF\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set_title('Random Forest ROC Curve', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_RF_ROCcurve.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b1bebd",
   "metadata": {},
   "source": [
    "## Step 5.2: PLS-DA (Partial Least Squares - Discriminant Analysis) <a class=\"anchor\" id=\"step-5_2\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "First, an optimization of the number of components of PLS-DA is performed.\n",
    "\n",
    "The VIPs scores are calculated using the function `_calculate_vips` in multianalysis.py that comes from the link https://www.researchgate.net/post/How-can-I-compute-Variable-Importance-in-Projection-VIP-in-Partial-Least-Squares-PLS as provided by Keiron Teilo O'Shea in that link.\n",
    "\n",
    "**Note: `max_comp` (maximum number of components) cannot be higher than the number of samples that will train a model minus 1. For example, if you have 15 samples and a 3-fold cross-validation each fold will have 5 samples. A training set will be comprised of two of those folds thus it will have 10 samples, thus `max_comp` (and `n_comp` later on) cannot be higher than 9. Another example if you have 22 samples and 5 folds, the folds will have 4/4/4/5/5 samples each. A training set will have four of these folds and the minimum sum of them is 4+4+4+5-1=16, thus max_comp cannot be higher than 16.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d797af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "# above is to supress PLS warnings\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed()\n",
    "\n",
    "max_comp = 9 # Max. number of components to search (the higher the more time it takes)\n",
    "\n",
    "# Store Results\n",
    "PLS_optim = metsta.optim_PLSDA_n_components(treated_data, target, regression, # Data, target and if it's a regression\n",
    "                                    encode2as1vector=True,\n",
    "                                    max_comp=max_comp, # Max. number of components to search\n",
    "                                    kf=None, n_fold=3, # Cross validation to use (none is stratified CV) and n of folds\n",
    "                                    scale=False) # Set scale to True only if you did not do scaling in pre-treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98e38a",
   "metadata": {},
   "source": [
    "In the figure below, $R^{2}$ and $Q^{2}$ are shown. You want to choose the number of components **where $Q^{2}$ specifically** stops increasing, so, in this case, 4 components will be chosen. \n",
    "\n",
    "- $Q^{2}$ - PLS score by its mean squared error based on the test samples, thus it is ideal to test if the model will overfit. This will increase until a certain number of components that should be chosen. Then it usually stabilizes but from a certain point it might start to decrease which would mean the model is overfitting. For example, in this case, we choose 4 components based on this score, but you could choose 5 or 6 and it would not affect the model a lot.\n",
    "- $R^{2}$ - PLS score by its mean squared error based on the training samples used to make the model (it will be higher than $Q^{2}$ but it should not be used to choose the number of components. This metric always increases with the more components used which means it will overfit the model eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f54a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cols = sns.color_palette('tab10', 10) # Set the colors for the lines\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True) # Set the figure size\n",
    "        c = 0\n",
    "        for i, values in PLS_optim.items():\n",
    "            if i =='CVscores':\n",
    "                name = 'Q$^2$'\n",
    "            else:\n",
    "                name = 'R$^2$'\n",
    "            \n",
    "            ax.plot(range(1, len(values) + 1), values, label=name, color = scores_cols[c])\n",
    "            c = c+1\n",
    "        \n",
    "        ax.set(xlabel='Number of Components', # Set the label for the x axis\n",
    "                ylabel='PLS Score') # Set the label for the Y axis\n",
    "        ax.legend(loc='lower right', fontsize=15) # Set the legend\n",
    "        ax.set_ylim([0, 1.02]) # Set limits for y axis\n",
    "        ax.set_xticks(range(0, len(values), 2)) # Set ticks that appear in the bottom of x axis\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0abac6f",
   "metadata": {},
   "source": [
    "### PLS-DA model fitting\n",
    "\n",
    "**See details of `PLSDA_model_cv` function (model fitting AND evaluation) in metanalysis_standard.py (adapted from the BinSim paper).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "# above is to supress PLS warnings\n",
    "\n",
    "n_comp = 4 # Number of components of PLS-DA model - very important\n",
    "\n",
    "PLSDA_results = metsta.PLSDA_model_CV(treated_data, target, regression, # Data, target and if it's a regression\n",
    "                       n_comp=n_comp, # Number of components of PLS-DA model - very important\n",
    "                       kf=None, n_fold=3, random_state=None, # Choose Cross-validation method (None is stratified cv),\n",
    "                                                             # the number of folds and a stable random_state for CV only\n",
    "                                                             # if cv none\n",
    "                       iter_num=10, # Number of iterations of cross-validation to do\n",
    "                       encode2as1vector=True,\n",
    "                       scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                       feat_type='VIP') # Feature Importance Metric to use, default is VIP scores (see function for others)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab48cd5",
   "metadata": {},
   "source": [
    "**Performance analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bfd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in PLSDA_results.items():\n",
    "    if k != 'Q2' and k != 'imp_feat':\n",
    "        pls_results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(pls_results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b29742",
   "metadata": {},
   "source": [
    "**Important Feature analysis**\n",
    "\n",
    "See the most important features for class discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26929e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_plsda = meta_data.copy()\n",
    "imp_feats_plsda.insert(0,'Bucket label', imp_feats_plsda.index)\n",
    "imp_feats_plsda.insert(1,'VIP Score', '')\n",
    "for n in range(len(PLSDA_results['imp_feat'])):\n",
    "    imp_feats_plsda['VIP Score'][PLSDA_results['imp_feat'][n][0]] = PLSDA_results['imp_feat'][n][1]\n",
    "imp_feats_plsda = imp_feats_plsda.sort_values(by='VIP Score', ascending=False)\n",
    "imp_feats_plsda.index = range(1, len(imp_feats_plsda)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_plsda.head(20) # Select number of features to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd9810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = False\n",
    "\n",
    "# Saving the most important features by their fraction 'frac_feat_impor'.\n",
    "# If None, saving the most important features based on a threshold 'VIP_Score_threshold'.\n",
    "# If also None, save the full dataset of all features\n",
    "frac_feat_impor = 0.02 # Fraction of features to save, If None the variable in the next line is used.\n",
    "VIP_Score_threshold = 1 # Only used if variable above is None, threshold of score to consider a feature important.\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    if frac_feat_impor:\n",
    "        max_idx = int(frac_feat_impor*len(imp_feats_plsda))\n",
    "        filt_imp_feats_plsda = imp_feats_plsda.iloc[:max_idx]\n",
    "        filt_imp_feats_plsda.to_excel(f'PLSDA_ImpFeat_{frac_feat_impor*100}%.xlsx')\n",
    "    elif VIP_Score_threshold:\n",
    "        filt_imp_feats_plsda = imp_feats_plsda[imp_feats_plsda['VIP Score'] > VIP_Score_threshold]\n",
    "        filt_imp_feats_plsda.to_excel(f'PLSDA_ImpFeat_VIPgreater{VIP_Score_threshold}.xlsx')\n",
    "    else:\n",
    "        imp_feats_plsda.to_excel(f'PLSDA_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf968d4c",
   "metadata": {},
   "source": [
    "### Sample Projection on the two most important Components/Latent Variables of PLS models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ce809",
   "metadata": {},
   "source": [
    "**To do** See if it's worth doing this in a regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not regression:\n",
    "    n_components = 4 # N of componentes\n",
    "\n",
    "    model, scores = fit_PLSDA_model(treated_data, target,\n",
    "                                    n_comp=n_components, scale=False, # Only true if scaling was not done earlier\n",
    "                                    encode2as1vector=True,\n",
    "                                    lv_prefix='LV ', label_name='Label')\n",
    "\n",
    "    lcolors = label_colours\n",
    "\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "            fig, ax = plt.subplots(1,1, figsize=(6,6)) # Set up fig size\n",
    "            metsta.plot_PCA(scores, lcolors, title=\"PLS Projection\", ax=ax,\n",
    "                            components=(1,2)) # Select components to see\n",
    "            plt.title('PLS Projection', fontsize=20) # Title\n",
    "            plt.legend(loc='upper right', ncol=1, fontsize=15)  # Legend           \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            #fig.savefig('Name_PLSplot.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41da830",
   "metadata": {},
   "source": [
    "### PLS-DA Permutation Test\n",
    "\n",
    "This is a test to observe if the model performance is significant, that is, if it is better than a random model. If it is, then the remaining results from the important features give meaningful information, if not, then you cannot use the important features results since they essentially mean nothing.\n",
    "\n",
    "The permutation test will permutate the class labels of your samples, that is, all classes will be randomized while maintaining the same number of samples per class and classes. Then, for each permutation it will see the model performance. \n",
    "\n",
    "The default metric for model performance is `accuracy`. If you have an imbalanced model, accuracy is not a good metric, so you should change to another such as `f1_weighted`. Metric can only be: `accuracy`, `f1_weighted`, `recall_weighted` or `precision_weighted`.\n",
    "\n",
    "**Note: Permutation tests take a while to do, thus the default is False in the beginning so you can make a first analysis on your dataset. If you then want to use the results of a supervised model, run a permutation test to check if your model is significant.**\n",
    "\n",
    "_p_-value calculation: (1 + n of times permutated model has better performance than non-permutated model)/n of permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64768d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GENERATE = False # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random state in the function below)\n",
    "\n",
    "    perm_results_PLSDA = metsta.permutation_PLSDA(\n",
    "        treated_data, target,  # data and labels\n",
    "        n_comp=4, # Number of components\n",
    "        iter_num=500, # N of permutations to do in your test - around 500 should be enough\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        encode2as1vector=True, scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "        metric='accuracy') # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(treated_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_PLSDA\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='PLS-DA Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('N of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('PLS-DA Permutation Test', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_PLSDA_PermutationTest.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4e7d5",
   "metadata": {},
   "source": [
    "### ROC curves (Receiver Operating Characteristic)\n",
    "\n",
    "This basically gives you an area under curve that the closer it is to 1, the better our model. We also iterate this n_iter times so we have a softer curve and to give as a better indication of the actual area under curve (AUC). This plots the true positive rate against the false positive rate.\n",
    "\n",
    "**Only possible for when your datasets have 2 classes. Choose the class which is considered the 'positive' class.**\n",
    "\n",
    "If you do not have 2 classes, skip ahead this section.\n",
    "\n",
    "**Do not forget to change parameters in the function to match the ones used earlier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ccc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_PLSDA = metsta.PLSDA_ROC_cv(treated_data, target, # Data and target\n",
    "                                pos_label=pos_label, # Positive label\n",
    "                                n_comp=4, # Number of components\n",
    "                                scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                                n_iter=15, # Number of iterations to repeat \n",
    "                                cv=None, n_fold=3, random_state=None) # Method of CV (None is stratified cv), the number of\n",
    "                                                                      # folds and stable random_state for CV only if cv none\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643df7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves \n",
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_PLSDA\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set(xlabel='False positive rate', ylabel='True positive rate')\n",
    "                ax.set_title('PLS-DA ROC Curve', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_PLSDA_ROCcurve.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ffb871",
   "metadata": {},
   "source": [
    "## Step 5.3: XGBoost (eXtreme Gradient Boosting) <a class=\"anchor\" id=\"step-5_3\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b7c08",
   "metadata": {},
   "source": [
    "This block of code automatically selects an XGBoost objective function for your specific use case. If you want to use a different function, you may select it here, or in the 'objective' input to the functions.\n",
    "\n",
    "Some reading on objective functions:\n",
    "- https://xgboost.readthedocs.io/en/stable/parameter.html (Ctrl-F objective)\n",
    "- https://machinelearningmastery.com/xgboost-loss-functions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_analysis = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if regression:\n",
    "    objective = \"reg:squarederror\"\n",
    "else:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        print('Warning: XGBoost is currently unreliable for binary classification tasks. If you still want to use it delete xgb_analysis = False')\n",
    "        objective = \"binary:logistic\"\n",
    "        xgb_analysis = False\n",
    "    else:\n",
    "        objective = \"multi:softprob\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b9ab5",
   "metadata": {},
   "source": [
    "We first start with a brief optimization of the parameters for XGBoost training. Default is to focus only on the number of estimators (trees) and their maximum depth. However, there are other parameters that can be tweaked, simply by adding new terms to the `xgb_optim_params` dictionary. Please be aware that each new parameter will explonentially increase the running time of the function, and that for regression problem even just a single-parameter tuning can take very long.\n",
    "\n",
    "To 'fix' an hyperparater that you do not want to tune at a non-default value, simply add it to the `XGB_optim` function as `**kwargs`.\n",
    "\n",
    "Resources on XGBoost Hyperparameters and their tuning:\n",
    "- https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "- https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning\n",
    "- https://freedium.cfd/https://towardsdatascience.com/xgboost-fine-tune-and-optimize-your-model-23d996fab663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea63679",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    # Select a random seed (number between the ()) if you don't want the results to change every time you run the code\n",
    "    np.random.seed()\n",
    "\n",
    "    xgb_max_n_estimators = 300\n",
    "\n",
    "    xgb_optim_params = {'n_estimators': range(10,xgb_max_n_estimators+1,5)} \n",
    "\n",
    "    #xgb_optim_params = {'min_child_weight': numeric_range(0,1,0.1), 'subsample': numeric_range(0,1,0.1), 'gamma': numeric_range(0,1,0.1), \n",
    "    #                    'max_depth': range(0,10,1)}\n",
    "\n",
    "    #XGB_Optim = metsta.optimise_xgb_parameters(\n",
    "    #   treated_data, target, xgb_optim_params, regression, objective)\n",
    "    XGB_Optim = metsta.optimise_xgb_parameters(\n",
    "        treated_data, target, xgb_optim_params, regression, objective, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2411847",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    param_to_plot = 'n_estimators'\n",
    "\n",
    "    # Plotting the results and adjusting parameters of the plot\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "            f, ax = plt.subplots(1, 1, figsize=(6,6), constrained_layout=True) # Set Figure Size\n",
    "\n",
    "            c_map = sns.color_palette('tab10', 10)\n",
    "\n",
    "            ax.plot(XGB_Optim.cv_results_['param_n_estimators'], [s*100 for s in XGB_Optim.cv_results_['mean_test_score']])\n",
    "            ax.set_ylabel('XGBoost CV Mean Accuracy (%)', fontsize=15) # Set the y_label and size\n",
    "            ax.set_xlabel(param_to_plot, fontsize=15)\n",
    "            ax.set_title('XGBoost', fontsize=18) # Set the title and size\n",
    "            ax.set_ylim([30,101]) # Set the limits on the y axis\n",
    "\n",
    "            #f.suptitle('Optimization of the number of trees')\n",
    "            ax.legend(fontsize=15) # Set the legend and size\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4929adf0",
   "metadata": {},
   "source": [
    "### Fitting the XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e63978",
   "metadata": {},
   "source": [
    "You may add more parameters to the function as `**kwargs`.\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96819b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    n_estimators = 200\n",
    "\n",
    "    XGB_results = metsta.XGB_model(treated_data, target, # Data and labels\n",
    "                    regres=regression, obj=objective, # Regression or classification, and objective function\n",
    "                    return_cv=True, iter_num=5, # If you want cross validation results and number of iterations for it\n",
    "                    n_estimators=n_estimators, # Number of trees in the model\n",
    "                    cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "                    #metrics = ('neg_mean_squared_error', 'r2'), subsample=0.7)\n",
    "                    # Choose the performance metrics\n",
    "                    metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted'))\n",
    "                    # gamma=0, min_child_weight=0.9, subsample=0.4),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e774c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "    for k,v in XGB_results.items():\n",
    "        if k != 'model' and k != 'imp_feat':\n",
    "            results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "    print(results_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05427ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    imp_feats_xgb = meta_data.copy()\n",
    "    imp_feats_xgb.insert(0,'Bucket label', imp_feats_xgb.index)\n",
    "    imp_feats_xgb.insert(1,'Feature Importance', '')\n",
    "    for n in range(len(XGB_results['imp_feat'])):\n",
    "        imp_feats_xgb['Feature Importance'].iloc[XGB_results['imp_feat'][n][0]] = XGB_results['imp_feat'][n][1]\n",
    "    imp_feats_xgb = imp_feats_xgb.sort_values(by='Feature Importance', ascending=False)\n",
    "    imp_feats_xgb.index = range(1, len(imp_feats_xgb)+1)\n",
    "else:\n",
    "    imp_feats_xgb = 'XGBoost analysis was not performed'\n",
    "imp_feats_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908fe4d",
   "metadata": {},
   "source": [
    "### XGBoost Permutation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE=False\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random permutator)\n",
    "\n",
    "    perm_results_XGB = metsta.permutation_XGB(\n",
    "        treated_data, target,  # data and labels\n",
    "        regres=regression, obj=objective, # regression vs classification and objective function \n",
    "        iter_num=100, # N of permutations to do in your test - around 500 should be enough\n",
    "        n_estimators=200, # Number of trees in the model\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        metric=('accuracy')) # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ca523",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(treated_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_XGB\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='XGBoost Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('N of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('XGBoost Permutation Test', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_XGB_PermutationTest.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef2e39b",
   "metadata": {},
   "source": [
    "### ROC Curves (Receiver Operating Characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a249ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = False\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_XGB = metsta.XGB_ROC_cv(treated_data, target, # Data and target\n",
    "                                        pos_label=pos_label, obj=objective, # Positive label and objective\n",
    "                                        n_estimators=200, # Number of trees of RF\n",
    "                                        n_iter=15, # Number of iterations to repeat \n",
    "                                        cv=None, n_fold=3) # Method of CV (None is stratified cv) and the number of folds\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves \n",
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_XGB\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set(xlabel='False positive rate', ylabel='True positive rate')\n",
    "                ax.set_title('XGBoost ROC Curve', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_XGB_ROCcurve.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b39a3",
   "metadata": {},
   "source": [
    "# Step 6: Univariate Analysis and Fold-Change Analysis <a class=\"anchor\" id=\"step-6\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "In this section, both Univariate Analysis and Fold-Change analysis are performed outputting a DataFrame ordered by lowest _p_-value to highest and with the columns of Fold change and logarithmic Fold Change.\n",
    "\n",
    "The Fold change is calculated in a dataset with missing values imputed and normalized after. **This means that with our very high number of missing values in FT-ICR-MS data, it affects the calculation of the fold change a lot. Thus, take this fold changes values with a grain of salt.**\n",
    "\n",
    "Choose between the parametric **t-test** and non-parametric **Mann-Whitney test** for 2-class univariate analysis, and between **ANOVA** and **Kruskal-Wallis test** for multiclass analysis.\n",
    "\n",
    "The functions for 2-class analysis all come were adapted from the BinSim paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8738524",
   "metadata": {},
   "source": [
    "## Step 6.1: 2-class Univariate Statistical Analysis <a class=\"anchor\" id=\"step-6_1\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603b9b5",
   "metadata": {},
   "source": [
    "Choose **control** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be06d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_class = classes[0]\n",
    "control_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a801f3",
   "metadata": {},
   "source": [
    "Choose **_p_-value significancy** threshold. Usual values are: 0.05, 0.01, 0.001. If you **do not want** to filter the data based on a _p_-value threshold, make alpha=**None**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc6264",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = None\n",
    "alpha = 0.05 # If you use Mann-Whitney with low number of samples you might have to change this alpha\n",
    "# It can be the correct approach with a lot of missing values though\n",
    "# With Mann-Whitney test, there will be a set of discrete p-values as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ed380",
   "metadata": {},
   "source": [
    "Choose **Fold change** threshold value.\n",
    "\n",
    "If you want to only select from the significant features, those that have a fold change greater than X, change **abs_log2FC_threshold**. This value is in **log 2 of the absolute fold change**. For example, if you want to only consider features that have a fold change greater than 2-fold (2 or 0.5), then the abs_log2FC_threshold should be 1. If you want it to be greater than 3-fold, the threshold should be np.log2(3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3211c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_log2FC_threshold = 1 # As a default, I will choose not to perform this step\n",
    "# Example for 2-fold threshold: abs_log2FC_threshold = 1 or np.log2(2)\n",
    "# Example for 3-fold threshold: abs_log2FC_threshold = np.log2(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9692c69f",
   "metadata": {},
   "source": [
    "**Perform Univariate Analysis**\n",
    "\n",
    "If you have more than 2 classes, the pre-treatment must be equal to the pre-treatment made in step 2, thus we use the same variables as before (hence the importance of choosing the pre-treatment by the variables and not in the function itself in step 2.\n",
    "\n",
    "If the filtering chosen is `total_samples` and the filt_kw is greater than 1, that is, a minimum number of samples to appear in the dataset, that number is transformed to represent the same percentage of samples in the smaller subsection of data of only the control and test classes. E.g. if the minimum n of samples a feature must appear in a 15-sample dataset is 4, then by performing univariate analysis between 2 classes on a 6-sample subset, the minimum n of samples allowed is (4/15) * 6 = 1.6 rounded up, that is, it has to appear in at least 2 of that 6 sample-subset (and 4 samples of the original 15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "useMW = False # Consider variance between groups as equal\n",
    "equal_var = True # Use Mann-Whitney Test or standard T-test\n",
    "\n",
    "if len(classes) == 2:\n",
    "    test_class = [cl for cl in classes if cl != control_class][0]\n",
    "    # Perform Univariate Analysis\n",
    "    univariate_results = metsta.compute_FC_pvalues_2groups(normalized=univariate_data, # Used for Fold-Change Computation\n",
    "                                  processed=treated_data, # Used for p-value computation\n",
    "                                  labels=target, # Labels of the samples\n",
    "                                  control_class=control_class, # Control class\n",
    "                                  test_class=test_class, # Non-control class\n",
    "                                  equal_var=equal_var, # Consider variance between groups as equal\n",
    "                                  useMW=useMW) # Use Mann-Whitney Test or standard T-test\n",
    "    \n",
    "    # Select only Features considered significative\n",
    "    if alpha:\n",
    "        filt_uni_results = univariate_results[univariate_results['FDR adjusted p-value'] < alpha].copy()\n",
    "    else:\n",
    "        filt_uni_results = univariate_results.copy()\n",
    "    \n",
    "    # Select features that have an absolute fold change (in log2) greater than abs_log2FC_threshold\n",
    "    if abs_log2FC_threshold:\n",
    "        # Calculate absolute Log2 Fold-Change\n",
    "        filt_uni_results['abs_log2FC'] = abs(filt_uni_results['log2FC'])\n",
    "        # Select\n",
    "        filt_uni_results = filt_uni_results[filt_uni_results['abs_log2FC'] > abs_log2FC_threshold]\n",
    "        filt_uni_results = filt_uni_results.drop(columns='abs_log2FC')\n",
    "        \n",
    "    print('Univariate Analysis Done.')\n",
    "\n",
    "# More than 2 classes\n",
    "else:\n",
    "    test_classes = [cl for cl in classes if cl != control_class]\n",
    "    univariate_results = {}\n",
    "    filt_uni_results = {}\n",
    "    univariate_df = {}\n",
    "\n",
    "    for test_class in test_classes: # For each non-control class\n",
    "        # Select only the samples of the control and current test class\n",
    "        selection = [i in [control_class, test_class] for i in target]\n",
    "        target_temp = list(np.array(target)[selection])\n",
    "        \n",
    "        file_temp = annotated_data[sample_cols].copy()\n",
    "        file_temp = file_temp.loc[:, selection]\n",
    "\n",
    "        # Perform the same filtering and pre-treatments steps but using only the control and test class samples\n",
    "\n",
    "        # Transform the filt_kw if needed to match the filtering done above (as explained in the markdown cell above)\n",
    "        if filt_method == 'total_samples':\n",
    "            # Adapting the filt_kw to a smaller subset of samples\n",
    "            # Use % of the original filtering used to calculate the equivalent number of samples in subset and round UP\n",
    "            # Possible Issue - since we already used the filtered dataset (because it has annotations and de-duplications),\n",
    "            # the data filtering with 'total_samples' is not perfect - a feature must pass this data filtering but also\n",
    "            # the original data filtering made\n",
    "            if filt_kw > 1:\n",
    "                f_kw = math.ceil(filt_kw/len(sample_cols)*sum(selection))\n",
    "            else:\n",
    "                f_kw = filt_kw\n",
    "        else:\n",
    "            f_kw = filt_kw\n",
    "\n",
    "        t_data,_,filt_data,_,_ = metsta.filtering_pretreatment(\n",
    "                          file_temp, list(np.array(target)[selection]), file_temp.columns,\n",
    "           #### Everything here must be the same as in step 2 except the f_kw as explained above\n",
    "                          filt_method, f_kw, extra_filt, mvi, mvi_kw, norm, norm_kw, tf, tf_kw, scaling, scaling_kw)\n",
    "\n",
    "        univariate_df[test_class] = [t_data, target_temp]\n",
    "        \n",
    "        # Perform Univariate Analysis on this newly acquired data\n",
    "        univariate_results[test_class] = metsta.compute_FC_pvalues_2groups(\n",
    "                                  normalized=filt_data, # Used for Fold-Change Computation\n",
    "                                  processed=t_data, # Used for p-value computation\n",
    "                                  labels=target_temp, # Labels of the samples\n",
    "                                  control_class=control_class, # Control class\n",
    "                                  test_class=test_class, # Non-control class\n",
    "                                  equal_var=equal_var, # Consider variance between groups as equal\n",
    "                                  useMW=useMW) # Use Mann-Whitney Test if True or standard T-test if False\n",
    "        \n",
    "        # Select only Features considered significative\n",
    "        if alpha:\n",
    "            filt_uni_results[test_class] = univariate_results[test_class][univariate_results[test_class][\n",
    "                'FDR adjusted p-value'] < alpha].copy()\n",
    "        else:\n",
    "            filt_uni_results[test_class] = univariate_results[test_class].copy()\n",
    "        \n",
    "        # Select features that have an absolute fold change (in log2) greater than abs_log2FC_threshold\n",
    "        if abs_log2FC_threshold:\n",
    "            # Calculate absolute Log2 Fold-Change\n",
    "            filt_uni_results[test_class]['abs_log2FC'] = abs(filt_uni_results[test_class]['log2FC'])\n",
    "            # Select\n",
    "            filt_uni_results[test_class] = filt_uni_results[test_class][\n",
    "                filt_uni_results[test_class]['abs_log2FC'] > abs_log2FC_threshold]\n",
    "            filt_uni_results[test_class] = filt_uni_results[test_class].drop(columns='abs_log2FC')\n",
    "\n",
    "        print(f'Univariate Analysis {test_class} vs. {control_class} Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3508a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the meta data of each feature\n",
    "temp_meta_data = meta_data[[i for i in meta_data.columns if i not in ['Neutral Mass', 'Probable m/z', 'm/z']]]\n",
    "\n",
    "# If you have 2 classes\n",
    "if len(classes) == 2:\n",
    "    filt_uni_results = pd.concat((filt_uni_results, temp_meta_data.loc[filt_uni_results.index]), axis=1)\n",
    "\n",
    "# More than 2 classes\n",
    "else:\n",
    "    for test_class in filt_uni_results.keys():\n",
    "        filt_uni_results[test_class] = pd.concat((filt_uni_results[test_class], temp_meta_data.loc[\n",
    "            filt_uni_results[test_class].index]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe907cc",
   "metadata": {},
   "source": [
    "Get the results in an Excel if you want to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52683020",
   "metadata": {},
   "outputs": [],
   "source": [
    "Univariate_Excel = False # Change to True to have the Excels\n",
    "if Univariate_Excel:\n",
    "    if len(classes) == 2:\n",
    "        filt_uni_results.to_excel(f'UniAnalysis_pvalue{alpha}_log2FC{abs_log2FC_threshold}.xlsx')\n",
    "    else:\n",
    "        for i in filt_uni_results:\n",
    "            filt_uni_results[i].to_excel(f'UniAnalysis_class{i}_pvalue{alpha}_log2FC{abs_log2FC_threshold}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a6f37",
   "metadata": {},
   "source": [
    "### Example Results (for more than 2 classes, a random class was chosen)\n",
    "\n",
    "**This is usually just useful for 2 classes, we will leave here the visualizations for more than 2 classes as an example.**\n",
    "\n",
    "The first four columns have the results of the univariate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec1229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(classes) == 2:\n",
    "    example_results = filt_uni_results\n",
    "    example_heatmap = treated_data\n",
    "    example_target = target\n",
    "    example_nonfilt_res = univariate_results\n",
    "else:\n",
    "    example_results = filt_uni_results[test_classes[0]]\n",
    "    example_heatmap = univariate_df[test_classes[0]][0]\n",
    "    example_target = univariate_df[test_classes[0]][1]\n",
    "    example_nonfilt_res = univariate_results[test_classes[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d8439f",
   "metadata": {},
   "source": [
    "See results ordered by **_p_-value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a81f21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example_results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6071b",
   "metadata": {},
   "source": [
    "See biggest fold changes from the test class in relation to the control class (1st cell) and vice-versa (2nd cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4438292",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_results.sort_values(by='log2FC', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ac777",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_results.sort_values(by='log2FC', ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb042e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_nonfilt_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e1b67b",
   "metadata": {},
   "source": [
    "**Heatmap** of the example shown considering only the significant features from the univariate analysis (can be better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb58514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple heatmap comparing intensities in treated_data\n",
    "f, ax = plt.subplots(1,1, figsize=(5, 7), constrained_layout=True) # Set figure size\n",
    "sns.heatmap(example_heatmap.T.loc[example_results.index],\n",
    "            cmap='RdBu_r', # Select colormap to use\n",
    "            vmin=-3, vmax=3) # Adjust minimum and maximum values in the Heatmap colorbar\n",
    "ax.tick_params(left=False)\n",
    "ax.set_yticklabels('')\n",
    "ax.set_ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4adef4",
   "metadata": {},
   "source": [
    "**Volcano Plot** of the example shown considering only the significant features from the univariate analysis\n",
    "\n",
    "**Much more useful when there are only 2 classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize=(7, 6), constrained_layout=True) # Set figure size\n",
    "\n",
    "alpha # Threshold used for p-values\n",
    "abs_log2FC_threshold # Threshold used for fold changes\n",
    "\n",
    "non_sig_feat_color = 'silver'\n",
    "reduced_sig_color = 'deepskyblue'\n",
    "increased_sig_color = 'lightcoral'\n",
    "\n",
    "non_sig_feats = []\n",
    "increased_sig_feats = []\n",
    "reduced_sig_feats = []\n",
    "for i in example_nonfilt_res.index:\n",
    "    if i not in example_results.index:\n",
    "        non_sig_feats.append(i)\n",
    "    elif example_nonfilt_res.loc[i, 'log2FC'] < 0:\n",
    "        reduced_sig_feats.append(i)\n",
    "    else:\n",
    "        increased_sig_feats.append(i)\n",
    "\n",
    "ax.scatter(example_nonfilt_res.loc[non_sig_feats, 'log2FC'], \n",
    "           -np.log10(example_nonfilt_res.loc[non_sig_feats, 'FDR adjusted p-value']),\n",
    "           c=non_sig_feat_color, alpha=0.7, label='Non-Significant')\n",
    "ax.scatter(example_nonfilt_res.loc[reduced_sig_feats, 'log2FC'], \n",
    "            -np.log10(example_nonfilt_res.loc[reduced_sig_feats, 'FDR adjusted p-value']),\n",
    "            c=reduced_sig_color, alpha=0.7, label='Downregulated')\n",
    "ax.scatter(example_nonfilt_res.loc[increased_sig_feats, 'log2FC'], \n",
    "            -np.log10(example_nonfilt_res.loc[increased_sig_feats, 'FDR adjusted p-value']),\n",
    "            c=increased_sig_color, alpha=0.7, label='Upregulated')\n",
    "\n",
    "ax.axhline(-np.log10(alpha), color='black', linestyle='--')\n",
    "if abs_log2FC_threshold != None:\n",
    "    ax.axvline(abs_log2FC_threshold, color='black', linestyle='--')\n",
    "    ax.axvline(-abs_log2FC_threshold, color='black', linestyle='--')\n",
    "\n",
    "ax.set_ylabel('- log$_1$$_0$(Adjusted (Benjamini-Hochberg) p-value)', fontsize=14)\n",
    "t_class = pd.unique(example_target)[pd.unique(example_target) != control_class][0]\n",
    "ax.set_xlabel(f'log$_2$(Fold Change))', fontsize=14)\n",
    "ax.set_title(f'Volcano Plot - {t_class}/{control_class}', fontsize=18)\n",
    "ax.legend(fontsize=12, bbox_to_anchor=(1,1))\n",
    "#f.savefig('Name_UniAnalysis_VolcanoPlot.jpg', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0062bdff",
   "metadata": {},
   "source": [
    "## Step 6.2: Multi-class Univariate Statistical Analysis <a class=\"anchor\" id=\"step-6_2\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33202049",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(classes) == 2:\n",
    "    multiclass_univariate_results = pd.DataFrame(columns=['FDR adjusted p-value',])\n",
    "else:\n",
    "    multiclass_univariate_results = metsta.compute_pvalues_multiple_groups(treated_data, groups, \n",
    "                                            useKW=False) # Choose if you want to use Kruskal-Wallis test (non-parametric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_univariate_results.sort_values(by='FDR adjusted p-value').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f374f955",
   "metadata": {},
   "source": [
    "If you want to export the entire table as an excel, run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d923c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiclass_univariate_results.to_excel('multiclass_univariate_results.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291bfdbf",
   "metadata": {},
   "source": [
    "# Step 7: Make Van Krevelen Diagrams, Kendrick Mass Defect Plots and Chemical Composition series for your samples <a class=\"anchor\" id=\"step-7\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f98065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  If you a previous formula annotation and/or our formula assignment, do you also want to use formulas from the\n",
    "# annotations?\n",
    "include_other_formula_cols = False\n",
    "\n",
    "if len(prev_formula_cols) > 0 or perform_formula_assignment:\n",
    "    formula_subset = []\n",
    "    for col in prev_formula_cols + [form_col, ]:\n",
    "        if col in processed_data.columns:\n",
    "            formula_subset.append(col)\n",
    "    if include_other_formula_cols:\n",
    "        formula_subset.extend(meta_cols_formulas)\n",
    "else:\n",
    "    formula_subset = meta_cols_formulas\n",
    "print(formula_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34646d",
   "metadata": {},
   "source": [
    "**Van Krevelen Plots**\n",
    "\n",
    "See the options for **color_dots_by** in the beginning of the next cell.\n",
    "\n",
    "This section plots a Van Krevelen Plot for each of the classes under analysis. This is made by only considering metabolites\n",
    "(features) that appear at least in one sample of said class. Only metabolites with assigned formulas are considered and the columns with formulas considered were chosen in the previous cell (**Note: you HAVE to select at least one annotation**). **If multiple formulas can be assigned to a metabolite whether within the same database annotation or different, they are both considered and plotted in the Van Krevelen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e57b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Van Krevelen Diagrams\n",
    "color_dots_by = 'Rank' # Other option 'logInt'\n",
    "# Van Krevelen points (peaks) are coloured based on their average intensity\n",
    "# Rank - colored by the rank of their average intensity compared to others\n",
    "# logInt - colored by the logarithm of their averaged intensity compared to others\n",
    "\n",
    "midpoint = 0.75 # Marks the point where the color passes from the low intensity color to the high intensity\n",
    "# 0.75 means 75% of points will be coloured with the low intensity color (stronger the lesser the intensity)\n",
    "\n",
    "for g in group_dfs:\n",
    "    # Calculating H/C and O/C ratios\n",
    "    forms = group_dfs[g].dropna(subset=formula_subset, how='all')\n",
    "    elems = create_element_counts(forms, formula_subset=formula_subset)\n",
    "\n",
    "    f, ax = plt.subplots(1,1, figsize=(6,6)) # Setting axes for the figs\n",
    "    \n",
    "    # Make the vector that will govern the colour of the plots\n",
    "    if color_dots_by == 'Rank':\n",
    "        c = univariate_data[elems.index].loc[np.array(target) == g].mean().rank(ascending=False)\n",
    "        slope_midpoint = midpoint*len(univariate_data[elems.index].columns)\n",
    "    elif color_dots_by == 'logInt':\n",
    "        c = np.log(univariate_data[elems.index].loc[np.array(target) == g].mean())\n",
    "        slope_midpoint = c.sort_values().iloc[int(midpoint*len(elems.index))]\n",
    "    \n",
    "    if formula_subset == 'Formula':\n",
    "        y = elems['H/C'].loc[c.index]\n",
    "        x = elems['O/C'].loc[c.index]\n",
    "    else:\n",
    "        y = elems['H/C']\n",
    "        x = elems['O/C']\n",
    "    \n",
    "    plt.scatter(x, y, s=3, c=c, cmap='bwr', norm=TwoSlopeNorm(slope_midpoint))\n",
    "    plt.xlabel('O/C', fontsize=20)\n",
    "    plt.ylabel('H/C', fontsize=20)\n",
    "    ax.margins(y=.1)\n",
    "    ax.set_ylim([0.15,2.01])\n",
    "    ax.set_xlim([-0.1,2.01])\n",
    "    plt.colorbar()\n",
    "    # Hide the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_title(g, fontsize=20)\n",
    "    \n",
    "    \n",
    "    #f, ax = plt.subplots(1,1, figsize=(8,8)) # Setting axes for the figs\n",
    "    #plt.title(g, fontsize=20)\n",
    "    \n",
    "    #f.savefig('Name_VKplot_' + g + '.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc862a",
   "metadata": {},
   "source": [
    "**Kendrick Mass Defect Plots**\n",
    "\n",
    "See the options for **rounding** in the beginning of the next cell.\n",
    "\n",
    "On cases where you have **multiple formulas belonging to different chemical composition series assigned to the same _m/z_ peak**, points are marked as Ambiguous (Amb.) which has the same colour as 'No Formula Assigned' (No Form.).\n",
    "\n",
    "#### Important Note: If your indexes were not Neutral Masses, then the figures below do not use Neutral Masses to calculate and Plot Kendrick Mass Defect and Nominal Masses. Thus, they do not represent 'True' Kendrick Mass Defect Plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a51d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rounding = 'up' # 'up' or 'nearest' - how Kendrick Nominal Mass is obtained by rounding up or to the nearest integer\n",
    "\n",
    "# Put these two lines instead of the current if you want to try to put them all in the same fig, you have to adjust things\n",
    "# for that to take into especially how many panels you need (right now it is (2,3) that is 2*3=6) and the figsize.\n",
    "#f, axs = plt.subplots(2,3, figsize=(16,12))\n",
    "#for g, ax in zip(group_dfs, axs.ravel()):\n",
    "for g in group_dfs:\n",
    "    f, ax = plt.subplots(1,1, figsize=(7,6), constrained_layout=True) # Setting axes for the figs\n",
    "    \n",
    "    # Getting the classes each formula has\n",
    "    forms = group_dfs[g].dropna(subset=formula_subset, how='all')\n",
    "    elems = create_element_counts(forms, formula_subset=formula_subset)\n",
    "    \n",
    "    l = []\n",
    "    n_form_per_peak = pd.Series(elems.index).value_counts()\n",
    "\n",
    "    for i in group_dfs[g].index: # For each peak to consider\n",
    "        # If it has formula assigned by the formula columns selected\n",
    "        if i in elems.index:\n",
    "            # See if it has more than one formula\n",
    "            if n_form_per_peak.loc[i] > 1:\n",
    "                # If it has, see if they belong to the same class series or not\n",
    "                cl = set(elems.loc[i, 'Series'])\n",
    "                if len(cl) == 1: # If yes assign it\n",
    "                    l.append(elems.loc[i, 'Series'].iloc[0])\n",
    "                else: # If not, say it is Ambiguous\n",
    "                    l.append('No Form. / Amb.')\n",
    "\n",
    "            # In case it only has one formula\n",
    "            else:\n",
    "                l.append(elems['Series'].loc[i])\n",
    "\n",
    "        # If it has not formula assigned by the formula columns selected\n",
    "        else:\n",
    "            l.append('No Form. / Amb.')\n",
    "    classes_series = ['CHO', 'CHOS', 'CHON', 'CHNS', 'CHONS', 'CHOP', 'CHONP','CHONSP', 'other', 'No Form. / Amb.']\n",
    "    dict_col = {lbl: c for lbl, c in zip(classes_series, sns.color_palette('tab10', len(classes_series)))}\n",
    "    list_col = np.array([dict_col[i] for i in l])\n",
    "    \n",
    "    # Calculate points for the scatter plot, choose if rounding shouls happen to the nearest        \n",
    "    nominal, fraction = metsta.calc_kmd(group_dfs[g], rounding=rounding, neutral_mass_col=mass_val_col)\n",
    "\n",
    "    # Scatter plot\n",
    "    for cl in classes_series:\n",
    "        n = np.array(nominal)[np.array(l) == cl]\n",
    "        f = np.array(fraction)[np.array(l) == cl]\n",
    "        lc = list_col[np.array(l) == cl]\n",
    "        scatter = ax.scatter(n,f, s=6, c=lc, label=cl)\n",
    "\n",
    "    if idx_masses == 'Neutral':\n",
    "        ax.set_xlabel('Kendrick Nominal Mass', fontsize=18) # Set X axis label\n",
    "        ax.set_ylabel('Kendrick Mass Defect', fontsize=18) # Set Y axis label\n",
    "    else:\n",
    "        ax.set_xlabel('Kendrick Nominal Mass (for m/z peak)', fontsize=18) # Set X axis label\n",
    "        ax.set_ylabel('Kendrick Mass Defect (for m/z peak)', fontsize=18) # Set Y axis label\n",
    "    ax.set_xlim([0,1250])\n",
    "    ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1,1)) # Set legend\n",
    "    ax.set_title(g, fontsize= 20) # Set title\n",
    "    \n",
    "    #f.savefig('Name_KMDplot_' + g + '.jpg', dpi=400) # Save the figure\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b5b53",
   "metadata": {},
   "source": [
    "**Chemical Composition Series**\n",
    "\n",
    "**If multiple formulas are assigned to the same _m/z_ peak**, whether within the same formula annotation or between different annotations, **each one will be counted in this plot**. That is, if a peak in a class has 3 possible candidate formulas, 2 belonging to the 'CHO' series and another to the 'CHOP' series; then 2 formulas will be added to the 'CHO' series and 1 to the 'CHOP' series. Thus, we are considering that the 3 elementary formulas are represented by that peak (probably an overestimation). In all cases, it is rare to find multiple candidate formulas for the same m/z peak, especially with extreme-resolution data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5848b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_composition_series(group_dfs,\n",
    "                            series_order=('CHO', 'CHOS', 'CHON', 'CHNS', 'CHONS', 'CHOP', 'CHONP','CHONSP', 'other'),\n",
    "                            formula_col=formula_subset,\n",
    "                            label_colours=label_colours,\n",
    "                            ax=None):\n",
    "    # Chemical compostition series\n",
    "    bar_number = len(group_dfs)\n",
    "    curr_num = - len(group_dfs)/2 + 0.5\n",
    "    width = 0.8/bar_number - 0.05\n",
    "    series = pd.DataFrame()\n",
    "    \n",
    "    for g in group_dfs:\n",
    "        forms = group_dfs[g].dropna(subset=formula_subset, how='all')\n",
    "        elems = create_element_counts(forms, formula_subset=formula_subset)\n",
    "        #print('This is the chemical composition Series for', g, ':\\n')\n",
    "    \n",
    "        counts = elems['Series'].value_counts().reindex(series_order)\n",
    "        series[g] = counts # Store the counts\n",
    "        x = np.arange(len(counts))  # the label locations\n",
    "        ax.barh(x+(width+0.05)*curr_num, counts, width, label=g, color=label_colours[g])\n",
    "        curr_num = curr_num + 1\n",
    "    ax.set_yticks(x)\n",
    "    ax.set_yticklabels(counts.index)\n",
    "    ax.set_xlabel('N of Formulas', fontsize = 15)\n",
    "    ax.set_title('Chemical Composition Series', fontsize=15)\n",
    "    plt.grid(zorder=0)\n",
    "    plt.legend()\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize=(9,6)) # Setting axes for the figs\n",
    "chem_comp_series = plot_composition_series(group_dfs, ax=ax,label_colours=label_colours,)\n",
    "#f.savefig('Name_CCSeries.jpg', dpi=400) # Save the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45896056",
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_comp_series.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a68f5",
   "metadata": {},
   "source": [
    "#### PCA of chemical composition series per sample with Loading arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the chemical composition series for each samples\n",
    "series = pd.DataFrame()\n",
    "series_order=('CHO', 'CHOS', 'CHON', 'CHNS', 'CHONS', 'CHOP', 'CHONP','CHONSP', 'other')\n",
    "for sample in sample_cols:\n",
    "    forms = processed_data.dropna(subset=sample).dropna(subset=formula_subset, how='all')\n",
    "    elems = create_element_counts(forms, formula_subset=formula_subset)\n",
    "\n",
    "    counts = elems['Series'].value_counts().reindex(series_order)\n",
    "    series[sample] = counts # Store the counts\n",
    "series = series.replace({np.nan:0})\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8870c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA_loading_arrows(series, principaldf, loadings, var_exp,\n",
    "                            n_components, top_features=None, method='top_variance', ax=None):\n",
    "    \"\"\"Draw Loading arrows of top n features.\n",
    "     \n",
    "     Based on idea and taken from St. Ovf. thread (Qiyun Zhu answer).\n",
    "     https://stackoverflow.com/questions/39216897/plot-pca-loadings-and-loading-in-biplot-in-sklearn-like-rs-autoplot.\"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    # Taken from Stack Overflow\n",
    "    if top_features:\n",
    "        # Method 1: Find top arrows that appear the longest (i.e., furthest from the origin) in the visible plot\n",
    "        if method == 'top_longest':\n",
    "            tops = (loadings ** 2).sum(axis=1).argsort()[-top_features:]\n",
    "            loadings_to_plot = loadings[tops]\n",
    "            idxs = np.array(series.index)[tops]\n",
    "\n",
    "        # Method 2: Find top features that drive most variance in the visible PCs:\n",
    "        elif method == 'top_variance':\n",
    "            tops = (np.abs(loadings) * var_exp).sum(axis=1).argsort()[-top_features:]\n",
    "            loadings_to_plot = loadings[tops]\n",
    "            idxs = np.array(series.index)[tops]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Method is not accepted. It should be one of \"top_longest\" or \"top_variance\".')\n",
    "            \n",
    "        # Scale the loadings so they are easier to interpret since their absolute values have no grand meaning\n",
    "        loadings_to_plot /= np.sqrt((loadings_to_plot ** 2).sum(axis=0))\n",
    "        loadings_to_plot = loadings_to_plot * np.array(np.abs(principaldf.iloc[:,:n_components]).max(axis=0))\n",
    "\n",
    "        # Empirical formula to determine arrow width (according to St. Ovf. Answer)\n",
    "        width = -0.005 * np.min([np.subtract(*plt.xlim()), np.subtract(*plt.ylim())])\n",
    "            \n",
    "        # Draw arrows\n",
    "        for arrow in range(top_features):\n",
    "            ax.arrow(0,0, loadings_to_plot[arrow,0], loadings_to_plot[arrow,1], alpha=0.7, ec='none', width=width,\n",
    "                     color='grey', length_includes_head=True)\n",
    "            ax.text(loadings_to_plot[arrow,0]*1.04, loadings_to_plot[arrow,1]*1.04, idxs[arrow],\n",
    "                     ha='center', va='center')\n",
    "        return\n",
    "    \n",
    "    # Scale the loadings so they are easier to interpret sicne their absolute values have no grand meaning\n",
    "    loadings_to_plot = loadings * np.array(np.abs(principaldf.iloc[:,:n_components]).max(axis=0))\n",
    "    \n",
    "    # Empirical formula to determine arrow width (according to St. Ovf. Answer) but thinner\n",
    "    width = -0.005 * np.min([np.subtract(*plt.xlim()), np.subtract(*plt.ylim())])\n",
    "    \n",
    "    # Draw arrows\n",
    "    for arrow in range(len(series)):\n",
    "        ax.arrow(0,0, loadings_to_plot[arrow,0], loadings_to_plot[arrow,1], alpha=0.7, ec='none', width=width,\n",
    "                 color='grey', length_includes_head=True)\n",
    "        ax.text(loadings_to_plot[arrow,0]*1.04, loadings_to_plot[arrow,1]*1.04, series.index[arrow],\n",
    "                 ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3226a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating PCA\n",
    "n_components = 2 # Select number of components to calculate\n",
    "principaldf, var, loadings = metsta.compute_df_with_PCs_VE_loadings(transf.pareto_scale(series.T), \n",
    "                                       n_components=n_components, # Select number of components to calculate\n",
    "                                       whiten=True, labels=target, return_var_ratios_and_loadings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(6,6)) # Change the size of the figure\n",
    "# Plot PCA\n",
    "ax.axis('equal')\n",
    "lcolors = label_colours\n",
    "\n",
    "metsta.plot_PCA(principaldf, lcolors, \n",
    "         components=(1,2), # Select components to see\n",
    "         title='', # Select title of plot\n",
    "         ax=ax)\n",
    "\n",
    "# Remove ellipses by putting a # before the next line\n",
    "metsta.plot_ellipses_PCA(principaldf, \n",
    "                  lcolors, \n",
    "                  components=(1,2), # Select components to see\n",
    "                  ax=ax, \n",
    "                  q=0.95) # Confidence ellipse with 95% (q) confidence\n",
    "\n",
    "# Putting loading arrows\n",
    "plot_PCA_loading_arrows(series, principaldf, loadings, var, n_components, top_features=None, ax=ax)\n",
    "\n",
    "ax.set_xlabel(f'PC 1 ({var[0] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "ax.set_ylabel(f'PC 2 ({var[1] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "\n",
    "plt.legend(fontsize=15, loc='upper left', bbox_to_anchor=(1,1)) # Set the size of labels\n",
    "#plt.grid() # If you want a grid or not\n",
    "plt.show()\n",
    "#f.savefig('Name_CCS_PCAplot.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069fc58",
   "metadata": {},
   "source": [
    "# Step 8: Pathways Assignment of HMDB Annotated Metabolites <a class=\"anchor\" id=\"step-8\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "This section reads a pathways database built with the Ramp software tool (https://academic.oup.com/bioinformatics/article/39/1/btac726/6827287) to use as a base to assign the pathways each compound belongs to.\n",
    "\n",
    "**It only works with HMDB identifiers and HMDB annotated compounds.**\n",
    "\n",
    "The result is a DataFrame where the index is each HMDB identifier in the `Matched IDs` columns of your data and the two columns represent the assigned pathways and corresponding IDs from the different databases RampID uses plus an extra column with the corresponding HMDB metabolite name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8e588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pathway database into a DataFrame\n",
    "with open('RAMP_ID_pathways_improved.pickle', 'rb') as handle:\n",
    "    pathways_db = pickle.load(handle)\n",
    "pathways_db = pathways_db[['HMDB Name', 'Pathway Name', 'Pathway ID']]\n",
    "met_per_path = pathways_db.explode(['Pathway Name', 'Pathway ID'])['Pathway ID'].value_counts()\n",
    "pathways_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f6a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pathways assignment\n",
    "pathways_assignment_idx = []\n",
    "pathways_assignment_name = []\n",
    "pathways_assignment_masses = []\n",
    "if 'Matched IDs' in processed_data.columns:\n",
    "    for i in processed_data['Matched IDs'].dropna().index:\n",
    "        for hmdb_id in range(len(processed_data.loc[i, 'Matched IDs'])):\n",
    "            if processed_data.loc[i, 'Matched IDs'][hmdb_id] in pathways_assignment_idx:\n",
    "                continue\n",
    "            else:\n",
    "                pathways_assignment_idx.append(processed_data.loc[i, 'Matched IDs'][hmdb_id])\n",
    "                pathways_assignment_name.append(processed_data.loc[i, 'Matched names'][hmdb_id])\n",
    "                pathways_assignment_masses.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1cd629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pathways assignment dataframe\n",
    "pathways_assignment = pd.DataFrame(index=pathways_assignment_idx, columns=['Pathway Name', 'Pathway ID'])\n",
    "if 'Matched IDs' in processed_data.columns:\n",
    "    for i in pathways_assignment.index:\n",
    "        if i in pathways_db.index:\n",
    "            pathways_assignment.loc[i] = pathways_db.loc[i]\n",
    "    pathways_assignment['Matched names'] = pathways_assignment_name\n",
    "    pathways_assignment['indexes'] = pathways_assignment_masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5598a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See full pathways assignment dataframe\n",
    "pathways_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c40882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See only the HMDB that led to pathway assignments\n",
    "pathways_assignment.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a07d1",
   "metadata": {},
   "source": [
    "Select chosen list of HMDB you want to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141abd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_hmdbs = ['HMDB0000045', 'HMDB0009947', 'HMDB0000001']\n",
    "\n",
    "filtered_chosen_hmdbs = []\n",
    "for i in chosen_hmdbs:\n",
    "    if i not in pathways_assignment.index:\n",
    "        print(f'{i} was not annotated for the currently analysed data and is thus not in the pathway assignment DataFrame.')\n",
    "    else:\n",
    "        filtered_chosen_hmdbs.append(i)\n",
    "\n",
    "pathways_assignment.loc[filtered_chosen_hmdbs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301af0d",
   "metadata": {},
   "source": [
    "## Step 8.1: Pathway Over-Representation Analysis <a class=\"anchor\" id=\"step-8_1\"></a>\n",
    "\n",
    "Quick Pathways Over-Representation Analysis considering Feature Occurrence Data and matched to the HMDB database.\n",
    "\n",
    "By this methodology, very general pathways with more metabolites such as 'Metabolism' or 'Biochemical pathways: part I' or 'Transport of small molecules' have a good chance of appearing as significant. We recommend you look more carefully to more specific pathways.\n",
    "\n",
    "Furthermore, our background set is so large, that most metabolic pathways will appear as significant by 'common p-values' even after multiple testing correction. Thus, pathways with multiple metabolites annotated that constitute a decent part of the pathway should be looked at more carefully.\n",
    "\n",
    "Furthermore, each mass can have multiple annotations and those annotations could correspond to metabolites in the same pathway. Thus, it is possible that a good portion of detected metabolites in a pathway could correspond to a single metabolic feature, which would diminish the importance of that pathway. So, analysis of the relevant pathways should be performed. For each pathway (and each class), a corresponding DataFrame of the relevant metabolic features associated will be created.\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce098442",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_metabolites_for_pathway = 3 # Get the minimum number of HMDB compounds (in DB) in a pathway to consider it for analysis\n",
    "min_pathway_data_ann_metabolites_found = 2 # Get the min. n of detected met. in a pathway to consider it for analysis\n",
    "\n",
    "# Count the number of HMDB metabolites in the pathway databases.\n",
    "pathways_counts = pathways_db.explode('Pathway ID')[\n",
    "    'Pathway ID'].reset_index().drop_duplicates().set_index('index')['Pathway ID'].value_counts()\n",
    "pathways_counts = pathways_counts[pathways_counts >= min_metabolites_for_pathway]\n",
    "pathways_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73164517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain for each mass associated pathways\n",
    "# Pathways that appear for multipel compounds annotated to the same peak only count as 1\n",
    "path_per_mass = pathways_assignment.dropna().explode(['Pathway Name', 'Pathway ID']).reset_index()[\n",
    "        ['Pathway Name', 'Pathway ID', 'indexes']].drop_duplicates()\n",
    "\n",
    "# See pathways with at least min_pathway_data_ann_metabolites_found metabolites detected in the dataset\n",
    "seen_paths = path_per_mass['Pathway ID'].value_counts()[\n",
    "    path_per_mass['Pathway ID'].value_counts()>=min_pathway_data_ann_metabolites_found].index\n",
    "\n",
    "keep_idx = []\n",
    "for i in path_per_mass.index:\n",
    "    if path_per_mass.loc[i, 'Pathway ID'] in pathways_counts.index:\n",
    "        if path_per_mass.loc[i, 'Pathway ID'] in seen_paths:\n",
    "            keep_idx.append(i)\n",
    "path_per_mass = path_per_mass.loc[keep_idx]\n",
    "\n",
    "unique_masses_with_paths = pd.unique(path_per_mass['indexes'])\n",
    "print('Masses with annotated compounds with associated pathways:', len(unique_masses_with_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6760075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All HMDB metabolites with associated pathways\n",
    "keep_idxs = []\n",
    "for i in pathways_db.index:\n",
    "    for path_id in pathways_db.loc[i, 'Pathway ID']:\n",
    "        if path_id in pathways_counts.index:\n",
    "            if path_id in seen_paths:\n",
    "                keep_idxs.append(i)\n",
    "                break\n",
    "filtered_pathways_db = pathways_db.loc[keep_idxs]\n",
    "filtered_pathways_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dada8f",
   "metadata": {},
   "source": [
    "### Select Background Set\n",
    "\n",
    "For associated pathways, the pathways considered are those that with more than the `min_metabolites_for_pathway` threshold detected metabolites in the dataset.\n",
    "\n",
    "- **Det.Met** - Detected Metabolites in the Dataset with associated pathways (**Default**)\n",
    "- **All.Met** - All Metabolites in the Database with associated pathways - In progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbcb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_set = 'Det.Met'\n",
    "\n",
    "if background_set == 'Det.Met':\n",
    "    total_metabolites_with_pathways = len(unique_masses_with_paths)\n",
    "#elif background_set == 'All.Met':\n",
    "#    total_metabolites_with_pathways = len(filtered_pathways_db)\n",
    "\n",
    "else:\n",
    "    raise ValueError('background_set method used not in [\"Det.Met\", \"All.Met\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c133ab5",
   "metadata": {},
   "source": [
    "### Select Method to Identify Significant Metabolites\n",
    "\n",
    "Select through which method is desired to select the significant metabolites (`method_for_significant`) and the threshold used in each case (`threshold_for_significant`) explained next to them. The significant metabolites have to have associated at least 1 pathway. In each case it will only work if one of the methodologies has been previously ran.\n",
    "\n",
    "- **RF Gini Importance** - `threshold_for_significant` is the top % of ranks considered significant (e.g. 0.20 for 20%).\n",
    "- **PLS-DA Feat. Importance** - `threshold_for_significant` is the top % of ranks considered significant if below 1 (e.g. 0.20 for 20%) or the threshold for importance if higher that should only be used for VIP Scores (e.g. 1 for VIP scores above 1 - recommended).\n",
    "- **XGBoost Feat. Importance** - `threshold_for_significant` is the top % of ranks considered significant (e.g. 0.20 for 20%).\n",
    "- **1v1 Univariate Analysis** - `threshold_for_significant` is the maximum adjusted (for multiple test correction) _p_-value from the univariate analysis (e.g. 0.05 for adjusted _p_-values under 0.05). It also has the `test_class_spec` specific parameter to select a specific test class against your control class in case you have more than 2 classes - **Default**.\n",
    "- **Multiclass Univariate Analysis** - `threshold_for_significant` is the maximum adjusted (for multiple test correction) _p_-value from the univariate analysis (e.g. 0.05 for adjusted _p_-values under 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f836c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Parameters\n",
    "method_for_significant = 'Multiclass Univariate Analysis'\n",
    "threshold_for_significant = 0.0001\n",
    "test_class_spec = 'dGRE3' # A test class to choose\n",
    "\n",
    "\n",
    "# Get the significant metabolites with associated pathway information\n",
    "\n",
    "# RF Gini Importance\n",
    "if method_for_significant == 'RF Gini Importance':\n",
    "    sig_mets = imp_feats_rf.iloc[:int(len(imp_feats_rf) * threshold_for_significant),0].values\n",
    "    sig_mets_w_paths = [i for i in sig_mets if i in unique_masses_with_paths]\n",
    "\n",
    "# PLS-DA Feat. Importance\n",
    "if method_for_significant == 'PLS-DA Feat. Importance':\n",
    "    if threshold_for_significant < 1:\n",
    "        sig_mets = imp_feats_plsda.iloc[:int(len(imp_feats_plsda) * threshold_for_significant),0].values\n",
    "    else:\n",
    "        sig_mets = imp_feats_plsda[imp_feats_plsda.iloc[:,1] > threshold_for_significant].iloc[:, 0].values\n",
    "    sig_mets_w_paths = [i for i in sig_mets if i in unique_masses_with_paths]\n",
    "\n",
    "# XGBoost Feat. Importance\n",
    "if method_for_significant == 'XGBoost Feat. Importance':\n",
    "    if type(imp_feats_xgb) == str:\n",
    "        raise ValueError('No XGB feature importance is stored.')\n",
    "    sig_mets = imp_feats_xgb.iloc[:int(len(imp_feats_xgb) * threshold_for_significant),0].values\n",
    "    sig_mets_w_paths = [i for i in sig_mets if i in unique_masses_with_paths]\n",
    "\n",
    "# 1v1 Univariate Analysis\n",
    "if method_for_significant == '1v1 Univariate Analysis':\n",
    "    if type(univariate_results) == dict:\n",
    "        sig_mets = univariate_results[test_class_spec][\n",
    "            univariate_results[test_class_spec]['FDR adjusted p-value'] < threshold_for_significant].index\n",
    "    else:\n",
    "        sig_mets = univariate_results[univariate_results['FDR adjusted p-value'] < threshold_for_significant].index\n",
    "    sig_mets_w_paths = [i for i in sig_mets if i in unique_masses_with_paths]\n",
    "\n",
    "# Multiclass Univariate Analysis\n",
    "if method_for_significant == 'Multiclass Univariate Analysis':\n",
    "    sig_mets = multiclass_univariate_results[\n",
    "        multiclass_univariate_results['FDR adjusted p-value'] < threshold_for_significant].index\n",
    "    sig_mets_w_paths = [i for i in sig_mets if i in unique_masses_with_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b059f",
   "metadata": {},
   "source": [
    "### Pathway Enrichment Analysis with the considered parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results\n",
    "spec_path_dfs = {}\n",
    "\n",
    "# Get the counts of metabolites of each pathway\n",
    "path_metabolites = path_per_mass['Pathway ID'].value_counts()\n",
    "\n",
    "# Get the counts of sig. metabolites of each pathway\n",
    "sig_metabolites = path_per_mass.set_index('indexes').loc[sig_mets_w_paths, 'Pathway ID']\n",
    "path_sig_metabolites = sig_metabolites.value_counts()\n",
    "\n",
    "# Number of metabolites with pathways\n",
    "annotated_metabolites_w_path = len(sig_mets_w_paths)\n",
    "\n",
    "path_to_ID = pathways_assignment.explode(['Pathway Name','Pathway ID']).set_index('Pathway ID')[\n",
    "    'Pathway Name'].reset_index().drop_duplicates().set_index('Pathway ID')\n",
    "\n",
    "# Preparing DF\n",
    "over_representation_df = pd.DataFrame(columns=['Pathway Name',\n",
    "    'N of Sig. Met. in Dataset', 'N of Det. Met. in Pathway', 'N of Met. in Pathway', \n",
    "                                    '% of Met. In Set', 'Probability'], dtype='object')\n",
    "\n",
    "for pathway in tqdm(path_sig_metabolites.index):\n",
    "    # Pathway Name\n",
    "    p_name = path_to_ID.loc[pathway, 'Pathway Name']\n",
    "    # Metabolites related to the current pathway\n",
    "    total_met_in_path = path_metabolites.loc[pathway]\n",
    "    # Number of sig. metabolites related to the current pathway\n",
    "    ann_met_in_path = path_sig_metabolites.loc[pathway]\n",
    "\n",
    "    # Calculating probability to find ann_met_in_path or more metabolites in annotated_metabolites_w_path\n",
    "    prob = stats.hypergeom(M=total_metabolites_with_pathways, \n",
    "                            n=total_met_in_path, \n",
    "                            N=annotated_metabolites_w_path).sf(ann_met_in_path-1)\n",
    "\n",
    "    # Adding the line to the DF\n",
    "    over_representation_df.loc[pathway] = [p_name, ann_met_in_path, total_met_in_path, met_per_path.loc[pathway],\n",
    "                                           ann_met_in_path/total_met_in_path*100, prob]\n",
    "\n",
    "    # Getting the masss of the compounds found in the pathway\n",
    "    spec_path_dfs[pathway] = processed_data.loc[list(sig_metabolites[sig_metabolites == pathway].index)]\n",
    "\n",
    "# Sorting DataFrame from least probable to more probable and adding adjusted probability\n",
    "# with Benjamini-Hochberg multiple test correction\n",
    "over_representation_df = over_representation_df.sort_values(by='Probability')\n",
    "over_representation_df['Adjusted (BH) Probability'] = metsta.p_adjust_bh(over_representation_df['Probability'])\n",
    "over_representation_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## See the peaks with metabolites associated with a certain pathway\n",
    "\n",
    "example_pathway = over_representation_df.index[1] # Choose a pathway to see.\n",
    "\n",
    "spec_path_dfs[example_pathway]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d0e30e",
   "metadata": {},
   "source": [
    "# Step 9: KEGG Colour Mapping <a class=\"anchor\" id=\"step-9\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17511f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_colour = 'red'\n",
    "class_2_colour = 'blue'\n",
    "both_colour = 'purple'\n",
    "\n",
    "print('Present only in',classes[0]+':',class_1_colour)\n",
    "print('Present only in',classes[1]+':',class_2_colour)\n",
    "print('Present in both', class_1_colour, 'and', class_1_colour+':', both_colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cbcb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pd.unique(pd.Series(target))) == 2:\n",
    "\n",
    "    kegg_data = annotated_data.copy()\n",
    "    kegg_data = kegg_data.dropna(subset='Matched HMDB IDs')\n",
    "    kegg_data = kegg_data[sample_cols+['Matched HMDB IDs']]\n",
    "    kegg_data = kegg_data.explode('Matched HMDB IDs', ignore_index=True)\n",
    "    kegg_data['Matched KEGG'] = np.nan\n",
    "    for a in tqdm(kegg_data.index):\n",
    "        kegg_hmdb_id = kegg_data['Matched HMDB IDs'][a]\n",
    "        kegg_data['Matched KEGG'][a] = dbs['HMDB']['DB'].loc[kegg_hmdb_id]['kegg']\n",
    "    kegg_data = kegg_data.dropna(subset='Matched KEGG')\n",
    "    kegg_data['Colour'] = np.nan\n",
    "    for k in kegg_data.index:\n",
    "        k_df = kegg_data.loc[[k]]\n",
    "        if k_df[groups[classes[0]]].isnull().values.all():\n",
    "            kegg_data['Colour'][k] = class_2_colour\n",
    "        elif k_df[groups[classes[1]]].isnull().values.all():\n",
    "            kegg_data['Colour'][k] = class_1_colour\n",
    "        else:\n",
    "            kegg_data['Colour'][k] = both_colour\n",
    "    kegg_data\n",
    "else:\n",
    "    print('Your data has more than two classes. Thus, KEGG colour mapping is not performed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c75937",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_KEGG_COLOURS = True\n",
    "if len(pd.unique(pd.Series(target))) == 2:\n",
    "    kegg_colours = kegg_data[['Matched KEGG', 'Colour']]\n",
    "    kegg_colours = kegg_colours.set_index('Matched KEGG')\n",
    "    if SAVE_KEGG_COLOURS:\n",
    "        kegg_colours_filename = filename.split('.')[0]+'_kegg_colours.csv'\n",
    "        kegg_colours.to_csv(kegg_colours_filename, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bbcc2",
   "metadata": {},
   "source": [
    "# Step 10: BinSim Specific Analysis <a class=\"anchor\" id=\"step-10\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "All analyses done using BinSim\n",
    "- PCA\n",
    "- HCA\n",
    "- Random Forest\n",
    "- PLS-DA\n",
    "- XGBoost\n",
    "\n",
    "BinSim was performed as described in the BinSim paper as mentioned earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbbaaa3",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e390e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(6,6)) # Change the size of the figure\n",
    "\n",
    "n_comps = 5\n",
    "see_comps = (1,2)\n",
    "\n",
    "principaldf_BinSim, var_BinSim, loadings_BinSim = metsta.compute_df_with_PCs_VE_loadings(bin_data, \n",
    "                                       n_components=n_comps, # Select number of components to calculate\n",
    "                                       whiten=True, labels=target, return_var_ratios_and_loadings=True)\n",
    "# Plot PCA\n",
    "ax.axis('equal')\n",
    "lcolors = label_colours\n",
    "metsta.plot_PCA(principaldf_BinSim, lcolors, \n",
    "         components=see_comps, # Select components to see\n",
    "         title='', # Select title of plot\n",
    "         ax=ax)\n",
    "\n",
    "# Remove ellipses by putting a # before the next line\n",
    "metsta.plot_ellipses_PCA(principaldf_BinSim, lcolors, \n",
    "                  components=see_comps, # Select components to see\n",
    "                  ax=ax, \n",
    "                  q=0.95) # Confidence ellipse with 95% (q) confidence\n",
    "\n",
    "ax.set_xlabel(f'PC {see_comps[0]} ({var_BinSim[see_comps[0]-1] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "ax.set_ylabel(f'PC {see_comps[1]} ({var_BinSim[see_comps[1]-1] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "\n",
    "plt.legend(fontsize=15) # Set the size of labels\n",
    "plt.grid() # If you want a grid or not\n",
    "plt.show()\n",
    "#f.savefig('Name_BinSim_PCAplot.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46d85f7",
   "metadata": {},
   "source": [
    "HCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing HCA \n",
    "metric = 'euclidean' # Select distance metric\n",
    "method = 'ward' # Select linkage method\n",
    "\n",
    "distances_BinSim = dist.pdist(bin_data, metric=metric)\n",
    "Z_BinSim = hier.linkage(distances_BinSim, method=method)\n",
    "\n",
    "hca_res_BinSim = {'Z': Z_BinSim, 'distances': distances_BinSim}\n",
    "\n",
    "# Plot HCA\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 4), constrained_layout=True) # Set Figure Size\n",
    "    metsta.plot_dendogram(hca_res_BinSim['Z'], \n",
    "                   target, ax=ax,\n",
    "                   label_colors=label_colours,\n",
    "                   title='', # Select title\n",
    "                   color_threshold=0) # Select a distance threshold from where different sets of lines are coloured\n",
    "\n",
    "    plt.show()\n",
    "    #f.savefig('Name_BinSim_HCAplot.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de88489",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a number for the seed for consistent results\n",
    "np.random.seed()\n",
    "\n",
    "n_trees=200 # Number of trees in the model\n",
    "\n",
    "RF_results_BinSim = metsta.RF_model(bin_data, target, regres=regression, # Data and labels \n",
    "                      return_cv=True, iter_num=5, # If you want cross calidation results and number of iterations for it\n",
    "                      n_trees=n_trees, # Number of trees in the model\n",
    "                      cv=None, n_fold=3, random_state=None, # Choose a method of cross-validation (None is stratified cv),\n",
    "                                                           # the n of folds and stable random_state for CV only if cv none\n",
    "        metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted')) # Choose the performance metrics\n",
    "\n",
    "rf_results_summary_BinSim = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in RF_results_BinSim.items():\n",
    "    if k != 'model' and k != 'imp_feat':\n",
    "        rf_results_summary_BinSim.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(rf_results_summary_BinSim)\n",
    "\n",
    "imp_feats_rf_BinSim = meta_data.copy()\n",
    "imp_feats_rf_BinSim.insert(0,'Bucket label', imp_feats_rf_BinSim.index)\n",
    "imp_feats_rf_BinSim.insert(1,'Gini Importance', '')\n",
    "imp_feats_rf_BinSim = imp_feats_rf_BinSim.copy()\n",
    "for n in range(len(RF_results_BinSim['imp_feat'])):\n",
    "    imp_feats_rf_BinSim['Gini Importance'].iloc[RF_results_BinSim['imp_feat'][n][0]] = RF_results_BinSim['imp_feat'][n][1]\n",
    "imp_feats_rf_BinSim = imp_feats_rf_BinSim.sort_values(by='Gini Importance', ascending=False)\n",
    "imp_feats_rf_BinSim.index = range(1, len(imp_feats_rf_BinSim)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_rf_BinSim.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b181df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = False\n",
    "\n",
    "# Saving the most important features by their fraction 'frac_feat_impor'.\n",
    "# If None, saving the most important features based on a threshold 'VIP_Score_threshold'.\n",
    "# If also None, save the full dataset of all features\n",
    "frac_feat_impor = 0.02 # Fraction of features to save, If None the variable in the next line is used.\n",
    "score_threshold = None # Only used if variable above is None, threshold of score to consider a feature important.\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    if frac_feat_impor:\n",
    "        max_idx = int(frac_feat_impor*len(imp_feats_rf_BinSim))\n",
    "        filt_imp_feats_rf_BinSim = imp_feats_rf_BinSim.iloc[:max_idx]\n",
    "        filt_imp_feats_rf_BinSim.to_excel(f'RF_BinSim_ImpFeat_{frac_feat_impor*100}%.xlsx')\n",
    "    elif score_threshold:\n",
    "        filt_imp_feats_rf_BinSim = imp_feats_rf_BinSim[imp_feats_rf_BinSim['Gini Importance'] > score_threshold]\n",
    "        filt_imp_feats_rf_BinSim.to_excel(f'RF_BinSim_ImpFeat_GiniImpgreater{score_threshold}.xlsx')\n",
    "    else:\n",
    "        imp_feats_rf_BinSim.to_excel(f'RF_BinSim_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbbeff1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GENERATE = False # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random permutator)\n",
    "\n",
    "    perm_results_BinSim_RF = metsta.permutation_RF(\n",
    "        bin_data, target,  # Data and labels \n",
    "        iter_num=500, # N of permutations to do in your test - around 500 should be enough\n",
    "        n_trees=200, # Number of trees in the model\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        metric=('accuracy')) # Choose a metric to use to evaluate if the model is significant\n",
    "    \n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(bin_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_BinSim_RF\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='RF Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('N of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('Random Forest Permutation Test (BinSim)', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_BinSim_RF_PermutationTest.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf62ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if len(pd.unique(pd.Series(target))) == 2:\n",
    "        # Set a random seed for reproducibility\n",
    "        np.random.seed()\n",
    "        \n",
    "        # Set up positive label\n",
    "        pos_label = pd.unique(pd.Series(target))[0]\n",
    "\n",
    "        resROC_BinSim_RF = metsta.RF_ROC_cv(bin_data, target, regres=regression, # Data and target\n",
    "                                    pos_label=pos_label, # Positive label\n",
    "                                    n_trees=200, # Number of trees of RF\n",
    "                                    n_iter=15, # Number of iterations to repeat \n",
    "                                    cv=None, n_fold=3, random_state=None) # method of CV (None is stratified cv) and the n\n",
    "                                                                          # of folds and stable random_state for CV only if\n",
    "                                                                          # cv none\n",
    "    \n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_BinSim_RF\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set_title('Random Forest ROC Curve (BinSim)', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_BinSim_RF_ROCcurve.jpg', dpi=400) # Save the figure\n",
    "    else:\n",
    "        print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f81904",
   "metadata": {},
   "source": [
    "PLS-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ebcc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Results\n",
    "PLS_optim_BinSim = metsta.optim_PLSDA_n_components(bin_data, target, regression, # Data and target\n",
    "                                    encode2as1vector=True,\n",
    "                                    max_comp=8, # Max. number of components to search (the higher the more time it takes)\n",
    "                                    kf=None, n_fold=3, # Cross validation to use (none is stratified CV) and n of folds\n",
    "                                    scale=False) # Set scale to True only if you did not do scaling in pre-treatments\n",
    "\n",
    "scores_cols = sns.color_palette('tab10', 10) # Set the colors for the lines\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(4,4), constrained_layout=True) # Set the figure size\n",
    "        c = 0\n",
    "        for i, values in PLS_optim.items():\n",
    "            if i =='CVscores':\n",
    "                name = 'Q$^2$'\n",
    "            else:\n",
    "                name = 'R$^2$'\n",
    "            \n",
    "            ax.plot(range(1, len(values) + 1), values, label=name, color = scores_cols[c])\n",
    "            c = c+1\n",
    "        \n",
    "        ax.set(xlabel='Number of Components', # Set the label for the x axis\n",
    "                ylabel='PLS Score') # Set the label for the Y axis\n",
    "        ax.legend(loc='lower right', fontsize=15) # Set the legend\n",
    "        ax.set_ylim([0, 1.02]) # Set limits for y axis\n",
    "        ax.set_xticks(range(0, len(values), 2)) # Set ticks that appear in the bottom of x axis\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture --no-stdout\n",
    "# above is to supress PLS warnings\n",
    "\n",
    "n_comp = 4 # Number of components of PLS-DA model - very important\n",
    "\n",
    "PLSDA_results_BinSim = metsta.PLSDA_model_CV(bin_data, target, regression, # Data and target\n",
    "                       n_comp=n_comp, # Number of components of PLS-DA model - very important\n",
    "                       kf=None, n_fold=3,  # Cross validation to use (none is stratified CV), n of folds\n",
    "                                                   # and stable random_state for CV only if cv none\n",
    "                       iter_num=10, # Number of iterations of cross-validation to do\n",
    "                       encode2as1vector=True,\n",
    "                       scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                       feat_type='VIP') # Feature Importance Metric to use, default is VIP scores (see function for others)\n",
    "\n",
    "pls_results_summary_BinSim = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in PLSDA_results_BinSim.items():\n",
    "    if k != 'Q2' and k != 'imp_feat':\n",
    "        pls_results_summary_BinSim.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(pls_results_summary_BinSim)\n",
    "\n",
    "imp_feats_plsda_BinSim = meta_data.copy()\n",
    "imp_feats_plsda_BinSim.insert(0,'Bucket label', imp_feats_plsda_BinSim.index)\n",
    "imp_feats_plsda_BinSim.insert(1,'VIP Score', '')\n",
    "for n in range(len(PLSDA_results_BinSim['imp_feat'])):\n",
    "    imp_feats_plsda_BinSim['VIP Score'].iloc[\n",
    "        PLSDA_results_BinSim['imp_feat'][n][0]] = PLSDA_results_BinSim['imp_feat'][n][1]\n",
    "imp_feats_plsda_BinSim = imp_feats_plsda_BinSim.sort_values(by='VIP Score', ascending=False)\n",
    "imp_feats_plsda_BinSim.index = range(1, len(imp_feats_plsda_BinSim)+1)\n",
    "\n",
    "imp_feats_plsda_BinSim.head(20) # Select number of features to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = False\n",
    "\n",
    "# Saving the most important features by their fraction 'frac_feat_impor'.\n",
    "# If None, saving the most important features based on a threshold 'VIP_Score_threshold'.\n",
    "# If also None, save the full dataset of all features\n",
    "frac_feat_impor = 0.02 # Fraction of features to save, If None the variable in the next line is used.\n",
    "VIP_Score_threshold = 1 # Only used if variable above is None, threshold of score to consider a feature important.\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    if frac_feat_impor:\n",
    "        max_idx = int(frac_feat_impor*len(imp_feats_plsda_BinSim))\n",
    "        filt_imp_feats_plsda_BinSim = imp_feats_plsda_BinSim.iloc[:max_idx]\n",
    "        filt_imp_feats_plsda_BinSim.to_excel(f'PLSDA_BinSim_ImpFeat_{frac_feat_impor*100}%.xlsx')\n",
    "    elif VIP_Score_threshold:\n",
    "        filt_imp_feats_plsda_BinSim = imp_feats_plsda_BinSim[imp_feats_plsda_BinSim['VIP Score'] > VIP_Score_threshold]\n",
    "        filt_imp_feats_plsda_BinSim.to_excel(f'PLSDA_BinSim_ImpFeat_VIPgreater{VIP_Score_threshold}.xlsx')\n",
    "    else:\n",
    "        imp_feats_plsda_BinSim.to_excel(f'PLSDA_BinSim_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e87bd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GENERATE = False # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random state in the function below)\n",
    "\n",
    "    perm_results_BinSim_PLSDA = metsta.permutation_PLSDA(\n",
    "        bin_data, target,  # data and labels\n",
    "        n_comp=4, # Number of components\n",
    "        iter_num=500, # N of permutations to do in your test - around 500 should be enough\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        encode2as1vector=True, scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "        metric='accuracy') # Choose a metric to use to evaluate if the model is significant\n",
    "    \n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(treated_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_BinSim_PLSDA\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='PLS-DA Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('N of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('PLS-DA Permutation Test (BinSim)', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_PLSDA_PermutationTest.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        # Set a random seed for reproducibility\n",
    "        np.random.seed()\n",
    "        \n",
    "        # Set up positive label\n",
    "        pos_label = pd.unique(target)[0]\n",
    "\n",
    "        resROC_BinSim_PLSDA = metsta.PLSDA_ROC_cv(treated_data, target, # Data and target\n",
    "                            pos_label=pos_label, # Positive label\n",
    "                            n_comp=4, # Number of components\n",
    "                            scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                            n_iter=15, # Number of iterations to repeat \n",
    "                            cv=None, n_fold=3, random_state=None) # Method of cross-validation (None is stratified cv), the\n",
    "                                                                # n of folds and stable random_state for CV only if cv none\n",
    "        \n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_BinSim_PLSDA\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set(xlabel='False positive rate', ylabel='True positive rate')\n",
    "                ax.set_title('PLS-DA ROC Curve (BinSim)', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_BinSim_PLSDA_ROCcurve.jpg', dpi=400) # Save the figure\n",
    "    else:\n",
    "        print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924e578",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16890226",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    xgb_max_n_estimators_binsim = 300\n",
    "\n",
    "    xgb_optim_params_binsim = {'n_estimators': range(10,xgb_max_n_estimators_binsim+1,5)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966fcb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    \n",
    "    XGB_Optim_BinSim = metsta.optimise_xgb_parameters(bin_data, target, xgb_optim_params_binsim, regression, objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626033dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    param_to_plot = 'n_estimators'\n",
    "\n",
    "    # Plotting the results and adjusting parameters of the plot\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "            f, ax = plt.subplots(1, 1, figsize=(6,6), constrained_layout=True) # Set Figure Size\n",
    "\n",
    "            c_map = sns.color_palette('tab10', 10)\n",
    "\n",
    "            ax.plot(XGB_Optim_BinSim.cv_results_['param_n_estimators'], [s*100 for s in XGB_Optim_BinSim.cv_results_['mean_test_score']])\n",
    "            ax.set_ylabel('XGBoost CV Mean Accuracy (%)', fontsize=15) # Set the y_label and size\n",
    "            ax.set_xlabel(param_to_plot, fontsize=15)\n",
    "            ax.set_title('XGBoost', fontsize=18) # Set the title and size\n",
    "            ax.set_ylim([30,101]) # Set the limits on the y axis\n",
    "\n",
    "            #f.suptitle('Optimization of the number of trees')\n",
    "            ax.legend(fontsize=15) # Set the legend and size\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c780f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    n_estimators=300 # Number of trees in the model\n",
    "\n",
    "    XGB_results_BinSim = metsta.XGB_model(bin_data, target, # Data and labels\n",
    "                        regres=regression, obj=objective, # If you're doing regression or classificattion and objective function\n",
    "                        return_cv=True, iter_num=5, # If you want cross calidation results and number of iterations for it\n",
    "                        n_estimators=n_estimators, # Number of trees in the model\n",
    "                        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the n of folds\n",
    "            metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted')) # Choose the performance metrics\n",
    "\n",
    "    XGB_results_summary_BinSim = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "    for k,v in XGB_results_BinSim.items():\n",
    "        if k != 'model' and k != 'imp_feat':\n",
    "            XGB_results_summary_BinSim.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "    print(XGB_results_summary_BinSim)\n",
    "\n",
    "    imp_feats_xgb_BinSim = meta_data.copy()\n",
    "    imp_feats_xgb_BinSim.insert(0,'Bucket label', imp_feats_xgb_BinSim.index)\n",
    "    imp_feats_xgb_BinSim.insert(1,'Feature Importance', '')\n",
    "    imp_feats_xgb_BinSim = imp_feats_xgb_BinSim.copy()\n",
    "    for n in range(len(XGB_results_BinSim['imp_feat'])):\n",
    "        imp_feats_xgb_BinSim['Feature Importance'].iloc[XGB_results_BinSim['imp_feat'][n][0]] = XGB_results_BinSim['imp_feat'][n][1]\n",
    "    imp_feats_xgb_BinSim = imp_feats_xgb_BinSim.sort_values(by='Feature Importance', ascending=False)\n",
    "    imp_feats_xgb_BinSim.index = range(1, len(imp_feats_xgb_BinSim)+1)\n",
    "else:\n",
    "    imp_feats_xgb_BinSim = \"XGBoost Analysis was not performed\"\n",
    "    \n",
    "imp_feats_xgb_BinSim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51cf66e",
   "metadata": {},
   "source": [
    "# Step 11: Find Specific Compounds <a class=\"anchor\" id=\"step-11\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "This code will allow you to conveniently find specific compounds by their index, name, formula, or neutral mass / Probable _m/z_. The mass finders work even if you don't know the specific mass, as you can search only by the first few digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_type = 'kegg' #pick 'formula', 'name', 'Neutral Mass'/'Probable m/z', 'index', or 'kegg'\n",
    "find_id = 'C00249' \n",
    "if id_type == 'index':\n",
    "    finder = processed_data.loc[processed_data.index.str.startswith(find_id)]\n",
    "elif id_type in ['Neutral Mass', 'Probable m/z']:\n",
    "    finder = processed_data.loc[processed_data[mass_val_col].astype('str').str.startswith(find_id)]\n",
    "elif id_type == 'formula':\n",
    "    index_list = []\n",
    "    for col in meta_cols_formulas:\n",
    "        temp_df = processed_data[[col]].dropna()\n",
    "        for t in temp_df.index:\n",
    "            if find_id in temp_df[col][t]:\n",
    "                index_list.append(t)\n",
    "    \n",
    "    for col in prev_formula_cols + [form_col, ]:\n",
    "        if col in processed_data.columns:\n",
    "            temp_df = processed_data[col].dropna()\n",
    "            for t in temp_df.index:\n",
    "                if type(temp_df[t]) == str:\n",
    "                    if find_id == temp_df[t]:\n",
    "                        index_list.append(t)\n",
    "                else:\n",
    "                    if find_id in temp_df[t]:\n",
    "                        index_list.append(t)\n",
    "    finder = processed_data.loc[processed_data.index.isin(index_list)]\n",
    "elif id_type == 'name':\n",
    "    index_list = []\n",
    "    for col in meta_cols_names:\n",
    "        temp_df = processed_data[[col]].dropna()\n",
    "        for t in temp_df.index:\n",
    "            if find_id in temp_df[col][t]:\n",
    "                index_list.append(t)\n",
    "    for col in prev_annotations_cols:\n",
    "        if col in processed_data.columns:\n",
    "            temp_df = processed_data[col].dropna()\n",
    "            for t in temp_df.index:\n",
    "                if type(temp_df[t]) == str:\n",
    "                    if find_id == temp_df[t]:\n",
    "                        index_list.append(t)\n",
    "                else:\n",
    "                    if find_id in temp_df[t]:\n",
    "                        index_list.append(t)\n",
    "    finder = processed_data.loc[processed_data.index.isin(index_list)]\n",
    "elif id_type == 'kegg':\n",
    "    index_list = []\n",
    "    if 'HMDB' in dbs:\n",
    "        temp_df = processed_data[['Matched KEGG IDs']].dropna()\n",
    "        for t in temp_df.index:\n",
    "            if find_id in temp_df['Matched KEGG IDs'][t]:\n",
    "                index_list.append(t)\n",
    "        finder = processed_data.loc[processed_data.index.isin(index_list)]\n",
    "    else:\n",
    "        print('No HMDB annotation found. Please annotate with HMDB to have access to KEGG ID information')\n",
    "\n",
    "finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to see the intensities distribution (might become difficult to see with a lot of samples)\n",
    "bar_plot_info = finder.replace({np.nan:0})\n",
    "if len(bar_plot_info.index) == 1:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(16,6))\n",
    "    x = np.arange(len(bar_plot_info.columns[-len(sample_cols):]))\n",
    "    for comps in range(len(bar_plot_info.index)):\n",
    "        ax.barh(x, np.array(bar_plot_info.iloc[comps, -len(sample_cols):]), color=sample_colours)\n",
    "        ax.set_ylabel('Normalized Intensity', fontsize=15)\n",
    "        ax.set_title(find_id, fontsize=15)\n",
    "else:\n",
    "    fig, axs = plt.subplots(1,len(bar_plot_info.index), figsize=(16,6))\n",
    "\n",
    "    x = np.arange(len(bar_plot_info.columns[-len(sample_cols):]))\n",
    "    for (comps, ax) in zip(range(len(bar_plot_info.index)), axs.ravel()):\n",
    "        ax.barh(x, np.array(bar_plot_info.iloc[comps, -len(sample_cols):]), color=sample_colours)\n",
    "        ax.set_yticks([])\n",
    "        #ax.tick_params(labelleft=False)\n",
    "        ax.set_ylabel('Normalized Intensity', fontsize=13)\n",
    "        ax.set_title(find_id)\n",
    "    ax = axs[0]\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(bar_plot_info.columns[-len(sample_cols):], fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3580a",
   "metadata": {},
   "source": [
    "Search for the differences between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a8304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average intensities\n",
    "gfinder = finder.copy()\n",
    "for g in groups:\n",
    "    gfinder[g+' Average'] = gfinder[gfinder.columns.intersection(groups[g])].mean(axis=1)\n",
    "    gfinder[g+' std'] = gfinder[gfinder.columns.intersection(groups[g])].std(axis=1)\n",
    "gfinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea592461",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cols = [col for col in gfinder.columns if 'Average' in col]\n",
    "std_cols = [col for col in gfinder.columns if 'std' in col]\n",
    "group_colours = [label_colours[lbl] for lbl in classes]\n",
    "bar_plot_info = gfinder.replace({np.nan:0})\n",
    "if len(bar_plot_info.index) == 1:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(10,7))\n",
    "    x = np.arange(len(avg_cols))\n",
    "    for comps in bar_plot_info.index:\n",
    "        ax.bar(x, np.array(bar_plot_info.loc[comps, avg_cols]), color=group_colours, yerr=np.array(bar_plot_info.loc[comps, std_cols]), capsize=12)\n",
    "        ax.set_ylabel('Normalized Intensity', fontsize=15)\n",
    "        ax.set_title(find_id, fontsize=15)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(groups, fontsize=12)\n",
    "else:\n",
    "    fig, axs = plt.subplots(1,len(bar_plot_info.index), figsize=(16,6))\n",
    "\n",
    "    x = np.arange(len(avg_cols))\n",
    "    for (comps, ax) in zip(bar_plot_info.index, axs.ravel()):\n",
    "        ax.bar(x, np.array(bar_plot_info.loc[comps, avg_cols]), color=group_colours, yerr=np.array(bar_plot_info.loc[comps, std_cols]), capsize=12)\n",
    "        ax.set_yticks([])\n",
    "        #ax.tick_params(labelleft=False)\n",
    "        ax.set_ylabel('Normalized Intensity', fontsize=13)\n",
    "        ax.set_title(find_id)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(groups)\n",
    "    ax = axs[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(finder.index) == 1:\n",
    "    its_list = []\n",
    "    for g in groups:\n",
    "        its = finder[finder.columns.intersection(groups[g])].T.reset_index(drop= True)\n",
    "        its_list.append(its)\n",
    "    its_df = pd.concat(its_list, axis=1)\n",
    "    its_df = its_df.set_axis(groups, axis=1)\n",
    "    fig, ax = plt.subplots(1,1, figsize=(12,7))\n",
    "    box1= ax.boxplot(its_df, labels=its_df.columns, patch_artist=True, medianprops=dict(color='black'))\n",
    "    for patch, color, lbl in zip(box1['boxes'], colours, its_df.columns):\n",
    "        patch.set_facecolor(color)\n",
    "    ax.tick_params(axis=\"x\", labelsize=25)\n",
    "    ax.tick_params(axis=\"y\", labelsize=20)\n",
    "    ax.set_title(find_id, fontsize=25)\n",
    "    plt.show()\n",
    "else:\n",
    "    fig, axs = plt.subplots(1,len(finder.index), figsize=(16,6))\n",
    "    for (comps, ax) in zip(finder.index, axs.ravel()):\n",
    "        comps_df = finder.loc[[comps]]\n",
    "        its_list = []\n",
    "        for g in groups:\n",
    "            its = comps_df[comps_df.columns.intersection(groups[g])].T.reset_index(drop= True)\n",
    "            its_list.append(its)\n",
    "        its_df = pd.concat(its_list, axis=1)\n",
    "        its_df = its_df.set_axis(groups, axis=1)\n",
    "        box1= ax.boxplot(its_df, labels=its_df.columns, patch_artist=True, medianprops=dict(color='black'))\n",
    "        for patch, color, lbl in zip(box1['boxes'], colours, its_df.columns):\n",
    "            patch.set_facecolor(color)\n",
    "        ax.set_title(find_id, fontsize=15)\n",
    "    ax = axs[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1110e22",
   "metadata": {},
   "source": [
    "### Correlated metabolites\n",
    "\n",
    "Find metabolites with strong positive and negative correlations to the selected one(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3214e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your search returned more than one metabolite, select the one you want to find correlated metabolites for \n",
    "\n",
    "found_met = finder.index[0] # Change index position (0, 1, 2, 3 etc.) or paste Bucket label (e.g. 228.2088971606 Da)\n",
    "\n",
    "print(found_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddaabc0",
   "metadata": {},
   "source": [
    "Select between the [Pearson](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient), [Kendall](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient) and [Spearman](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) correlation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_method = 'pearson' # Pick 'pearson', 'kendall' or 'spearman'\n",
    "\n",
    "corr_matrix = treated_data.corr(method=corr_method)[[found_met]]\n",
    "\n",
    "corr_mets = meta_data.copy()\n",
    "corr_mets.insert(0,'Bucket label', corr_mets.index)\n",
    "corr_mets.insert(1,'Corr Coef', '')\n",
    "for c in corr_mets.index:\n",
    "    corr_mets['Corr Coef'][c] = corr_matrix.loc[c][found_met]\n",
    "corr_mets = corr_mets.drop(found_met)\n",
    "corr_mets = corr_mets.sort_values(by='Corr Coef', ascending=False)\n",
    "corr_mets.index = range(1, len(corr_mets)+1)\n",
    "corr_mets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you want the full table in excel\n",
    "# corr_mets.to_excel(filename.split('.')[0]+'_'+found_met+'_corrs.xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the 10 metabolites with the strongest positive correlations with the selected\n",
    "corr_mets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the 10 metabolites with the strongest negative correlations with the selected\n",
    "corr_mets.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da255203",
   "metadata": {},
   "source": [
    "### Batch search\n",
    "\n",
    "If you have a list of compounds you want to search for in the sample, you can  submit it as an excel file and run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1459f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_search = pd.read_excel('batch_search_test.xlsx')\n",
    "\n",
    "batch_search['Monoisotopic mass'] = \"\"\n",
    "batch_search['Matched Name IDs'] = \"\"\n",
    "batch_search['Matched Formula IDs'] = \"\"\n",
    "batch_search['Similar masses'] = \"\"\n",
    "\n",
    "for b in batch_search.index:\n",
    "\n",
    "    b_mass = metsta.calculate_monoisotopic_mass(batch_search['Formula'][b])\n",
    "    batch_search['Monoisotopic mass'][b] = float(b_mass)\n",
    "\n",
    "    name_index_list = []\n",
    "    for col in meta_cols_names:\n",
    "        temp_df = processed_data[[col]].dropna()\n",
    "        for t in temp_df.index:\n",
    "            if t not in name_index_list:\n",
    "                if batch_search['Name'][b] in temp_df[col][t]:\n",
    "                    name_index_list.append(t)\n",
    "\n",
    "    form_index_list = []\n",
    "    for col in meta_cols_formulas:\n",
    "        temp_df = processed_data[[col]].dropna()\n",
    "        for t in temp_df.index:\n",
    "            if t not in form_index_list:\n",
    "                if batch_search['Formula'][b] in temp_df[col][t]:\n",
    "                    form_index_list.append(t)\n",
    "\n",
    "    mass_index_list = []\n",
    "    mass_df = processed_data[processed_data[mass_val_col].between(b_mass-1,b_mass+1)]\n",
    "    for m in mass_df.index:\n",
    "        mass_index_list.append(m)\n",
    "\n",
    "    batch_search['Matched Name IDs'][b] = name_index_list\n",
    "    batch_search['Matched Formula IDs'][b] = form_index_list\n",
    "    batch_search['Similar masses'][b] = mass_index_list\n",
    "\n",
    "batch_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f921c",
   "metadata": {},
   "source": [
    "### Notebook made by:\n",
    "\n",
    "- FT-ICR-MS-Lisboa Laboratory Group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
