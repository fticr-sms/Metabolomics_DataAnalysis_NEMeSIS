{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869f8d1a",
   "metadata": {},
   "source": [
    "# Extra Module for Metabolomics Data Analysis\n",
    "\n",
    "# sMDiN Analysis (Sample Mass-Difference Networks Analysis)\n",
    "\n",
    "sMDiN or sample Mass-Difference Network analysis is a pre-treatment to complement intensity-data that is available in a separated module as a jupyter notebook. It uses feature occurrence data by building Mass-Difference Networks (masses linked if their mass-difference corresponds to a common biochemical transformation) for each sample in the data. Then, network analysis is performed on each of these networks based on what characteristic of the data you want to analyze (for example, which chemical transformation might have different prevalences between samples of different classes). Then, the Unsupervised and Supervised analysis can be repeated using the tables obtained from these network analysis.\n",
    "\n",
    "Here, the user can choose if they prefer to build the networks using the conventional mass-differences or only formula differences from formula assigned features if they exist in the data.\n",
    "\n",
    "paper doi: 10.3389/fmolb.2022.917911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hier\n",
    "import scipy.stats as stats\n",
    "\n",
    "import sklearn.ensemble as skensemble\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import MDiN_functions as md\n",
    "import metanalysis_standard as metsta\n",
    "from elips import plot_confidence_ellipse\n",
    "from multianalysis import p_adjust_bh, fit_PLSDA_model, _calculate_vips, _generate_y_PLSDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14b4bce",
   "metadata": {},
   "source": [
    "#### Import treated Data from the main notebook.\n",
    "\n",
    "Select the filename of the file to import from the main jupyter notebook analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d807750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename for the data to import\n",
    "filename = 'Export_TreatedData.xlsx'\n",
    "filename_pickle_treated = 'Export_TreatedData.pickle'\n",
    "filename_pickle_proc = 'Export_ProcData.pickle'\n",
    "\n",
    "#treated_data = pd.read_excel(filename, sheet_name='Fully Treated Data').set_index('Unnamed: 0').T\n",
    "bin_data = pd.read_excel(filename, sheet_name='BinSim Treated Data').set_index('Bucket label').T\n",
    "univariate_data = pd.read_excel(filename, sheet_name='MVI+Norm Data').set_index('Unnamed: 0')\n",
    "\n",
    "processed_data = pd.read_pickle(filename_pickle_proc)\n",
    "treated_data = pd.read_pickle(filename_pickle_treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename for the target to import\n",
    "filename_target = 'Export_Target.txt'\n",
    "\n",
    "with open(filename_target) as a:\n",
    "    tg = a.readlines()\n",
    "target = [t.strip() for t in tg]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6fe81",
   "metadata": {},
   "source": [
    "### Reading MDB list\n",
    "\n",
    "MDB - Mass-Difference-based building Block.\n",
    "\n",
    "MDBs are the list of chemical transformations that are used to build Mass-Difference Networks. They usually represent some of the most common and ubiquitous reactions in biological systems but can also be specific to the biological system in case.\n",
    "\n",
    "The default file provided `MDB_list.txt` contains 15 common biochemical transformation.\n",
    "\n",
    "This file can also be used as a guide for the formatting required to create your own MDB list. In short, it should have 4 columns without headers where the first one should correspond to the absolute change in the compound that the chemical transformation causes (for example, methylation is CH2), the second column to the name of the Mass-Difference-based building Block (MDB), that is of the chemical transformation, the third column should be the mass difference associated to the column (for methylation, it would be 14.015650064399999 for example) and the fourth column should say true. Each column should be tab separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebbf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdb_filename = 'MDB_list.txt'\n",
    "\n",
    "# Setting up the Chemical Transformations DataFrame\n",
    "MDBs_to_use = pd.read_csv(mdb_filename, sep='\\t', header=None)\n",
    "MDBs_to_use.columns = ['Label', 'Transformation', 'Mass', 'Selected']\n",
    "MDBs_to_use = MDBs_to_use.set_index('Label')\n",
    "comp = []\n",
    "for i in MDBs_to_use.index:\n",
    "    comp.append(md.formula_process(i))\n",
    "MDBs_to_use['Comp.'] = comp\n",
    "\n",
    "MDBs_to_use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a7d9c0",
   "metadata": {},
   "source": [
    "## Building the MDiN\n",
    "\n",
    "Here, we built the actual general MDiN for the whole dataset. From this general dataset, we will then subgraph it for each sample with only the metabolic features that appear in it to make the sample Mass-Difference Networks.\n",
    "\n",
    "There are 4 possible types of MDiNs that you can choose:\n",
    "\n",
    "- **Simple MDiN**: This is the simplest and fastest type of MDiN. It only requires a list of mass values (and MDBs) and creates connections (edges) in the network if the mass difference between metabolic features (nodes) corresponds to one of the MDBs used.\n",
    "- **Univocal MDiN**: It also only requires a list of mass values (and MDBs). It starts by building a simple MDiN but then it trims this simple MDiN by seeing cases where one node has multiple edges representing the same chemical transformation in the same 'direction' (that is addition or subtraction of a chemical group) and only keeping the one who has a lower associated error. This is based on the idea that each metabolite feature should have a unique formula, since direct infusion mass spectrometry would indicate that for each unique formula, you should only have one metabolic feature. If there are multiples of the same 'edge' MDB from the same node, this principle would be violated.\n",
    "- **Mass Formula Propagation (Mass Form. Prop.) MDiN**: It requires a list of mass values and a list of reliably (or more reliably) identificated metabolic features (for example, formulas from annotated metabolites). It builds a Univocal MDiN but uses it for formula propagation in the network starting from those reliably identificated metabolic features. It eliminates edges to both avoid incoherencies and contradictions. The former by leading to very improbable formulas as defined by different criterias such as the usual elemental ratios, Valency restrictions or maximum number of different elements. The latter by eliminating edges where the propagation from two starting nodes leads to different formulas.\n",
    "- **Formula Difference Networks**: This network is built from assigned formulas in the data instead of the mass differences. It requires only a DataFrame or Series with the formula associated to each metabolic feature. It restricts the data to only the formula assigned metabolites but also reduces possible errors in link creation since there is no deviation associated with formula differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f59cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of MDiN desired (details about each on the cell above)\n",
    "mdin_type = 'Univocal' # Options: 'Simple', 'Univocal', 'Mass Form. Prop.', 'Formula'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad9700",
   "metadata": {},
   "source": [
    "**Simple MDiN cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31242a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for Simple MDiN\n",
    "if mdin_type == 'Simple':\n",
    "    # Parameters\n",
    "    # Column with mass values to build the Mass Difference Network\n",
    "    mass_val_col = 'Neutral Mass'\n",
    "    # Allowed ppm deviation to link the nodes\n",
    "    ppm_thresh = 0.5\n",
    "\n",
    "    # Mass list\n",
    "    masses_list = list(processed_data[mass_val_col].values)\n",
    "\n",
    "    formula_df = processed_data.copy()\n",
    "    general_MDiN = md.simple_MDiN(masses_list, trans_groups=MDBs_to_use, ppm=ppm_thresh)\n",
    "    re_nodes = {v: k for k, v in formula_df[mass_val_col].to_dict().items()}\n",
    "    general_MDiN = nx.relabel_nodes(general_MDiN, re_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5a513",
   "metadata": {},
   "source": [
    "**Univocal MDiN cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for Univocal MDiN\n",
    "if mdin_type == 'Univocal':\n",
    "    # Parameters\n",
    "    # Column with mass values to build the Mass Difference Network\n",
    "    mass_val_col = 'Neutral Mass'\n",
    "    # Allowed ppm deviation to link the nodes\n",
    "    ppm_thresh = 0.5\n",
    "\n",
    "    # Mass list\n",
    "    masses_list = list(processed_data[mass_val_col].values)\n",
    "\n",
    "    formula_df = processed_data.copy()\n",
    "    general_MDiN = md.univocal_MDiN(masses_list, trans_groups=MDBs_to_use, ppm=ppm_thresh)\n",
    "    re_nodes = {v: k for k, v in formula_df[mass_val_col].to_dict().items()}\n",
    "    general_MDiN = nx.relabel_nodes(general_MDiN, re_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663d848",
   "metadata": {},
   "source": [
    "**Mass Formula Propagation MDiN cell**\n",
    "\n",
    "First, there is here a suggestion on how to build a reliable formula DataFrame, this can be chosen as the user prefers but should have the same formatting as the end result of the next cell (DataFrame with one column, the index are the masses of the features with reliably annotated formulas and the column named 'Formula' contains the corresponding formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reliable_forms_df = pd.DataFrame(columns=['Formula'])\n",
    "if mdin_type == 'Mass Form. Prop.':\n",
    "    # Column with mass values to build the Mass Difference Network\n",
    "    mass_val_col = 'Neutral Mass'\n",
    "\n",
    "    # Building the reliable formulas set\n",
    "    # Here is a way to consider reliable, formulas that come from annotated compounds which only have one possibility of \n",
    "    # formula for the node. For this we select, which annotation columns we consider and where are the respective formulas\n",
    "    # in the two dictionaries below (based of if the formulas are just a string or they are in lists in the respective cols)\n",
    "    ann_to_form_cols_instring = {'Name': 'Formula'}\n",
    "    ann_to_form_cols_inlist = {'Matched HMDB names': 'Matched HMDB formulas',\n",
    "                        'Matched LTS names': 'Matched LTS formulas',  'Matched DBK names': 'Matched DBK formulas',}\n",
    "\n",
    "    temp_df = processed_data.loc[processed_data['Has Match?'].dropna()]\n",
    "\n",
    "    for i in temp_df.index:\n",
    "        form = []\n",
    "        for a_col, f_col in ann_to_form_cols_instring.items():\n",
    "            a = temp_df.loc[i, a_col]\n",
    "            if type(a) == str:\n",
    "                f = temp_df.loc[i, f_col]\n",
    "                if f not in form:\n",
    "                    form.append(f)\n",
    "\n",
    "        for a_col, f_col in ann_to_form_cols_inlist.items():\n",
    "            a = temp_df.loc[i, a_col]\n",
    "            if type(a) == list:\n",
    "                fs = temp_df.loc[i, f_col]\n",
    "                for f in fs:\n",
    "                    if f not in form:\n",
    "                        form.append(f)\n",
    "\n",
    "        # Only keep indexes that have 1 possible formula\n",
    "        if len(form) == 1:\n",
    "            reliable_forms_df.loc[temp_df.loc[i, mass_val_col]] = form[0]\n",
    "\n",
    "# DataFrame\n",
    "reliable_forms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to build the MDiN\n",
    "if mdin_type == 'Mass Form. Prop.':\n",
    "    # Other Parameters\n",
    "    # Reliable Formulas DF\n",
    "    reliable_forms_df = reliable_forms_df\n",
    "    # Allowed ppm deviation to link the nodes\n",
    "    ppm_thresh = 0.5\n",
    "\n",
    "    # Mass list\n",
    "    masses_list = list(processed_data[mass_val_col].values)\n",
    "\n",
    "    formula_df = processed_data.copy()\n",
    "    general_MDiN = md.formula_MDiN(masses_list, reliable_forms_df, trans_groups=MDBs_to_use, ppm=ppm_thresh)\n",
    "    re_nodes = {v: k for k, v in formula_df[mass_val_col].to_dict().items()}\n",
    "    general_MDiN = nx.relabel_nodes(general_MDiN, re_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2b55f2",
   "metadata": {},
   "source": [
    "**Formula Difference-Networks**\n",
    "\n",
    "Here, as in the case before, we have to prepare a separate DataFrame which has the indexes as thee metabolic feature indexes and then the formulas in DataFrame format. For that, we have to have a way to select the formulas that are considered since we may have multiple columns each with their own formula assignments. As ane xample, we choose one formula column and build the needed DataFrame two cells down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the necessary formula DataFrame\n",
    "filt_elems = pd.DataFrame()\n",
    "if mdin_type == 'Formula':\n",
    "    # Select the column with Formula Assignment you want to use\n",
    "    form_col = 'Formula_Assignment'\n",
    "\n",
    "    # Getting the column, dropping the peaks without formulas and the peaks which are isotopic peaks\n",
    "    form_df = processed_data.loc[:,[form_col]].dropna()\n",
    "    form_df = form_df.loc[[i for i in form_df.index if 'iso' not in form_df.loc[i, form_col]]]\n",
    "\n",
    "    elems = md.create_element_counts(form_df, formula_subset=[form_col,], compute_ratios=False)\n",
    "    filt_elems = elems.iloc[:,:-1]\n",
    "\n",
    "# Formula DataFrame\n",
    "filt_elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef802cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to build the Formula-Difference Networks\n",
    "if mdin_type == 'Formula':\n",
    "    # Column with mass values just to add as attributes\n",
    "    mass_val_col = 'Neutral Mass'\n",
    "    \n",
    "    # DF with the formulas in DataFrame format\n",
    "    filt_elems = filt_elems\n",
    "\n",
    "    # Transform MDB to suitable format\n",
    "    MDB_df = pd.DataFrame(dict(MDBs_to_use['Comp.'])).T\n",
    "\n",
    "    # Making MDB and filt_elems compatible\n",
    "    for col in MDB_df.columns:\n",
    "        if col not in filt_elems.columns:\n",
    "            filt_elems[col] = 0\n",
    "    for col in filt_elems.columns:\n",
    "        if col not in MDB_df.columns:\n",
    "            MDB_df[col] = 0\n",
    "    MDB_df = MDB_df[filt_elems.columns]\n",
    "\n",
    "    formula_df = processed_data.loc[filt_elems.index]\n",
    "    general_MDiN = md.FDiN_builder(formula_df, filt_elems, MDB_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d598f0",
   "metadata": {},
   "source": [
    "### Discarding all uninformative isolated nodes from the network, that is, the nodes that do not establish any connections\n",
    "\n",
    "You may also discard nodes from very small components as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of components in the general MDiN:')\n",
    "comp_len = []\n",
    "for i in sorted(nx.connected_components(general_MDiN), key=len, reverse=True):\n",
    "    comp_len.append(len(i))\n",
    "comp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude network components below a certain size (2 to at least remove isolated nodes)\n",
    "min_comp_size = 2\n",
    "\n",
    "comps = []\n",
    "for i in sorted(nx.connected_components(general_MDiN), key=len, reverse=True):\n",
    "    if len(i) > min_comp_size:\n",
    "        comps.extend(i)\n",
    "general_MDiN = general_MDiN.subgraph(comps)\n",
    "len(general_MDiN.nodes()) # Nº of nodes leftover in the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20b77f",
   "metadata": {},
   "source": [
    "## Building the Sample Mass-Difference Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to store sMDiNs\n",
    "sMDiNs = {}\n",
    "for samp in treated_data.index:\n",
    "    # Subgraphing sMDiN\n",
    "    idxs = [i for i in formula_df[\n",
    "        formula_df.loc[:,samp].replace({np.nan:0}) != 0].index]\n",
    "    ints = {i: treated_data.loc[samp, i] for i in formula_df[\n",
    "        formula_df.loc[:,samp].replace({np.nan:0}) != 0].index}\n",
    "    sMDiNs[samp] = general_MDiN.copy().subgraph(idxs)\n",
    "\n",
    "    # Storing intensity of feature in sample on the nodes\n",
    "    intensity_attr = dict.fromkeys(sMDiNs[samp].nodes(),0)\n",
    "    intensity_matrix = []\n",
    "    mass_matrix = []\n",
    "    for m in ints:\n",
    "        int_v = ints[m]\n",
    "        intensity_attr[m] = {'mass':formula_df.loc[m, mass_val_col], 'intensity': int_v}\n",
    "    nx.set_node_attributes(sMDiNs[samp], intensity_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517444b8",
   "metadata": {},
   "source": [
    "## Analysing Sample MDiNs\n",
    "\n",
    "There are many ways to analysis the sMDiNs built, and that is the true advantage of the method, here we show 2 of them based on the original paper where this methodology was explained\n",
    "\n",
    "- Degree analysis\n",
    "- MDBI - Mass-Difference based building block Impact analysis\n",
    "\n",
    "One measures of centrality: degree that keeps each node as a feature (no feature reduction) with its value for each sample being the respective metric value for each sample MDiN.\n",
    "\n",
    "**MDB Impact** is a measure of the impact that each MDB had in establishing a sample MDiN. To that end, counts of the number of edges established due to each MDB are counted in each sample MDiN - each MDB represents a set of chemical transformations. To allow comparison between samples with different number of edges the counts in each sample MDiN are transformed to a percentage. This analysis was made to see if the relative importance of the MDBs in establishing the networks is characteristic of the class the sample belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739ef253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Deg = {}\n",
    "MDB_Impact = {}\n",
    "\n",
    "for samp in treated_data.index:\n",
    "\n",
    "    # Centrality measures\n",
    "    Deg[samp] = dict(sMDiNs[samp].degree())\n",
    "\n",
    "    # MDB Impact\n",
    "    MDB_Impact[samp] = dict.fromkeys(list(MDBs_to_use.index), 0) # MDBs from the transformation list\n",
    "    for i in sMDiNs[samp].edges():\n",
    "        MDB_Impact[samp][sMDiNs[samp].edges()[i]['Transformation']] = MDB_Impact[samp][\n",
    "            sMDiNs[samp].edges()[i]['Transformation']] + 1\n",
    "\n",
    "# Centrality Measures\n",
    "Deg = pd.DataFrame.from_dict(Deg).replace({np.nan:0}).T\n",
    "\n",
    "# MDB Impact\n",
    "MDB_Impact = pd.DataFrame.from_dict(MDB_Impact).replace({np.nan:0})\n",
    "MDB_Impact = (MDB_Impact/MDB_Impact.sum()).T\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9721c6",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "\n",
    "Now, everyhting is in position to perform traditional statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the classes are those that you want\n",
    "classes = list(pd.unique(target))\n",
    "# customize label colors\n",
    "\n",
    "colours = sns.color_palette('tab10', 10) # Only room for 10 classes in this case, choose your colours\n",
    "#colours = ('coral', 'turquoise', 'gold', 'indigo', 'lightgreen') # Example for using named colours\n",
    "ordered_labels = classes # Put the classes, you can choose the order\n",
    "\n",
    "label_colours = {lbl: c for lbl, c in zip(ordered_labels, colours)}\n",
    "sample_colours = [label_colours[lbl] for lbl in target]\n",
    "\n",
    "# See the colours for each class\n",
    "sns.palplot(label_colours.values())\n",
    "new_ticks = plt.xticks(range(len(ordered_labels)), ordered_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d4073",
   "metadata": {},
   "source": [
    "## Unsupervised Statistical Analysis\n",
    "\n",
    "Unsupervised analysis means that the algorithms here do not receive the information of the different class labels.\n",
    "\n",
    "Here, we show PCA and Hierarchical Clustering (HCA) Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6556802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA(principaldf, label_colors, components=(1,2), title=\"PCA\", ax=None):\n",
    "    \"Plot the projection of samples in the 2 main components of a PCA model.\"\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    loc_c1, loc_c2 = [c - 1 for c in components]\n",
    "    col_c1_name, col_c2_name = principaldf.columns[[loc_c1, loc_c2]]\n",
    "\n",
    "    #ax.axis('equal')\n",
    "    ax.set_xlabel(f'{col_c1_name}')\n",
    "    ax.set_ylabel(f'{col_c2_name}')\n",
    "\n",
    "    unique_labels = principaldf['Label'].unique()\n",
    "\n",
    "    for lbl in unique_labels:\n",
    "        subset = principaldf[principaldf['Label']==lbl]\n",
    "        ax.scatter(subset[col_c1_name],\n",
    "                   subset[col_c2_name],\n",
    "                   s=50, color=label_colors[lbl], label=lbl)\n",
    "\n",
    "    #ax.legend(framealpha=1)\n",
    "    ax.set_title(title, fontsize=15)\n",
    "\n",
    "def plot_ellipses_PCA(principaldf, label_colors, components=(1,2),ax=None, q=None, nstd=2):\n",
    "    \"Plot confidence ellipses of a class' samples based on their projection in the 2 main components of a PCA model.\"\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    loc_c1, loc_c2 = [c - 1 for c in components]\n",
    "    points = principaldf.iloc[:, [loc_c1, loc_c2]]\n",
    "\n",
    "    #ax.axis('equal')\n",
    "\n",
    "    unique_labels = principaldf['Label'].unique()\n",
    "\n",
    "    for lbl in unique_labels:\n",
    "        subset_points = points[principaldf['Label']==lbl]\n",
    "        plot_confidence_ellipse(subset_points, q, nstd, ax=ax, ec=label_colors[lbl], fc='none')\n",
    "\n",
    "def color_list_to_matrix_and_cmap(colors, ind, axis=0):\n",
    "        if any(issubclass(type(x), list) for x in colors):\n",
    "            all_colors = set(itertools.chain(*colors))\n",
    "            n = len(colors)\n",
    "            m = len(colors[0])\n",
    "        else:\n",
    "            all_colors = set(colors)\n",
    "            n = 1\n",
    "            m = len(colors)\n",
    "            colors = [colors]\n",
    "        color_to_value = dict((col, i) for i, col in enumerate(all_colors))\n",
    "\n",
    "        matrix = np.array([color_to_value[c]\n",
    "                           for color in colors for c in color])\n",
    "\n",
    "        matrix = matrix.reshape((n, m))\n",
    "        matrix = matrix[:, ind]\n",
    "        if axis == 0:\n",
    "            # row-side:\n",
    "            matrix = matrix.T\n",
    "\n",
    "        cmap = mpl.colors.ListedColormap(all_colors)\n",
    "        return matrix, cmap\n",
    "\n",
    "def plot_dendogram(Z, leaf_names, label_colors, title='', ax=None, no_labels=False, labelsize=12, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    hier.dendrogram(Z, labels=leaf_names, leaf_font_size=10, above_threshold_color='0.2', orientation='left',\n",
    "                    ax=ax, **kwargs)\n",
    "    #Coloring labels\n",
    "    #ax.set_ylabel('Distance (AU)')\n",
    "    ax.set_xlabel('Distance (AU)')\n",
    "    ax.set_title(title, fontsize = 15)\n",
    "    \n",
    "    #ax.tick_params(axis='x', which='major', pad=12)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=labelsize, pad=12)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    #xlbls = ax.get_xmajorticklabels()\n",
    "    xlbls = ax.get_ymajorticklabels()\n",
    "    rectimage = []\n",
    "    for lbl in xlbls:\n",
    "        lbl_text = lbl.get_text()\n",
    "        if type(list(label_colors)[0]) == np.float64:\n",
    "            lbl_text = float(lbl_text)\n",
    "        col = label_colors[lbl_text]\n",
    "        lbl.set_color(col)\n",
    "        #lbl.set_fontweight('bold')\n",
    "        if no_labels:\n",
    "            lbl.set_color('w')\n",
    "        rectimage.append(col)\n",
    "\n",
    "    cols, cmap = color_list_to_matrix_and_cmap(rectimage, range(len(rectimage)), axis=0)\n",
    "\n",
    "    axins = inset_axes(ax, width=\"5%\", height=\"100%\",\n",
    "                   bbox_to_anchor=(1, 0, 1, 1),\n",
    "                   bbox_transform=ax.transAxes, loc=3, borderpad=0)\n",
    "\n",
    "    axins.pcolor(cols, cmap=cmap, edgecolors='w', linewidths=1)\n",
    "    axins.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004abe3",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA) - Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65884c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(6,6)) # Change the size of the figure\n",
    "\n",
    "principaldf_deg, var_deg, loadings_deg = metsta.compute_df_with_PCs_VE_loadings(Deg, \n",
    "                                       n_components=2, # Select number of components to calculate\n",
    "                                       whiten=True, labels=target, return_var_ratios_and_loadings=True)\n",
    "\n",
    "# Plot PCA\n",
    "ax.axis('equal')\n",
    "lcolors = label_colours\n",
    "\n",
    "plot_PCA(principaldf_deg, lcolors, \n",
    "         components=(1,2), # Select components to see\n",
    "         title='Degree', # Select title of plot\n",
    "         ax=ax)\n",
    "\n",
    "# Remove ellipses by putting a # before the next line\n",
    "plot_ellipses_PCA(principaldf_deg, \n",
    "                  lcolors, \n",
    "                  components=(1,2), # Select components to see\n",
    "                  ax=ax, \n",
    "                  q=0.95) # Confidence ellipse with 95% (q) confidence\n",
    "\n",
    "ax.set_xlabel(f'PC 1 ({var_deg[0] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "ax.set_ylabel(f'PC 2 ({var_deg[1] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "\n",
    "plt.legend(fontsize=15) # Set the size of labels\n",
    "plt.grid() # If you want a grid or not\n",
    "plt.show()\n",
    "#f.savefig('Name_PCAplot_smdinDeg.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6bbce9",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering Analysis (HCA) - Degree\n",
    "\n",
    "Performing Hierarchical Clustering.\n",
    "\n",
    "Distance metrics: 'euclidean' is the default, others are in https://docs.scipy.org/doc/scipy/reference/spatial.distance.html.\n",
    "\n",
    "Linkage metrics: **'ward', 'average'**, 'centroid', 'single', 'complete', 'weighted', 'median'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'euclidean' # Select distance metric\n",
    "method = 'ward' # Select linkage method\n",
    "\n",
    "distances = dist.pdist(Deg, metric=metric)\n",
    "Z = hier.linkage(distances, method=method)\n",
    "\n",
    "hca_res_deg = {'Z': Z, 'distances': distances}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot HCA\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 4), constrained_layout=True) # Set Figure Size\n",
    "    plot_dendogram(hca_res_deg['Z'], \n",
    "                   target, ax=ax,\n",
    "                   label_colors=label_colours,\n",
    "                   title='Degree', # Select title\n",
    "                   color_threshold=0) # Select a distance threshold from where different sets of lines are coloured\n",
    "\n",
    "    plt.show()\n",
    "    #f.savefig('Name_HCAplot_smdinDeg.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3878de3",
   "metadata": {},
   "source": [
    "If you want a version of a dendrogram more easy to change parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "# Plotting the dendrogram, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n",
    "# For details on how you can change different aspects of the dendrograms\n",
    "dn = hier.dendrogram(hca_res_deg['Z'], labels=target,\n",
    "                     leaf_font_size=13,\n",
    "                     above_threshold_color='b')\n",
    "# Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "# Coloring the labels with their specific colours\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl_text = lbl.get_text()\n",
    "    if type(list(label_colours)[0]) == np.float64:\n",
    "        lbl_text = float(lbl_text)\n",
    "    lbl.set_color(label_colours[lbl_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b48e30",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA) - MDB Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16baad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(6,6)) # Change the size of the figure\n",
    "\n",
    "principaldf_mdbi, var_mdbi, loadings_mdbi = metsta.compute_df_with_PCs_VE_loadings(MDB_Impact, \n",
    "                                       n_components=2, # Select number of components to calculate\n",
    "                                       whiten=True, labels=target, return_var_ratios_and_loadings=True)\n",
    "\n",
    "# Plot PCA\n",
    "ax.axis('equal')\n",
    "lcolors = label_colours\n",
    "\n",
    "plot_PCA(principaldf_mdbi, lcolors, \n",
    "         components=(1,2), # Select components to see\n",
    "         title='MDB Impact', # Select title of plot\n",
    "         ax=ax)\n",
    "\n",
    "# Remove ellipses by putting a # before the next line\n",
    "plot_ellipses_PCA(principaldf_mdbi, \n",
    "                  lcolors, \n",
    "                  components=(1,2), # Select components to see\n",
    "                  ax=ax, \n",
    "                  q=0.95) # Confidence ellipse with 95% (q) confidence\n",
    "\n",
    "ax.set_xlabel(f'PC 1 ({var_mdbi[0] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "ax.set_ylabel(f'PC 2 ({var_mdbi[1] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "\n",
    "plt.legend(fontsize=15) # Set the size of labels\n",
    "plt.grid() # If you want a grid or not\n",
    "plt.show()\n",
    "#f.savefig('Name_PCAplot_smdinMDBI.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437de79",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering Analysis (HCA) - MDB Impact\n",
    "\n",
    "Performing Hierarchical Clustering.\n",
    "\n",
    "Distance metrics: 'euclidean' is the default, others are in https://docs.scipy.org/doc/scipy/reference/spatial.distance.html.\n",
    "\n",
    "Linkage metrics: **'ward', 'average'**, 'centroid', 'single', 'complete', 'weighted', 'median'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'euclidean' # Select distance metric\n",
    "method = 'ward' # Select linkage method\n",
    "\n",
    "distances = dist.pdist(MDB_Impact, metric=metric)\n",
    "Z = hier.linkage(distances, method=method)\n",
    "\n",
    "hca_res_mdbi = {'Z': Z, 'distances': distances}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77164f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot HCA\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 4), constrained_layout=True) # Set Figure Size\n",
    "    plot_dendogram(hca_res_mdbi['Z'], \n",
    "                   target, ax=ax,\n",
    "                   label_colors=label_colours,\n",
    "                   title='MDB Impact', # Select title\n",
    "                   color_threshold=0) # Select a distance threshold from where different sets of lines are coloured\n",
    "\n",
    "    plt.show()\n",
    "    #f.savefig('Name_HCAplot_smdinMDBI.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e736d4b",
   "metadata": {},
   "source": [
    "If you want a version of a dendrogram more easy to change parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "# Plotting the dendrogram, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n",
    "# For details on how you can change different aspects of the dendrograms\n",
    "dn = hier.dendrogram(hca_res_mdbi['Z'], labels=target,\n",
    "                     leaf_font_size=13,\n",
    "                     above_threshold_color='b')\n",
    "# Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "# Coloring the labels with their specific colours\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl_text = lbl.get_text()\n",
    "    if type(list(label_colours)[0]) == np.float64:\n",
    "        lbl_text = float(lbl_text)\n",
    "    lbl.set_color(label_colours[lbl_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ddf141",
   "metadata": {},
   "source": [
    "## Supervised Statistical Analysis\n",
    "\n",
    "Supervised analysis means that the algorithms have access to label information. This means they are **not** indicated for the purpose of seeing if there are differences between classes/samples, only for seeing which metabolites are most important for those differences.\n",
    "\n",
    "The supervised statistical analysis methods currently implemented in this notebook are:\n",
    "- Random Forest Models (RFs)\n",
    "- Partial Least Squares (PLS)\n",
    "- Extreme Gradient Boosting (XGBoost)\n",
    "\n",
    "They all support both regression and classification problems, but may not be equally suitable for all use cases.\n",
    "\n",
    "XGBoost has thus far performed poorly in Binary classification problems, and both XGBoost and Random Forests may take a long time to run for regression problems, depending on the hyperparameters chosen.\n",
    "\n",
    "**Functions for this step are in metanalysis_standard.py and are an adaptation of functions in multianalysis.py (from the BinSim paper).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d120ae",
   "metadata": {},
   "source": [
    "First, you must intend if you intend to use the methods below to perform regressions or classifications. You may also change this in the parameter of individual method functions.\n",
    "\n",
    "If you pick regressions, please maake sure that the \"class\" labels are numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4e9d1",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "First: Minor optimization of the number of trees (200 is a good number to use though) - see when the accuracy of the model stops increasing and starts fluctuating around a certain value (that should be the minimum number of trees to use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random seed (number between the ()) if you don't want the results to change every time you run the code\n",
    "np.random.seed()\n",
    "\n",
    "# See maximum number of trees to search\n",
    "top_tree_in_grid=300\n",
    "\n",
    "# Vector with values for the parameter n_estimators\n",
    "# Models will be built from 10 to 300 trees in 5 tree intervals\n",
    "values = {'n_estimators': range(10,top_tree_in_grid,5)}\n",
    "\n",
    "if regression:\n",
    "    rf = skensemble.RandomForestRegressor(n_estimators=200)\n",
    "else:\n",
    "    rf = skensemble.RandomForestClassifier(n_estimators=200)\n",
    "    \n",
    "clf = GridSearchCV(rf, values, cv=3, n_jobs=-1) # Change cv to change cross-validation\n",
    "\n",
    "print('Fitting RFs...', end=' ')\n",
    "\n",
    "RF_optim = {'Degree':{}, 'MDBI':{}}\n",
    "\n",
    "# Degree Analysis\n",
    "clf.fit(Deg, target) # Fitting the data to RF models with all the different number of trees\n",
    "\n",
    "# Storing results\n",
    "RF_optim['Degree']['scores'] = list(clf.cv_results_['mean_test_score'])\n",
    "RF_optim['Degree']['n_trees'] = list(clf.cv_results_['param_n_estimators'])\n",
    "\n",
    "# MDB Impact Analysis\n",
    "clf.fit(MDB_Impact, target) # Fitting the data to RF models with all the different number of trees\n",
    "\n",
    "# Storing results\n",
    "RF_optim['MDBI']['scores'] = list(clf.cv_results_['mean_test_score'])\n",
    "RF_optim['MDBI']['n_trees'] = list(clf.cv_results_['param_n_estimators'])\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee46f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results and adjusting parameters of the plot\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(6,6), constrained_layout=True) # Set Figure Size\n",
    "\n",
    "        c_map = sns.color_palette('tab10', 10)\n",
    "\n",
    "        for treatment, c in zip(RF_optim.keys(), c_map):\n",
    "            ax.plot(RF_optim[treatment]['n_trees'], [s*100 for s in RF_optim[treatment]['scores']],\n",
    "                    label=treatment, color=c)\n",
    "        \n",
    "        ax.set_ylabel('Random Forest CV Mean Accuracy (%)', fontsize=15) # Set the y_label and size\n",
    "        ax.set_title('RF Optimization', fontsize=18) # Set the title and size\n",
    "        ax.set_ylim([30,101]) # Set the limits on the y axis\n",
    "\n",
    "        #f.suptitle('Optimization of the number of trees')\n",
    "        ax.legend(fontsize=15) # Set the legend and size\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ac186",
   "metadata": {},
   "source": [
    "### Fitting the RF model - Degree\n",
    "\n",
    "**See details of `RF_model` function (model fitting AND evaluation) in metanalysis_standard.py. Credit to initial function to the BinSim paper.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad031d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a number for the seed for consistent results\n",
    "np.random.seed()\n",
    "\n",
    "n_trees=200 # Number of trees in the model\n",
    "\n",
    "RF_results_deg = metsta.RF_model(Deg, target, regression, # Data, labels and if it's a regression or classification\n",
    "                return_cv=True, iter_num=5, # If you want cross validation results and number of iterations for it\n",
    "                n_trees=n_trees, # Number of trees in the model\n",
    "                cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "                # For Classification Problems\n",
    "                 metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted')) # Choose the perf. metrics\n",
    "\n",
    "                # For Regression problems\n",
    "                #metrics = ('neg_mean_squared_error',), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0b1a9",
   "metadata": {},
   "source": [
    "Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc128deb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in RF_results_deg.items():\n",
    "    if k != 'model' and k != 'imp_feat':\n",
    "        rf_results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(rf_results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38d15f",
   "metadata": {},
   "source": [
    "**Important Feature analysis**\n",
    "\n",
    "See the most important features for class discrimination (sorted by importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a132df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_rf_deg = processed_data.loc[list(general_MDiN.nodes()),\n",
    "                                  [i for i in processed_data.columns if i not in treated_data.index]].copy()\n",
    "imp_feats_rf_deg.insert(0,'Bucket label', imp_feats_rf_deg.index)\n",
    "imp_feats_rf_deg.insert(1,'Gini Importance', '')\n",
    "for n in range(len(RF_results_deg['imp_feat'])):\n",
    "    imp_feats_rf_deg['Gini Importance'].iloc[RF_results_deg['imp_feat'][n][0]] = RF_results_deg['imp_feat'][n][1]\n",
    "imp_feats_rf_deg = imp_feats_rf_deg.sort_values(by='Gini Importance', ascending=False)\n",
    "imp_feats_rf_deg.index = range(1, len(imp_feats_rf_deg)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667a851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_rf_deg.head(20) # Select number of features to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = True\n",
    "\n",
    "# Saving the most important features by their fraction 'frac_feat_impor'.\n",
    "# If None, saving the most important features based on a threshold 'VIP_Score_threshold'.\n",
    "# If also None, save the full dataset of all features\n",
    "frac_feat_impor = 0.02 # Fraction of features to save, If None the variable in the next line is used.\n",
    "score_threshold = None # Only used if variable above is None, threshold of score to consider a feature important.\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    if frac_feat_impor:\n",
    "        max_idx = int(frac_feat_impor*len(imp_feats_rf_deg))\n",
    "        filt_imp_feats_rf_deg = imp_feats_rf_deg.iloc[:max_idx]\n",
    "        filt_imp_feats_rf_deg.to_excel(f'RF_smdinDeg_ImpFeat_{frac_feat_impor*100}%.xlsx')\n",
    "    elif score_threshold:\n",
    "        filt_imp_feats_rf_deg = imp_feats_rf_deg[imp_feats_rf_deg['Gini Importance'] > score_threshold]\n",
    "        filt_imp_feats_rf_deg.to_excel(f'RF_smdinDeg_ImpFeat_GiniImpgreater{score_threshold}.xlsx')\n",
    "    else:\n",
    "        imp_feats_rf_deg.to_excel(f'RF_smdinDeg_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78821c14",
   "metadata": {},
   "source": [
    "### RF Permutation Test\n",
    "\n",
    "This is a test to observe if the model performance is significant, that is, if it is better than a random model. If it is, then the remaining results from the important features give meaningful information, if not, then you cannot use the important features results since they essentially mean nothing.\n",
    "\n",
    "The permutation test will permutate the class labels of your samples, that is, all classes will be randomized while maintaining the same number of samples per class and classes. Then, for each permutation it will see the model performance. \n",
    "\n",
    "The default metric for model performance is `accuracy`. If you have an imbalanced model, accuracy is not a good metric, so you should change to another such as `f1_weighted`.\n",
    "\n",
    "**Note: Permutation tests take a while to do, thus the default is False in the begginning so you can make a first analysis on your dataset. If you then want to use the results of a supervised model, run a permutation test to check if your model is significant.**\n",
    "\n",
    "p-value calculation: (1 + nº of times permutated model has better performance than non-permutated model)/nº of permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1938e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GENERATE = True # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random permutator)\n",
    "\n",
    "    perm_results_RF_deg = metsta.permutation_RF(\n",
    "        Deg, target, regression,  # data, labels and if it's a regression\n",
    "        iter_num=500, # Nº of permutations to do in your test - around 500 should be enough\n",
    "        n_trees=200, # Number of trees in the model\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        metric=('accuracy')) # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab861ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(Deg.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_RF_deg\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='RF Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('Nº of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('Random Forest Permutation Test - Degree', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_RF_PermutationTest_smdinDeg.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8bd088",
   "metadata": {},
   "source": [
    "### ROC curves (Receiver Operating Characteristic)\n",
    "\n",
    "This basically gives you an area under curve that the closer it is to 1, the better our model. We also iterate this n_iter times so we have a softer curve and to give as a better indication of the actual area under curve (AUC). This plots the true positive rate against the false positive rate.\n",
    "\n",
    "**Only possible for when your datasets have 2 classes. Choose the class which is considered the 'positive' class.**\n",
    "\n",
    "Credit to initial function to the BinSim paper.\n",
    "\n",
    "If you do not have 2 classes, skip ahead this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_RF_deg = metsta.RF_ROC_cv(Deg, target, regres=regression, # Data, target and if it's a regression\n",
    "                                        pos_label=pos_label, # Positive label\n",
    "                                        n_trees=200, # Number of trees of RF\n",
    "                                        n_iter=15, # Number of iterations to repeat \n",
    "                                        cv=None, n_fold=3) # Method of CV (None is stratified cv) and the number of folds\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        # Plot the ROC curves \n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_RF_deg\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set_title('Random Forest ROC Curve - Degree', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_RF_ROCcurve_smdinDeg.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d97947",
   "metadata": {},
   "source": [
    "### Fitting the RF model - MDB Impact\n",
    "\n",
    "**See details of `RF_model` function (model fitting AND evaluation) in metanalysis_standard.py. Credit to initial function to the BinSim paper.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a number for the seed for consistent results\n",
    "np.random.seed()\n",
    "\n",
    "n_trees=200 # Number of trees in the model\n",
    "\n",
    "RF_results_mdbi = metsta.RF_model(MDB_Impact, target, regression, # Data, labels and if it's a regression or classification\n",
    "                return_cv=True, iter_num=5, # If you want cross validation results and number of iterations for it\n",
    "                n_trees=n_trees, # Number of trees in the model\n",
    "                cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "                # For Classification Problems\n",
    "                 metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted')) # Choose the perf. metrics\n",
    "\n",
    "                # For Regression problems\n",
    "                #metrics = ('neg_mean_squared_error',), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048978b5",
   "metadata": {},
   "source": [
    "Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84915b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in RF_results_mdbi.items():\n",
    "    if k != 'model' and k != 'imp_feat':\n",
    "        rf_results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(rf_results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5aa74",
   "metadata": {},
   "source": [
    "**Important Feature analysis**\n",
    "\n",
    "See the most important features for class discrimination (sorted by importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe328269",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_rf_mdbi = pd.DataFrame(index=MDB_Impact.columns)\n",
    "imp_feats_rf_mdbi.insert(0,'Bucket label', imp_feats_rf_mdbi.index)\n",
    "imp_feats_rf_mdbi.insert(1,'Gini Importance', '')\n",
    "for n in range(len(RF_results_mdbi['imp_feat'])):\n",
    "    imp_feats_rf_mdbi['Gini Importance'].iloc[RF_results_mdbi['imp_feat'][n][0]] = RF_results_mdbi['imp_feat'][n][1]\n",
    "imp_feats_rf_mdbi = imp_feats_rf_mdbi.sort_values(by='Gini Importance', ascending=False)\n",
    "imp_feats_rf_mdbi.index = range(1, len(imp_feats_rf_mdbi)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91729756",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_rf_mdbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = True\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    imp_feats_rf_mdbi.to_excel(f'RF_smdinMDBI_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad23d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metabolinks.transformations as transf\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "tf = transf.FeatureScaler(method='standard')\n",
    "df = tf.fit_transform(MDB_Impact)\n",
    "df = df[imp_feats_rf_mdbi['Bucket label']]\n",
    "\n",
    "g = sns.heatmap(df.T, cmap='PRGn', vmin=-3, vmax=3)\n",
    "\n",
    "# Manually specify colorbar labelling after it's been generated\n",
    "colorbar = g.collections[0].colorbar\n",
    "colorbar.ax.tick_params(labelsize=14) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d78a683",
   "metadata": {},
   "source": [
    "### RF Permutation Test\n",
    "\n",
    "This is a test to observe if the model performance is significant, that is, if it is better than a random model. If it is, then the remaining results from the important features give meaningful information, if not, then you cannot use the important features results since they essentially mean nothing.\n",
    "\n",
    "The permutation test will permutate the class labels of your samples, that is, all classes will be randomized while maintaining the same number of samples per class and classes. Then, for each permutation it will see the model performance. \n",
    "\n",
    "The default metric for model performance is `accuracy`. If you have an imbalanced model, accuracy is not a good metric, so you should change to another such as `f1_weighted`.\n",
    "\n",
    "**Note: Permutation tests take a while to do, thus the default is False in the begginning so you can make a first analysis on your dataset. If you then want to use the results of a supervised model, run a permutation test to check if your model is significant.**\n",
    "\n",
    "p-value calculation: (1 + nº of times permutated model has better performance than non-permutated model)/nº of permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b035c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GENERATE = True # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random permutator)\n",
    "\n",
    "    perm_results_RF_mdbi = metsta.permutation_RF(\n",
    "        MDB_Impact, target, regression,  # data, labels and if it's a regression\n",
    "        iter_num=500, # Nº of permutations to do in your test - around 500 should be enough\n",
    "        n_trees=200, # Number of trees in the model\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        metric=('accuracy')) # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aeb682",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(MDB_Impact.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_RF_mdbi\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='RF Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('Nº of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('Random Forest Permutation Test - MDB Impact', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_RF_PermutationTest_smdinMDBI.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49411930",
   "metadata": {},
   "source": [
    "### ROC curves (Receiver Operating Characteristic)\n",
    "\n",
    "This basically gives you an area under curve that the closer it is to 1, the better our model. We also iterate this n_iter times so we have a softer curve and to give as a better indication of the actual area under curve (AUC). This plots the true positive rate against the false positive rate.\n",
    "\n",
    "**Only possible for when your datasets have 2 classes. Choose the class which is considered the 'positive' class.**\n",
    "\n",
    "Credit to initial function to the BinSim paper.\n",
    "\n",
    "If you do not have 2 classes, skip ahead this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a195b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_RF_mdbi = metsta.RF_ROC_cv(MDB_Impact, target, regres=regression, # Data, target and if it's a regression\n",
    "                                        pos_label=pos_label, # Positive label\n",
    "                                        n_trees=200, # Number of trees of RF\n",
    "                                        n_iter=15, # Number of iterations to repeat \n",
    "                                        cv=None, n_fold=3) # Method of CV (None is stratified cv) and the number of folds\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25794d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        # Plot the ROC curves \n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_RF_mdbi\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set_title('Random Forest ROC Curve - MDB Impact', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_RF_ROCcurve_smdinMDBI.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b1bebd",
   "metadata": {},
   "source": [
    "### PLS-DA (Partial Least Squares - Discriminant Analysis) - Degree\n",
    "\n",
    "First, an optimization of the number of components of PLS-DA and a **set of functions for PLS-DA - `optim_PLSDA_n_components` for example - to see in metanalysis_standard.**\n",
    "\n",
    "The VIPs scores are calculated using the function `_calculate_vips` in multianalysis.py that comes from the link https://www.researchgate.net/post/How-can-I-compute-Variable-Importance-in-Projection-VIP-in-Partial-Least-Squares-PLS as provided by Keiron Teilo O'Shea in that link.\n",
    "\n",
    "**Note: `max_comp` (maximum number of components) cannot be higher than the number of samples that will train a model minus 1. For example, if you have 15 samples and a 3-fold cross-validation each fold will have 5 samples. A training set will be comprised of two of those folds thus it will have 10 samples, thus `max_comp` (and `n_comp` later on) cannot be higher than 9. Another example if you have 22 samples and 5 folds, the folds will have 4/4/4/5/5 samples each. A training set will have four of these folds and the minimum sum of them is 4+4+4+5-1=16, thus max_comp cannot be higher than 16.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d797af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "# above is to supress PLS warnings\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed()\n",
    "\n",
    "max_comp = 9 # Max. number of components to search (the higher the more time it takes)\n",
    "\n",
    "# Store Results\n",
    "PLS_optim_deg = metsta.optim_PLSDA_n_components(Deg, target, regression, # Data, target and if it's a regression\n",
    "                                    encode2as1vector=True,\n",
    "                                    max_comp=max_comp, # Max. number of components to search\n",
    "                                    kf=None, n_fold=3, # Cross validation to use (none is stratified CV) and nº of folds\n",
    "                                    scale=False) # Set scale to True only if you did not do scaling in pre-treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98e38a",
   "metadata": {},
   "source": [
    "In the figure below, $R^{2}$ and $Q^{2}$ are shown. You want to choose the number of components **where $Q^{2}$ specifically** stops increasing, so, in this case, 4 components will be chosen. \n",
    "\n",
    "- $Q^{2}$ - PLS score by its mean squared error based on the test samples, thus it is ideal to test if the model will overfit. This will increase until a certain number of components that should be chosen. Then it usually stabilizes but from a certain point it might start to decrease which would mean the model is overfitting. For example, in this case, we choose 4 components based on this score, but you could choose 5 or 6 and it would not affect the model a lot.\n",
    "- $R^{2}$ - PLS score by its mean squared error based on the training samples used to make the model (it will be higher than $Q^{2}$ but it should not be used to choose the number of components. This metric always increases with the more components used which means it will overfit the model eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f54a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cols = sns.color_palette('tab10', 10) # Set the colors for the lines\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True) # Set the figure size\n",
    "        c = 0\n",
    "        for i, values in PLS_optim_deg.items():\n",
    "            if i =='CVscores':\n",
    "                name = 'Q$^2$'\n",
    "            else:\n",
    "                name = 'R$^2$'\n",
    "            \n",
    "            ax.plot(range(1, len(values) + 1), values, label=name, color = scores_cols[c])\n",
    "            c = c+1\n",
    "        \n",
    "        ax.set(xlabel='Number of Components', # Set the label for the x axis\n",
    "                ylabel='PLS Score') # Set the label for the Y axis\n",
    "        ax.legend(loc='lower right', fontsize=15) # Set the legend\n",
    "        ax.set_ylim([0, 1.02]) # Set limits for y axis\n",
    "        ax.set_xticks(range(0, len(values), 2)) # Set ticks that appear in the bottom of x axis\n",
    "        ax.set_title('Degree', fontsize=15)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0abac6f",
   "metadata": {},
   "source": [
    "### PLS-DA model fitting\n",
    "\n",
    "**See details of `PLSDA_model_cv` function (model fitting AND evaluation) in metanalysis_standard.py as adapted from the one in the BinSim paper.**\n",
    "\n",
    "The VIPs scores are calculated using the function `_calculate_vips` in multianalysis.py that comes from the link https://www.researchgate.net/post/How-can-I-compute-Variable-Importance-in-Projection-VIP-in-Partial-Least-Squares-PLS as provided by Keiron Teilo O'Shea in that link.\n",
    "\n",
    "The function `_generate_y_PLSDA` is also present in multianalysis.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "# above is to supress PLS warnings\n",
    "\n",
    "n_comp = 9 # Number of components of PLS-DA model - very important\n",
    "\n",
    "PLSDA_results_deg = metsta.PLSDA_model_CV(Deg, target, regression, # Data, target and if it's a regression\n",
    "                       n_comp=n_comp, # Number of components of PLS-DA model - very important\n",
    "                       kf = None, n_fold=3, # Cross validation to use (none is stratified CV) and nº of folds\n",
    "                       iter_num=10, # Number of iterations of cross-validation to do\n",
    "                       encode2as1vector=True,\n",
    "                       scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                       feat_type='VIP') # Feature Importance Metric to use, default is VIP scores (see function for others)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab48cd5",
   "metadata": {},
   "source": [
    "**Performance analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bfd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in PLSDA_results_deg.items():\n",
    "    if k != 'Q2' and k != 'imp_feat':\n",
    "        pls_results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(pls_results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b29742",
   "metadata": {},
   "source": [
    "**Important Feature analysis**\n",
    "\n",
    "See the most important features for class discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26929e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_plsda_deg = processed_data.loc[list(general_MDiN.nodes()),\n",
    "                                  [i for i in processed_data.columns if i not in treated_data.index]].copy()\n",
    "imp_feats_plsda_deg.insert(0,'Bucket label', imp_feats_plsda_deg.index)\n",
    "imp_feats_plsda_deg.insert(1,'VIP Score', '')\n",
    "for n in range(len(PLSDA_results_deg['imp_feat'])):\n",
    "    imp_feats_plsda_deg['VIP Score'].iloc[PLSDA_results_deg['imp_feat'][n][0]] = PLSDA_results_deg['imp_feat'][n][1]\n",
    "imp_feats_plsda_deg = imp_feats_plsda_deg.sort_values(by='VIP Score', ascending=False)\n",
    "imp_feats_plsda_deg.index = range(1, len(imp_feats_plsda_deg)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_plsda_deg.head(20) # Select number of features to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd9810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = True\n",
    "\n",
    "# Saving the most important features by their fraction 'frac_feat_impor'.\n",
    "# If None, saving the most important features based on a threshold 'VIP_Score_threshold'.\n",
    "# If also None, save the full dataset of all features\n",
    "frac_feat_impor = 0.02 # Fraction of features to save, If None the variable in the next line is used.\n",
    "VIP_Score_threshold = 1 # Only used if variable above is None, threshold of score to consider a feature important.\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    if frac_feat_impor:\n",
    "        max_idx = int(frac_feat_impor*len(imp_feats_plsda_deg))\n",
    "        filt_imp_feats_plsda_deg = imp_feats_plsda_deg.iloc[:max_idx]\n",
    "        filt_imp_feats_plsda_deg.to_excel(f'PLSDA_smdinDeg_ImpFeat_{frac_feat_impor*100}%.xlsx')\n",
    "    elif VIP_Score_threshold:\n",
    "        filt_imp_feats_plsda_deg = imp_feats_plsda_deg[imp_feats_plsda_deg['VIP Score'] > VIP_Score_threshold]\n",
    "        filt_imp_feats_plsda_deg.to_excel(f'PLSDA_smdinDeg_ImpFeat_VIPgreater{VIP_Score_threshold}.xlsx')\n",
    "    else:\n",
    "        imp_feats_plsda_deg.to_excel(f'PLSDA_smdinDeg_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf968d4c",
   "metadata": {},
   "source": [
    "### Sample Projection on the two most important Components/Latent Variables of PLS models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ce809",
   "metadata": {},
   "source": [
    "**To do** See if it's worth doing this in a regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not regression:\n",
    "    n_components = 4 # Nº of componentes\n",
    "\n",
    "    model, scores = fit_PLSDA_model(Deg, target,\n",
    "                                    n_comp=n_components, scale=False, # Only true if scaling was not done earlier\n",
    "                                    encode2as1vector=True,\n",
    "                                    lv_prefix='LV ', label_name='Label')\n",
    "\n",
    "    lcolors = label_colours\n",
    "\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "            fig, ax = plt.subplots(1,1, figsize=(6,6)) # Set up fig size\n",
    "            plot_PCA(scores, lcolors, title=\"PLS Projection - Degree\", ax=ax,\n",
    "                    components=(1,2)) # Select components to see\n",
    "            plt.title('PLS Projection - Degree', fontsize=20) # Title\n",
    "            plt.legend(loc='upper right', ncol=1, fontsize=15)  # Legend           \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            #fig.savefig('Name_PLSplot_smdinDeg.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41da830",
   "metadata": {},
   "source": [
    "### PLS-DA Permutation Test\n",
    "\n",
    "This is a test to observe if the model performance is significant, that is, if it is better than a random model. If it is, then the remaining results from the important features give meaningful information, if not, then you cannot use the important features results since they essentially mean nothing.\n",
    "\n",
    "The permutation test will permutate the class labels of your samples, that is, all classes will be randomized while maintaining the same number of samples per class and classes. Then, for each permutation it will see the model performance. \n",
    "\n",
    "The default metric for model performance is `accuracy`. If you have an imbalanced model, accuracy is not a good metric, so you should change to another such as `f1_weighted`. Metric can only be: `accuracy`, `f1_weighted`, `recall_weighted` or `precision_weighted`.\n",
    "\n",
    "**Note: Permutation tests take a while to do, thus the default is False in the begginning so you can make a first analysis on your dataset. If you then want to use the results of a supervised model, run a permutation test to check if your model is significant.**\n",
    "\n",
    "p-value calculation: (1 + nº of times permutated model has better performance than non-permutated model)/nº of permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64768d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GENERATE = True # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random state in the function below)\n",
    "\n",
    "    perm_results_PLSDA_deg = metsta.permutation_PLSDA(\n",
    "        Deg, target,  # data and labels\n",
    "        n_comp=4, # Number of components\n",
    "        iter_num=500, # Nº of permutations to do in your test - around 500 should be enough\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        encode2as1vector=True, scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "        metric='accuracy') # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(Deg.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_PLSDA_deg\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='PLS-DA Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('Nº of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('PLS-DA Permutation Test - Degree', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_PLSDA_PermutationTest_smdinDeg.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4e7d5",
   "metadata": {},
   "source": [
    "### ROC curves (Receiver Operating Characteristic)\n",
    "\n",
    "This basically gives you an area under curve that the closer it is to 1, the better our model. We also iterate this n_iter times so we have a softer curve and to give as a better indication of the actual area under curve (AUC). This plots the true positive rate against the false positive rate.\n",
    "\n",
    "**Only possible for when your datasets have 2 classes. Choose the class which is considered the 'positive' class.**\n",
    "\n",
    "Credit to initial function to the BinSim paper.\n",
    "\n",
    "If you do not have 2 classes, skip ahead this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ccc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_PLSDA_deg = metsta.PLSDA_ROC_cv(Deg, target, # Data and target\n",
    "                                pos_label=pos_label, # Positive label\n",
    "                                n_comp=4, # Number of components\n",
    "                                scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                                n_iter=15, # Number of iterations to repeat \n",
    "                                cv=None, n_fold=3) # method of cross-validation (None is stratified cv) and the number of folds\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643df7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves \n",
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_PLSDA_deg\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set(xlabel='False positive rate', ylabel='True positive rate')\n",
    "                ax.set_title('PLS-DA ROC Curve - Degree', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_PLSDA_ROCcurve_smdinDeg.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99085230",
   "metadata": {},
   "source": [
    "### PLS-DA (Partial Least Squares - Discriminant Analysis) - MDB Impact\n",
    "\n",
    "First, an optimization of the number of components of PLS-DA and a **set of functions for PLS-DA - `optim_PLSDA_n_components` for example - to see in metanalysis_standard.**\n",
    "\n",
    "The VIPs scores are calculated using the function `_calculate_vips` in multianalysis.py that comes from the link https://www.researchgate.net/post/How-can-I-compute-Variable-Importance-in-Projection-VIP-in-Partial-Least-Squares-PLS as provided by Keiron Teilo O'Shea in that link.\n",
    "\n",
    "**Note: `max_comp` (maximum number of components) cannot be higher than the number of samples that will train a model minus 1. For example, if you have 15 samples and a 3-fold cross-validation each fold will have 5 samples. A training set will be comprised of two of those folds thus it will have 10 samples, thus `max_comp` (and `n_comp` later on) cannot be higher than 9. Another example if you have 22 samples and 5 folds, the folds will have 4/4/4/5/5 samples each. A training set will have four of these folds and the minimum sum of them is 4+4+4+5-1=16, thus max_comp cannot be higher than 16.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "# above is to supress PLS warnings\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed()\n",
    "\n",
    "max_comp = 9 # Max. number of components to search (the higher the more time it takes)\n",
    "\n",
    "# Store Results\n",
    "PLS_optim_mdbi = metsta.optim_PLSDA_n_components(MDB_Impact, target, regression, # Data, target and if it's a regression\n",
    "                                    encode2as1vector=True,\n",
    "                                    max_comp=max_comp, # Max. number of components to search\n",
    "                                    kf=None, n_fold=3, # Cross validation to use (none is stratified CV) and nº of folds\n",
    "                                    scale=False) # Set scale to True only if you did not do scaling in pre-treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b33464",
   "metadata": {},
   "source": [
    "In the figure below, $R^{2}$ and $Q^{2}$ are shown. You want to choose the number of components **where $Q^{2}$ specifically** stops increasing, so, in this case, 4 components will be chosen. \n",
    "\n",
    "- $Q^{2}$ - PLS score by its mean squared error based on the test samples, thus it is ideal to test if the model will overfit. This will increase until a certain number of components that should be chosen. Then it usually stabilizes but from a certain point it might start to decrease which would mean the model is overfitting. For example, in this case, we choose 4 components based on this score, but you could choose 5 or 6 and it would not affect the model a lot.\n",
    "- $R^{2}$ - PLS score by its mean squared error based on the training samples used to make the model (it will be higher than $Q^{2}$ but it should not be used to choose the number of components. This metric always increases with the more components used which means it will overfit the model eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cols = sns.color_palette('tab10', 10) # Set the colors for the lines\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True) # Set the figure size\n",
    "        c = 0\n",
    "        for i, values in PLS_optim_mdbi.items():\n",
    "            if i =='CVscores':\n",
    "                name = 'Q$^2$'\n",
    "            else:\n",
    "                name = 'R$^2$'\n",
    "            \n",
    "            ax.plot(range(1, len(values) + 1), values, label=name, color = scores_cols[c])\n",
    "            c = c+1\n",
    "        \n",
    "        ax.set(xlabel='Number of Components', # Set the label for the x axis\n",
    "                ylabel='PLS Score') # Set the label for the Y axis\n",
    "        ax.legend(loc='lower right', fontsize=15) # Set the legend\n",
    "        ax.set_ylim([0, 1.02]) # Set limits for y axis\n",
    "        ax.set_xticks(range(0, len(values), 2)) # Set ticks that appear in the bottom of x axis\n",
    "        ax.set_title('MDB Impact', fontsize=15)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75646213",
   "metadata": {},
   "source": [
    "### PLS-DA model fitting\n",
    "\n",
    "**See details of `PLSDA_model_cv` function (model fitting AND evaluation) in metanalysis_standard.py as adapted from the one in the BinSim paper.**\n",
    "\n",
    "The VIPs scores are calculated using the function `_calculate_vips` in multianalysis.py that comes from the link https://www.researchgate.net/post/How-can-I-compute-Variable-Importance-in-Projection-VIP-in-Partial-Least-Squares-PLS as provided by Keiron Teilo O'Shea in that link.\n",
    "\n",
    "The function `_generate_y_PLSDA` is also present in multianalysis.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "# above is to supress PLS warnings\n",
    "\n",
    "n_comp = 4 # Number of components of PLS-DA model - very important\n",
    "\n",
    "PLSDA_results_mdbi = metsta.PLSDA_model_CV(MDB_Impact, target, regression, # Data, target and if it's a regression\n",
    "                       n_comp=n_comp, # Number of components of PLS-DA model - very important\n",
    "                       kf = None, n_fold=3, # Cross validation to use (none is stratified CV) and nº of folds\n",
    "                       iter_num=10, # Number of iterations of cross-validation to do\n",
    "                       encode2as1vector=True,\n",
    "                       scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                       feat_type='VIP') # Feature Importance Metric to use, default is VIP scores (see function for others)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70eead",
   "metadata": {},
   "source": [
    "**Performance analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c96c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in PLSDA_results_mdbi.items():\n",
    "    if k != 'Q2' and k != 'imp_feat':\n",
    "        pls_results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(pls_results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f778df0f",
   "metadata": {},
   "source": [
    "**Important Feature analysis**\n",
    "\n",
    "See the most important features for class discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97766f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_plsda_mdbi = pd.DataFrame(index=MDB_Impact.columns)\n",
    "imp_feats_plsda_mdbi.insert(0,'Bucket label', imp_feats_plsda_mdbi.index)\n",
    "imp_feats_plsda_mdbi.insert(1,'VIP Score', '')\n",
    "for n in range(len(PLSDA_results_mdbi['imp_feat'])):\n",
    "    imp_feats_plsda_mdbi['VIP Score'].iloc[PLSDA_results_mdbi['imp_feat'][n][0]] = PLSDA_results_mdbi['imp_feat'][n][1]\n",
    "imp_feats_plsda_mdbi = imp_feats_plsda_mdbi.sort_values(by='VIP Score', ascending=False)\n",
    "imp_feats_plsda_mdbi.index = range(1, len(imp_feats_plsda_mdbi)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15008966",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_plsda_mdbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc00d31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = True\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    imp_feats_plsda_mdbi.to_excel(f'PLSDA_smdinMDBI_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metabolinks.transformations as transf\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "tf = transf.FeatureScaler(method='standard')\n",
    "df = tf.fit_transform(MDB_Impact)\n",
    "df = df[imp_feats_plsda_mdbi['Bucket label']]\n",
    "\n",
    "g = sns.heatmap(df.T, cmap='PRGn', vmin=-3, vmax=3)\n",
    "\n",
    "# Manually specify colorbar labelling after it's been generated\n",
    "colorbar = g.collections[0].colorbar\n",
    "colorbar.ax.tick_params(labelsize=14) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ce2a7",
   "metadata": {},
   "source": [
    "### Sample Projection on the two most important Components/Latent Variables of PLS models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f97e94",
   "metadata": {},
   "source": [
    "**To do** See if it's worth doing this in a regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not regression:\n",
    "    n_components = 4 # Nº of componentes\n",
    "\n",
    "    model, scores = fit_PLSDA_model(MDB_Impact, target,\n",
    "                                    n_comp=n_components, scale=False, # Only true if scaling was not done earlier\n",
    "                                    encode2as1vector=True,\n",
    "                                    lv_prefix='LV ', label_name='Label')\n",
    "\n",
    "    lcolors = label_colours\n",
    "\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "            fig, ax = plt.subplots(1,1, figsize=(6,6)) # Set up fig size\n",
    "            plot_PCA(scores, lcolors, title=\"PLS Projection - MDB Impact\", ax=ax,\n",
    "                    components=(1,2)) # Select components to see\n",
    "            plt.title('PLS Projection - MDB Impact', fontsize=20) # Title\n",
    "            plt.legend(loc='upper right', ncol=1, fontsize=15)  # Legend           \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            #fig.savefig('Name_PLSplot_smdinMDBI.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba5096d",
   "metadata": {},
   "source": [
    "### PLS-DA Permutation Test\n",
    "\n",
    "This is a test to observe if the model performance is significant, that is, if it is better than a random model. If it is, then the remaining results from the important features give meaningful information, if not, then you cannot use the important features results since they essentially mean nothing.\n",
    "\n",
    "The permutation test will permutate the class labels of your samples, that is, all classes will be randomized while maintaining the same number of samples per class and classes. Then, for each permutation it will see the model performance. \n",
    "\n",
    "The default metric for model performance is `accuracy`. If you have an imbalanced model, accuracy is not a good metric, so you should change to another such as `f1_weighted`. Metric can only be: `accuracy`, `f1_weighted`, `recall_weighted` or `precision_weighted`.\n",
    "\n",
    "**Note: Permutation tests take a while to do, thus the default is False in the begginning so you can make a first analysis on your dataset. If you then want to use the results of a supervised model, run a permutation test to check if your model is significant.**\n",
    "\n",
    "p-value calculation: (1 + nº of times permutated model has better performance than non-permutated model)/nº of permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce8766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GENERATE = True # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random state in the function below)\n",
    "\n",
    "    perm_results_PLSDA_mdbi = metsta.permutation_PLSDA(\n",
    "        MDB_Impact, target,  # data and labels\n",
    "        n_comp=4, # Number of components\n",
    "        iter_num=500, # Nº of permutations to do in your test - around 500 should be enough\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        encode2as1vector=True, scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "        metric='accuracy') # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f48783",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(MDB_Impact.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_PLSDA_mdbi\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='PLS-DA Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('Nº of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('PLS-DA Permutation Test - MDB Impact', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_PLSDA_PermutationTest_smdinMDBI.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978431e0",
   "metadata": {},
   "source": [
    "### ROC curves (Receiver Operating Characteristic)\n",
    "\n",
    "This basically gives you an area under curve that the closer it is to 1, the better our model. We also iterate this n_iter times so we have a softer curve and to give as a better indication of the actual area under curve (AUC). This plots the true positive rate against the false positive rate.\n",
    "\n",
    "**Only possible for when your datasets have 2 classes. Choose the class which is considered the 'positive' class.**\n",
    "\n",
    "Credit to initial function to the BinSim paper.\n",
    "\n",
    "If you do not have 2 classes, skip ahead this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_PLSDA_mdbi = metsta.PLSDA_ROC_cv(MDB_Impact, target, # Data and target\n",
    "                                pos_label=pos_label, # Positive label\n",
    "                                n_comp=4, # Number of components\n",
    "                                scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                                n_iter=15, # Number of iterations to repeat \n",
    "                                cv=None, n_fold=3) # method of cross-validation (None is stratified cv) and the number of folds\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ddc5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves \n",
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_PLSDA_mdbi\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set(xlabel='False positive rate', ylabel='True positive rate')\n",
    "                ax.set_title('PLS-DA ROC Curve - MDB Impact', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_PLSDA_ROCcurve_smdinMDBI.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ffb871",
   "metadata": {},
   "source": [
    "### XGBoost (eXtreme Gradient Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b7c08",
   "metadata": {},
   "source": [
    "This block of code automatically selects an XGBoost objective function for your specific use case. If you want to use a different function, you may select it here, or in the 'objective' input to the functions.\n",
    "\n",
    "Some reading on objective functions:\n",
    "- https://xgboost.readthedocs.io/en/stable/parameter.html (Ctrl-F objective)\n",
    "- https://machinelearningmastery.com/xgboost-loss-functions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_analysis = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if regression:\n",
    "    objective = \"reg:squarederror\"\n",
    "else:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        print('Warning: XGBoost is currently unreliable for binary classification tasks. If you still want to use it delete xgb_analysis = False')\n",
    "        objective = \"binary:logistic\"\n",
    "        xgb_analysis = False\n",
    "    else:\n",
    "        objective = \"multi:softprob\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b9ab5",
   "metadata": {},
   "source": [
    "### XGBoost - Degree\n",
    "\n",
    "We first start with a brief optimization of the parameters for XGBoost training. Default is to focus only on the number of estimators (trees) and their maximum depth. However, there are other parameters that can be tweaked, simply by adding new terms to the xgb_optim_params dictionary. Please be aware that each new parameter will explonentially increase the running time of the function, and that for regression problem even just a single-parameter tuning can take very long.\n",
    "\n",
    "To 'fix' an hyperparater that you do not want to tune at a non-default value, simply add it to the XGB_optim function as **kwargs\n",
    "\n",
    "Resources on XGBoost Hyperparameters and their tuning:\n",
    "- https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "- https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning\n",
    "- https://freedium.cfd/https://towardsdatascience.com/xgboost-fine-tune-and-optimize-your-model-23d996fab663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea63679",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    # Select a random seed (number between the ()) if you don't want the results to change every time you run the code\n",
    "    np.random.seed()\n",
    "\n",
    "    xgb_max_n_estimators_deg = 300\n",
    "\n",
    "    xgb_optim_params_deg = {'n_estimators': range(10,xgb_max_n_estimators_deg+1,5)} \n",
    "\n",
    "    #xgb_optim_params = {'min_child_weight': numeric_range(0,1,0.1), 'subsample': numeric_range(0,1,0.1),\n",
    "    #                    'gamma': numeric_range(0,1,0.1), \n",
    "    #                    'max_depth': range(0,10,1)}\n",
    "\n",
    "    XGB_Optim_deg = metsta.optimise_xgb_parameters(Deg, target, xgb_optim_params_deg, regression, objective,\n",
    "                                                   n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2411847",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    param_to_plot = 'n_estimators'\n",
    "\n",
    "    # Plotting the results and adjusting parameters of the plot\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "            f, ax = plt.subplots(1, 1, figsize=(6,6), constrained_layout=True) # Set Figure Size\n",
    "\n",
    "            c_map = sns.color_palette('tab10', 10)\n",
    "\n",
    "            ax.plot(XGB_Optim_deg.cv_results_['param_n_estimators'],\n",
    "                    [s*100 for s in XGB_Optim_deg.cv_results_['mean_test_score']])\n",
    "            ax.set_ylabel('XGBoost CV Mean Accuracy (%)', fontsize=15) # Set the y_label and size\n",
    "            ax.set_xlabel(param_to_plot, fontsize=15)\n",
    "            ax.set_title('XGBoost - Degree', fontsize=18) # Set the title and size\n",
    "            ax.set_ylim([30,101]) # Set the limits on the y axis\n",
    "\n",
    "            #f.suptitle('Optimization of the number of trees')\n",
    "            ax.legend(fontsize=15) # Set the legend and size\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4929adf0",
   "metadata": {},
   "source": [
    "### Fitting the XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e63978",
   "metadata": {},
   "source": [
    "You may add more parameters to the function as **kwargs\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96819b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    n_estimators = 200\n",
    "\n",
    "    XGB_results_deg = metsta.XGB_model(Deg, target, # Data and labels\n",
    "                    regres=regression, obj=objective, # Regression or classification, and objective function\n",
    "                    return_cv=True, iter_num=5, # If you want cross validation results and number of iterations for it\n",
    "                    n_estimators=n_estimators, # Number of trees in the model\n",
    "                    cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "                    #metrics = ('neg_mean_squared_error', 'r2'), subsample=0.7)\n",
    "                    metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted')) #, gamma=0, min_child_weight=0.9, subsample=0.4), # Choose the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e774c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "    for k,v in XGB_results_deg.items():\n",
    "        if k != 'model' and k != 'imp_feat':\n",
    "            results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "    print(results_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05427ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    imp_feats_xgb_deg = processed_data.loc[list(general_MDiN.nodes()),\n",
    "                                  [i for i in processed_data.columns if i not in treated_data.index]].copy()\n",
    "    imp_feats_xgb_deg.insert(0,'Bucket label', imp_feats_xgb_deg.index)\n",
    "    imp_feats_xgb_deg.insert(1,'Feature Importance', '')\n",
    "    for n in range(len(XGB_results_deg['imp_feat'])):\n",
    "        imp_feats_xgb_deg['Feature Importance'].iloc[XGB_results_deg['imp_feat'][n][0]] = XGB_results_deg['imp_feat'][n][1]\n",
    "    imp_feats_xgb_deg = imp_feats_xgb_deg.sort_values(by='Feature Importance', ascending=False)\n",
    "    imp_feats_xgb_deg.index = range(1, len(imp_feats_xgb_deg)+1)\n",
    "else:\n",
    "    imp_feats_xgb_deg = 'XGBoost analysis was not performed'\n",
    "imp_feats_xgb_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9182588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_xgb_deg.head(20) # Select number of features to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e2b60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = True\n",
    "\n",
    "# Saving the most important features by their fraction 'frac_feat_impor'.\n",
    "# If None, save the full dataset of all features\n",
    "frac_feat_impor = 0.02 # Fraction of features to save, If None the variable in the next line is used.\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    if frac_feat_impor:\n",
    "        max_idx = int(frac_feat_impor*len(imp_feats_xgb_deg))\n",
    "        filt_imp_feats_xgb_deg = imp_feats_xgb_deg.iloc[:max_idx]\n",
    "        filt_imp_feats_xgb_deg.to_excel(f'XGB_smdinDeg_ImpFeat_{frac_feat_impor*100}%.xlsx')\n",
    "    else:\n",
    "        imp_feats_xgb_deg.to_excel(f'XGB_smdinDeg_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908fe4d",
   "metadata": {},
   "source": [
    "### XGBoost Permutation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE=True\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random permutator)\n",
    "\n",
    "    perm_results_XGB_deg = metsta.permutation_XGB(\n",
    "        Deg, target,  # data and labels\n",
    "        regres=regression, obj=objective, # regression vs classification and objective function \n",
    "        iter_num=100, # Nº of permutations to do in your test - around 500 should be enough\n",
    "        n_estimators=200, # Number of trees in the model\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        metric=('accuracy')) # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ca523",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(treated_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_XGB_deg\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='XGBoost Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('Nº of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('XGBoost Permutation Test - Degree', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_XGB_PermutationTest_smdinDeg.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef2e39b",
   "metadata": {},
   "source": [
    "### ROC Curves (Receiver Operating Characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a249ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_XGB_deg = metsta.XGB_ROC_cv(Deg, target, # Data and target\n",
    "                                        pos_label=pos_label, obj=objective, # Positive label and objective\n",
    "                                        n_estimators=200, # Number of trees of RF\n",
    "                                        n_iter=15, # Number of iterations to repeat \n",
    "                                        cv=None, n_fold=3) # Method of CV (None is stratified cv) and the number of folds\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813de7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves \n",
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_XGB_deg\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set(xlabel='False positive rate', ylabel='True positive rate')\n",
    "                ax.set_title('XGBoost ROC Curve - Degree', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_XGB_ROCcurve_smdinDeg.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b52e99",
   "metadata": {},
   "source": [
    "### XGBoost - MDB Impact\n",
    "\n",
    "We first start with a brief optimization of the parameters for XGBoost training. Default is to focus only on the number of estimators (trees) and their maximum depth. However, there are other parameters that can be tweaked, simply by adding new terms to the xgb_optim_params dictionary. Please be aware that each new parameter will explonentially increase the running time of the function, and that for regression problem even just a single-parameter tuning can take very long.\n",
    "\n",
    "To 'fix' an hyperparater that you do not want to tune at a non-default value, simply add it to the XGB_optim function as **kwargs\n",
    "\n",
    "Resources on XGBoost Hyperparameters and their tuning:\n",
    "- https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "- https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning\n",
    "- https://freedium.cfd/https://towardsdatascience.com/xgboost-fine-tune-and-optimize-your-model-23d996fab663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d441481",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    # Select a random seed (number between the ()) if you don't want the results to change every time you run the code\n",
    "    np.random.seed()\n",
    "\n",
    "    xgb_max_n_estimators_mdbi = 300\n",
    "\n",
    "    xgb_optim_params_mdbi = {'n_estimators': range(10,xgb_max_n_estimators_mdbi+1,5)} \n",
    "\n",
    "    #xgb_optim_params_mdbi = {'min_child_weight': numeric_range(0,1,0.1), 'subsample': numeric_range(0,1,0.1),\n",
    "    #'gamma': numeric_range(0,1,0.1), \n",
    "    #                    'max_depth': range(0,10,1)}\n",
    "\n",
    "    XGB_Optim_mdbi = metsta.optimise_xgb_parameters(MDB_Impact, target, xgb_optim_params_mdbi,\n",
    "                                               regression, objective, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    param_to_plot = 'n_estimators'\n",
    "\n",
    "    # Plotting the results and adjusting parameters of the plot\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "            f, ax = plt.subplots(1, 1, figsize=(6,6), constrained_layout=True) # Set Figure Size\n",
    "\n",
    "            c_map = sns.color_palette('tab10', 10)\n",
    "\n",
    "            ax.plot(XGB_Optim_mdbi.cv_results_['param_n_estimators'],\n",
    "                    [s*100 for s in XGB_Optim_mdbi.cv_results_['mean_test_score']])\n",
    "            ax.set_ylabel('XGBoost CV Mean Accuracy (%)', fontsize=15) # Set the y_label and size\n",
    "            ax.set_xlabel(param_to_plot, fontsize=15)\n",
    "            ax.set_title('XGBoost - MDB Impact', fontsize=18) # Set the title and size\n",
    "            ax.set_ylim([30,101]) # Set the limits on the y axis\n",
    "\n",
    "            #f.suptitle('Optimization of the number of trees')\n",
    "            ax.legend(fontsize=15) # Set the legend and size\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad80fe8",
   "metadata": {},
   "source": [
    "### Fitting the XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c98964",
   "metadata": {},
   "source": [
    "You may add more parameters to the function as **kwargs\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    n_estimators = 200\n",
    "\n",
    "    XGB_results_mdbi = metsta.XGB_model(MDB_Impact, target, # Data and labels\n",
    "                    regres=regression, obj=objective, # Regression or classification, and objective function\n",
    "                    return_cv=True, iter_num=5, # If you want cross validation results and number of iterations for it\n",
    "                    n_estimators=n_estimators, # Number of trees in the model\n",
    "                    cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "                    #metrics = ('neg_mean_squared_error', 'r2'), subsample=0.7)\n",
    "                    metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted')) #, gamma=0, min_child_weight=0.9, subsample=0.4), # Choose the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77229e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "    for k,v in XGB_results_mdbi.items():\n",
    "        if k != 'model' and k != 'imp_feat':\n",
    "            results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "    print(results_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe14a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    imp_feats_xgb_mdbi = pd.DataFrame(index=MDB_Impact.columns)\n",
    "    imp_feats_xgb_mdbi.insert(0,'Bucket label', imp_feats_xgb_mdbi.index)\n",
    "    imp_feats_xgb_mdbi.insert(1,'Feature Importance', '')\n",
    "    for n in range(len(XGB_results_mdbi['imp_feat'])):\n",
    "        imp_feats_xgb_mdbi['Feature Importance'].iloc[XGB_results_mdbi['imp_feat'][n][0]] = XGB_results_mdbi[\n",
    "            'imp_feat'][n][1]\n",
    "    imp_feats_xgb_mdbi = imp_feats_xgb_mdbi.sort_values(by='Feature Importance', ascending=False)\n",
    "    imp_feats_xgb_mdbi.index = range(1, len(imp_feats_xgb_mdbi)+1)\n",
    "else:\n",
    "    imp_feats_xgb_mdbi = 'XGBoost analysis was not performed'\n",
    "imp_feats_xgb_mdbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9a1f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = True\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    imp_feats_xgb_mdbi.to_excel(f'XGB_smdinMDBI_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc896653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metabolinks.transformations as transf\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "tf = transf.FeatureScaler(method='standard')\n",
    "df = tf.fit_transform(MDB_Impact)\n",
    "df = df[imp_feats_xgb_mdbi['Bucket label']]\n",
    "\n",
    "g = sns.heatmap(df.T, cmap='PRGn', vmin=-3, vmax=3)\n",
    "\n",
    "# Manually specify colorbar labelling after it's been generated\n",
    "colorbar = g.collections[0].colorbar\n",
    "colorbar.ax.tick_params(labelsize=14) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af71e98b",
   "metadata": {},
   "source": [
    "### XGBoost Permutation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141365a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE=True\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random permutator)\n",
    "\n",
    "    perm_results_XGB_mdbi = metsta.permutation_XGB(\n",
    "        MDB_Impact, target,  # data and labels\n",
    "        regres=regression, obj=objective, # regression vs classification and objective function \n",
    "        iter_num=100, # Nº of permutations to do in your test - around 500 should be enough\n",
    "        n_estimators=200, # Number of trees in the model\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        metric=('accuracy')) # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4ece2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(treated_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_XGB_mdbi\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='XGBoost Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('Nº of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('XGBoost Permutation Test - MDB Impact', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_XGB_PermutationTest_smdinMDBI.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82cbf6",
   "metadata": {},
   "source": [
    "### ROC Curves (Receiver Operating Characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ff764",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_XGB_mdbi = metsta.XGB_ROC_cv(MDB_Impact, target, # Data and target\n",
    "                                        pos_label=pos_label, obj=objective, # Positive label and objective\n",
    "                                        n_estimators=200, # Number of trees of RF\n",
    "                                        n_iter=15, # Number of iterations to repeat \n",
    "                                        cv=None, n_fold=3) # Method of CV (None is stratified cv) and the number of folds\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d6141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves \n",
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_XGB_mdbi\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set(xlabel='False positive rate', ylabel='True positive rate')\n",
    "                ax.set_title('XGBoost ROC Curve - MDB Impact', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_XGB_ROCcurve_smdinMDBI.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ceb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
