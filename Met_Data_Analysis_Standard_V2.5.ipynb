{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5b12b7",
   "metadata": {},
   "source": [
    "# Metabolomics Data Analysis - FT-ICR-MS-Lisboa\n",
    "\n",
    "This notebook provides a template for standard metabolomics data analysis whether or not you already annoted your data with names and/or chemical formulas using Metaboscape.\n",
    "\n",
    "This allows you to annotate, treat, see common and exclusive metabolites, do multivariate unsupervised and supervised statistical analysis, do univariate statistical analysis, produce Van Krevelen diagrams, Kendrick Mass Defect plots and chemical composition series. It also has compound finders that allow you to search for specific compounds using their names, chemical formulas, _m/z_'s or neutral masses.\n",
    "\n",
    "A wide variety of data pre-treatments is provided, but you don't have to use all of them. Some of the functions may seem intimidating, but they are easily costumizable and instructions to do that are provided.\n",
    "\n",
    "**Warning**: Reading files is very dependent on the format of the file, you'll have to see and adapt that part and not just press run all on the notebook.\n",
    "\n",
    "**Please inform us if you think something would be useful here that is not here already, other things you would like to be able to do or if something breaks spectacularly. As with 1.0 version, 2.0 version is likely to have some minor bugs and errors for specific cases that we will correct in future versions.**\n",
    "\n",
    "### References\n",
    "\n",
    "A lot of materials (Python functions) from the following paper was used for this pipeline (furthermore, BinSim analysis as described in the paper is also done here in the notebook):\n",
    "\n",
    "- Traquete, F.; Luz, J.; Cordeiro, C.; Sousa Silva, M.; Ferreira, A.E.N. Binary Simplification as an Effective Tool in Metabolomics Data Analysis. _Metabolites_ 2021, 11, doi:10.3390/metabo11110788.\n",
    "\n",
    "Apart from this, 3 specific Python libraries that are used should also be mentioned:\n",
    "\n",
    "- Metabolinks (our in-house Python library) - https://zenodo.org/record/5336951#.Y-TbpnbP1D8.\n",
    "- UpSetPlot (to make the UpSetPlots only) - https://pypi.org/project/UpSetPlot/0.8.0/.\n",
    "- Pyvenn (to make the Venn Diagrams only) - https://github.com/tctianchi/pyvenn.\n",
    "\n",
    "Finally, the most common Python libraries that are used here are pandas, numpy, scipy, scikit-learn, matplotlib and seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8af115",
   "metadata": {},
   "source": [
    "# Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "\n",
    "- **[Step 0: Installing Metabolinks and other packages](#step-0)**\n",
    "- **[Step 1: Upload your data](#step-1)**\n",
    "  - **[Step 1.1: Define your groups and see data characterization](#step-1_1)**\n",
    "  - **[Step 1.2: Annotate with Database(s)](#step-1_2)**\n",
    "  - **[Step 1.3: De-duplicating annotations](#step-1_3)**  \n",
    "- **[Step 2: Basic processing and pre-treatment](#step-2)**\n",
    "- **[Step 3: Find Common and Exclusive metabolites between the groups](#step-3)**\n",
    "- **[Step 4: Unsupervised Statistical Analysis (PCA and HCA)](#step-4)**\n",
    "- **[Step 5: Supervised Statistical Analysis (Random Forest and PLS-DA)](#step-5)**\n",
    "  - **[Step 5.1: Random Forest](#step-5_1)**\n",
    "  - **[Step 5.2: PLS-DA (Partial Least Squares - Discriminant Analysis)](#step-5_2)**\n",
    "  - **[Step 5.3: XGBoost (eXtreme Gradient Boosting)](#step-5_3)**\n",
    "- **[Step 6: Univariate Analysis and Fold-Change Analysis](#step-6)**\n",
    "  - **[Step 6.1: 2-class Univariate Statistical Analysis](#step-6_1)**\n",
    "  - **[Step 6.2: Multi-class Univariate Statistical Analysis](#step-6_2)**\n",
    "- **[Step 7: Make Van Krevelen Diagrams, Kendrick Mass Defect Plots and Chemical Composition series for your samples](#step-7)**\n",
    "- **[Step 8: Pathways Assignment of HMDB Annotated Metabolites](#step-8)**\n",
    "- **[Step 9: KEGG Colour Mapping](#step-9)**\n",
    "- **[Step 10: BinSim Specific Analysis](#step-10)**\n",
    "- **[Step 11: Find Specific Compounds](#step-11)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a369c",
   "metadata": {},
   "source": [
    "### Some common needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d575684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import itertools\n",
    "\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hier\n",
    "import scipy.stats as stats\n",
    "\n",
    "import sklearn.ensemble as skensemble\n",
    "from sklearn.metrics import (roc_auc_score, roc_curve, auc,\n",
    "                             f1_score, precision_score, recall_score)\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import ticker\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import upsetplot\n",
    "from upsetplot import from_contents\n",
    "from upsetplot import UpSet\n",
    "\n",
    "# Our Python package\n",
    "import metabolinks as mtl\n",
    "import metabolinks.transformations as transf\n",
    "\n",
    "# elips.py file (has to be in the same folder)\n",
    "from elips import plot_confidence_ellipse\n",
    "# venn.py file\n",
    "import venn as venn\n",
    "# metanalysis_standard.py file\n",
    "import metanalysis_standard as metsta\n",
    "# some functions from interface_aux_functions\n",
    "from interface_aux_functions import create_element_counts\n",
    "# multianalysis.py file (has to be in the same folder)\n",
    "from multianalysis import p_adjust_bh, fit_PLSDA_model, _calculate_vips, _generate_y_PLSDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ad46ed",
   "metadata": {},
   "source": [
    "# Step 0: Installing Metabolinks and other packages<a class=\"anchor\" id=\"step-0\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "**Metabolinks and UpSetPlot**\n",
    "\n",
    "- Open 'Command Line' or 'Linha de comandos' on your pc.\n",
    "- Run the line 'pip install metabolinks'.\n",
    "- Run the line 'pip install UpSetPlot'.\n",
    "- Run the line 'conda install -c conda-forge py-xgboost'.\n",
    "- Restart jupyter.\n",
    "\n",
    "**pyvenn**\n",
    "\n",
    "- Go to https://github.com/tctianchi/pyvenn/blob/master/venn.py.\n",
    "- Over 'Raw' (see where 'Watch' is on the upper left and move look down), click 'Save link as...'.\n",
    "- Save it on the same folder you have the rest of the files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed7c53",
   "metadata": {},
   "source": [
    "# Step 1: Upload your data <a class=\"anchor\" id=\"step-1\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "(**Warning**: Depending on the format of your file, this can be different!)\n",
    "\n",
    "This is made for csv and excel files extracted from MetaboScape but can also work with different data tables. Default is csv, excel is last block of text (remove # if you want to use it). If you have a target in the first row of your data, make `target_in_file` True.\n",
    "\n",
    "Select if the masses in the first column of your data (idx_masses) are Neutral masses ('Neutral'), m/z values obtained from positive ionization mode ('Positive') or negative ionization mode ('Negative') or if the values cannot be interpreted as masses ('None' - this will not allow you to perform data annotation downstream).\n",
    "\n",
    "What does this do?\n",
    "- Produces a pandas DataFrame with your spectral data\n",
    "- Renames the columns to obtain \"clean\" sample names (if necessary)\n",
    "- Replaces 0 values with numpy null objects (nan). This is necessary to know how many metabolites each sample has and to allow further data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For .csv or .xslsx from MetaboScape (they still might have some differences, for example in the headers)\n",
    "# Example\n",
    "\n",
    "filename = '5yeasts_notnorm.csv' # Name of your file\n",
    "#filename = 'Farinhas de Grilo (2).xlsx'\n",
    "## Indicate if the file read includes the target (sample classes) in its first row\n",
    "target_in_file = False\n",
    "idx_masses = 'Neutral' # 'Neutral' (neutral masses), 'Positive' (Obtained from ESI+), 'Negative' (Obtained from ESI-)\n",
    "# or 'None' (mass column cannot be inferred)\n",
    "\n",
    "\n",
    "# Samples names frequently have 00000. Use this code to make them 'cleaner'.\n",
    "# If not needed just skip this part (use #) when the function is applied\n",
    "def renamer(colname):\n",
    "    # Util to optionally remove all those 00000 from sample names\n",
    "    return ''.join(colname.split('00000'))\n",
    "\n",
    "# If it is a .csv file\n",
    "if filename.endswith('csv'):\n",
    "    if target_in_file: # If you have the target in the file\n",
    "        file = pd.read_csv(filename, header=[0,1])\n",
    "        colnames = [renamer(i) for i in file.columns.get_level_values(0)]\n",
    "        target_file = dict(zip(colnames, file.columns.get_level_values(1)))\n",
    "        file.columns = colnames\n",
    "\n",
    "    else: # If you do not have the target in the file\n",
    "        file = pd.read_csv(filename)\n",
    "        file.columns = [renamer(i) for i in file.columns]\n",
    "\n",
    "# If it is a .xlsx file\n",
    "elif filename.endswith('xlsx'):\n",
    "    if target_in_file: # If you have the target in the file\n",
    "        file = pd.read_excel(filename, header=[0,1])\n",
    "        colnames = [renamer(i) for i in file.columns.get_level_values(0)]\n",
    "        target_file = dict(zip(colnames, file.columns.get_level_values(1)))\n",
    "        file.columns = colnames\n",
    "\n",
    "    else: # If you do not have the target in the file\n",
    "        file = pd.read_excel(filename)\n",
    "        file.columns = [renamer(i) for i in file.columns]    \n",
    "else:\n",
    "    raise ValueError('Provided file is not an Excel or a csv file.')\n",
    "\n",
    " # Important for database match - calculating Neutral Mass / Probable m/z column if possible\n",
    "if idx_masses != 'None':\n",
    "    # If the masses in the index are Neutral\n",
    "    if idx_masses == 'Neutral':\n",
    "        file.insert(1, 'Neutral Mass', file[file.columns[0]].str.replace('Da', '').astype('float'))\n",
    "    # If the masses are m/z values obtained in Positive Ionization Mode\n",
    "    if idx_masses == 'Positive':\n",
    "        file.insert(1, 'Probable m/z', file[file.columns[0]].astype('str').str.replace('Da', '').astype('float'))\n",
    "    # If the masses are m/z values obtained in Negative Ionization Mode\n",
    "    elif idx_masses == 'Negative':\n",
    "        file.insert(1, 'Probable m/z', file[file.columns[0]].astype('str').str.replace('Da', '').astype('float'))\n",
    "\n",
    "file = file.set_index(file.columns[0])\n",
    "file.index.name = 'Bucket label'\n",
    "\n",
    "# Select the column with the masses to compare\n",
    "if idx_masses == 'Neutral':\n",
    "    mass_val_col = 'Neutral Mass'\n",
    "else:\n",
    "    mass_val_col = 'Probable m/z'\n",
    "\n",
    "# Replaces zeros with numpy nans. Essential for data processing\n",
    "file = file.replace({0.0:np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1661827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify metadata columns\n",
    "metadata_cols = ['Neutral Mass', 'Probable m/z', 'm/z', 'Formula', 'Name']\n",
    "\n",
    "# Identify sample columns - automatic based on metadata columns selected\n",
    "sample_cols = []\n",
    "for c in file.columns:\n",
    "    if c not in metadata_cols:\n",
    "        sample_cols.append(c)\n",
    "print(sample_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43692a7b",
   "metadata": {},
   "source": [
    "If you are working with a regression problem (labels are numerical values in a scale), set the regression parametre to True. Otherwise, it is assumed that you are working with a classification problem (label are categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501dbee8",
   "metadata": {},
   "source": [
    "# Step 1.1: Define your groups and see data characterization <a class=\"anchor\" id=\"step-1_1\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "Here, we will define our groups (yeast strains in our example), so that we can obtain merged dataframes for each one of them and define colours to help us visualise them in later figures.\n",
    "\n",
    "If your read file already included the target, we will use that one, confirm if it is correct. If it included but you want to change it, write the target you want and put `target_overwrite` to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your groups in the \"target_temp\" list by the exact order in which they appear in the dataframe.\n",
    "# Remember that each group must appear as many times as there are samples belonging to that group.\n",
    "# If your target was in the file you provided, you do not need to update this list\n",
    "target_temp = ['WT', 'WT', 'WT', 'dGRE3', 'dGRE3', 'dGRE3', 'dENO1', 'dENO1', 'dENO1', 'dGLO1', 'dGLO1', 'dGLO1',\n",
    "          'dGLO2', 'dGLO2', 'dGLO2']\n",
    "#target_temp = ['Aqua', 'Aqua', 'Aqua', 'Org', 'Org', 'Org']\n",
    "\n",
    "target_overwrite = False # Change in case you want to overwrite the target in file given\n",
    "\n",
    "target = target_temp # Default target\n",
    "\n",
    "if target_in_file:\n",
    "    target = [target_file[s] for s in sample_cols] # Update to target present in file provided\n",
    "\n",
    "    if target_overwrite:\n",
    "        target = target_temp # Overwrite target to the one defined by you\n",
    "\n",
    "\n",
    "# See if the classes are those that you want\n",
    "classes = list(pd.unique(target))\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab535e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Colors for plots to ensure consistency\n",
    "\n",
    "Play around with colours to get the ones you want. \n",
    "\n",
    "- Colormaps like the tab10 used below: https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "- List of names of individual colours: https://matplotlib.org/stable/gallery/color/named_colors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed722fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize label colors\n",
    "\n",
    "colours = sns.color_palette('tab10', 10) # Only room for 10 classes in this case, choose your colours\n",
    "#colours = ('coral', 'turquoise', 'gold', 'indigo', 'lightgreen') # Example for using named colours\n",
    "ordered_labels = classes # Put the classes, you can choose the order\n",
    "\n",
    "label_colours = {lbl: c for lbl, c in zip(ordered_labels, colours)}\n",
    "sample_colours = [label_colours[lbl] for lbl in target]\n",
    "\n",
    "# See the colours for each class\n",
    "sns.palplot(label_colours.values())\n",
    "new_ticks = plt.xticks(range(len(ordered_labels)), ordered_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b66ca72",
   "metadata": {},
   "source": [
    "Initial Filtering of the data if you want to do it. This function is explained and used in more detail after in **step 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2dbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_feature_appear = 2 # Select the minimum number of samples a feature must appear to be kept in the dataset\n",
    "\n",
    "meta_cols = [i for i in file.columns if i not in sample_cols]\n",
    "temp = metsta.basic_feat_filtering(file[sample_cols].T, target=None,\n",
    "                            filt_method='total_samples', # Method\n",
    "                            filt_kw=min_samples_feature_appear) # Make a sample have to appear\n",
    "file = pd.concat((file[meta_cols].reindex(temp.columns), temp.T), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1052601",
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5a8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See data characterization\n",
    "data_characteristics = metsta.characterize_data(file[sample_cols].T, target=target)\n",
    "data_characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f3967",
   "metadata": {},
   "source": [
    "**Remove the reference feature if you have already normalized your data by the reference feature previously**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_feat_lbl = ''\n",
    "\n",
    "if ref_feat_lbl != '':\n",
    "    file = file.drop(index=ref_feat_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290aead",
   "metadata": {},
   "source": [
    "# Step 1.2: Annotate with Database(s) <a class=\"anchor\" id=\"step-1_2\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "This is where you upload your database(s) to annotate your experimental dataset. \n",
    "\n",
    "Make sure that your file contains at least the following columns:\n",
    "- One with the databases accession label. This will serve as the index. In case you are a masochist and have opted to create your own database, make sure you give each compound an accession label (eg. DB0001, DB0002, DB0003, etc.)\n",
    "- One with the compounds' monoisotopic molecular masses (make sure that they are neutral masses)\n",
    "- One with the compounds' names\n",
    "- One with the compounds' chemical formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d384026c",
   "metadata": {},
   "source": [
    "For the sake of simplicity, the lists of compound IDs, names and formulas will be placed in different columns. Just remember that they will be added by the same order, so the first ID in the IDs column corresponds to the first name in the names column and the first formula in the formulas column.\n",
    "\n",
    "**See metanalysis_standard.py for functions about annotation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = { # How you want the database to be called in the data: 'HMDB', ' PCY', 'DBK'\n",
    "    'HMDB': {'File': 'hmdb_complete.xlsx', # The name of each file\n",
    "             'Index_name': 'accession', # The name of the index in each database\n",
    "             'Name_col': 'name', # The name column in each database\n",
    "             'Mass_col': 'monisotopic_molecular_weight', # The mass column in each database. Can be None\n",
    "             'Formula_col': 'chemical_formula'}, # The formula column in each database\n",
    "\n",
    "    'LTS': {'File': 'LOTUS_DB_Ver2.xlsx', \n",
    "             'Index_name': 'Wikidata_ID',\n",
    "             'Name_col': 'Name',\n",
    "             'Mass_col': 'Mass',\n",
    "             'Formula_col': 'Formula'},\n",
    "\n",
    "    'DBK': {'File': 'Drugbank_small_molecules_labeled.csv', \n",
    "             'Index_name': 'accession',\n",
    "             'Name_col': 'Name',\n",
    "             'Mass_col': None,\n",
    "             'Formula_col': 'Formula'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88721346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing it\n",
    "for d in dbs:\n",
    "    print(d, ' -> ', dbs[d]['File'], '|', dbs[d]['Index_name'],'|', dbs[d]['Mass_col'],'|', \n",
    "          dbs[d]['Name_col'],'|', dbs[d]['Formula_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload databases\n",
    "for d in dbs:\n",
    "    print('Processing '+d)\n",
    "    if dbs[d]['File'].endswith('.csv'):\n",
    "        db = pd.read_csv(dbs[d]['File']).set_index(dbs[d]['Index_name'])\n",
    "        if d == 'HMDB':\n",
    "            db['name'] = db['name'].str.replace(\"b'\", \"\")\n",
    "            db['name'] = db['name'].str.replace(\"'\", \"\")\n",
    "    elif dbs[d]['File'].endswith('.xlsx'):\n",
    "        db = pd.read_excel(dbs[d]['File']).set_index(dbs[d]['Index_name'])\n",
    "        if d == 'HMDB':\n",
    "            db['name'] = db['name'].str.replace(\"b'\", \"\")\n",
    "            db['name'] = db['name'].str.replace(\"'\", \"\")\n",
    "    else:\n",
    "        raise ValueError('File Format not accepted. Only csv and xlsx files are accepted.')\n",
    "    ##\n",
    "    if dbs[d]['Mass_col'] == None:\n",
    "        db['Calculated Mass'] = db[dbs[d]['Formula_col']].dropna().apply(metsta.calculate_monoisotopic_mass)\n",
    "        dbs[d]['Mass_col'] = 'Calculated Mass'\n",
    "    ##\n",
    "    dbs[d]['DB'] = db\n",
    "    print(d,'->', len(db.index), 'compounds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b2b9e",
   "metadata": {},
   "source": [
    "#### Select which adducts you want to search for in the analysis\n",
    "\n",
    "- Select adduct name and adduct mass shift in the dictionary - **At least one has to be selected to perform data annotation.**\n",
    "\n",
    "This will calculate a mass based on the shift provided for each compound in the selected databases, which will then be used to search for and match to the _m/z_ or Neutral masses in your dataset.\n",
    "\n",
    "Below, there are some examples for each of the 3 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c018c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_mass = 0.000548579909065\n",
    "\n",
    "if idx_masses == 'Neutral':\n",
    "    adducts_to_consider = {\n",
    "        'Neutral': 0}\n",
    "elif idx_masses == 'Positive':\n",
    "    adducts_to_consider = {\n",
    "        # Some common positive adducts to consider\n",
    "        'H+': metsta.chemdict['H'] - electron_mass,\n",
    "        'Na+': metsta.chemdict['Na'] - electron_mass,\n",
    "        'K+': metsta.chemdict['K'] - electron_mass,\n",
    "    }\n",
    "elif idx_masses == 'Negative':\n",
    "    adducts_to_consider = {\n",
    "        # Some common negative adducts to consider - Confirm if these are correct\n",
    "        'H-': - metsta.chemdict['H'] + electron_mass,\n",
    "        'Cl-': metsta.chemdict['Cl'] + electron_mass,\n",
    "    }\n",
    "else:\n",
    "    adducts_to_consider = {} # No annotation is possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2c63b",
   "metadata": {},
   "source": [
    "You can tune the parameter **ppm_margin** (first line of next cell) to select the maximum deviation you want for annotation.\n",
    "\n",
    "We give an overview of the annotation here, but you should see only after filtration what remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25383963",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ppm_margin = 1\n",
    "only_select_min_ppm = False # If True, when there are candidates for annotation with different ppm deviations, return only\n",
    "# The ones with the lowest ppm deviation\n",
    "\n",
    "# Annotation\n",
    "annotated_data = file.copy()\n",
    "    \n",
    "metsta.metabolite_annotation(annotated_data, dbs, ppm_margin, mass_val_col,\n",
    "                             adducts_to_consider=adducts_to_consider, only_select_min_ppm=only_select_min_ppm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23686835",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data.loc[annotated_data['Matched HMDB IDs'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a41613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_cols = [i for i in annotated_data.columns if i not in sample_cols]\n",
    "meta_cols_ids = [i for i in meta_cols if 'IDs' in i]\n",
    "meta_cols_names = [i for i in meta_cols if 'names' in i]\n",
    "meta_cols_formulas = [i for i in meta_cols if 'formulas' in i]\n",
    "meta_cols_mcounts = [i for i in meta_cols if 'match count' in i]\n",
    "print(meta_cols)\n",
    "print('------------')\n",
    "print(meta_cols_ids)\n",
    "print('------------')\n",
    "print(meta_cols_names)\n",
    "print('------------')\n",
    "print(meta_cols_formulas)\n",
    "print('------------')\n",
    "print(meta_cols_mcounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470cf2d0",
   "metadata": {},
   "source": [
    "# Step 1.3: De-duplicating annotations <a class=\"anchor\" id=\"step-1_3\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "**This is by far the least streamlined section of the notebook. Function is specifically for MetaboScape data.**\n",
    "\n",
    "Whether it is by MetaboScape or our script here in Python, due to the proximity of some m/z peaks, they can have the same exact compound annotation or in case of MetaboScape, formula.\n",
    "\n",
    "The following part merges peaks that have the same compound annotation on MetaboScape or the different databases here into one single peak. This should happen since a compound should not be split into multiple peaks generally, there is no biological reason for being multiple peaks with palmitic acid, for example. Usually there is one peak that is the 'main' one with much higher intensities across the samples, although some cases this does not happen with the two _m/z_ peaks have or the annotation comes from two different adducts.\n",
    "\n",
    "There is however a lot of problems and not ideal solutions being employed. In general, our procedure is the following.\n",
    "\n",
    "1) See peaks that have the same metabolite annotation by other databases.\n",
    "\n",
    "2) See if the other compound annotations do not have different annotations for those peaks.\n",
    "\n",
    "3) If not, save the meta data of the compound and formula annotations by the different databases.\n",
    "\n",
    "4) **Situation Trouble - If yes, then we may have a problem. If for example, HMDB puts two different compounds for the 2 _m/z_ peaks and LOTUS puts the same compound, it is fair to treat them as different peaks. HOWEVER, if there are more than two peaks assigned with the same formula, the following can happen. Let's imagine a scenario where HMDB puts the same compound for 4 _m/z_ peaks and LOTUS assigns to one of them one compound, to a second one a different compound and the last two ones does not assign a compound. What is the correct course of action? Right now, it just does not merge any of these peaks, but we could merge the two peaks that do not have an annotation by LOTUS. Would that be correct? Or should we merge with one of the two other peaks which have annotations by LOTUS. After all, they would normally be merged if not for the existence of two different LOTUS annotations. Hence, the problem.**\n",
    "\n",
    "4) Then create the new peak, by keeping the highest intensity value in each sample from the different peaks (our intensity values come from the maximum value in the peak and not peak area.\n",
    "\n",
    "5) Situation 1: If all the highest intensity values come from one _m/z_ peak, then that peak becomes the 'de facto' peak and all others are erased.\n",
    "\n",
    "6) Situation 2: The highest intensity comes from at least two different _m/z_ peaks and ALL peaks come from the same adduct **(including ones that are not used for the merge)**. Then, the peak 'bucket label', 'Neutral Mass' or 'Probable _m/z_' columns become the weighted average (based on the average intensity of the peaks) of all the peaks with the same annotation. If there are no multiple adducts accepted for annotation, this is the situation used.\n",
    "\n",
    "7) Situation 3: Identical to Situation 2 but there is at least one peak that comes from a different adduct based on Probable _m/z_ column. Then, the peak 'bucket label', 'Neutral Mass'/'Probable _m/z_' columns become identical to the peak which has the highest average intensity of all the peaks with the same annotation.\n",
    "\n",
    "8) This process is repeated for MetaboScape annotations and all databases first. And is then used for Smart Formula. **Usually the number of de-duplications made by each database should decrease since when you de-duplciate duplicate assignments by one database, you are usually de-duplicating in others.**\n",
    "\n",
    "\n",
    "**The problem mentioned should be rare. However, ALWAYS check the merge_problems variable. If it is NOT empty, then those merge problems issues might exist. We do not currently have an automatic answer for them. They should be seen on a case by case basis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c497399",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Name' in meta_cols:\n",
    "    #mcid = ['Name'] + meta_cols_ids\n",
    "    mcid = ['Name'] + list(dbs.keys())\n",
    "    \n",
    "else:\n",
    "    mcid = list(dbs.keys())\n",
    "    \n",
    "if 'Formula' in meta_cols:\n",
    "    mcid = mcid + ['Formula']\n",
    "\n",
    "if 'm/z' in meta_cols:\n",
    "    mz_col = True\n",
    "\n",
    "else:\n",
    "    mz_col=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b0f96e",
   "metadata": {},
   "source": [
    "Duplicate (or more) annotations report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe689d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in mcid:\n",
    "    n_duplicates = []\n",
    "    if col not in ['Name', 'Formula']:\n",
    "        col_alt = 'Matched '+col+' IDs'\n",
    "    else:\n",
    "        col_alt = col\n",
    "        col = 'MetaboScape ' + col\n",
    "    for i in annotated_data[annotated_data[col_alt].notnull()][col_alt]:\n",
    "        a = 0\n",
    "        for j in annotated_data[annotated_data[col_alt].notnull()][col_alt]:\n",
    "            if i==j:\n",
    "                if a == 1:\n",
    "                    #print(i)\n",
    "                    n_duplicates.append(i)\n",
    "                    break\n",
    "                a+=1\n",
    "    print(col)\n",
    "    print('Nº of same annotations on multiple peaks:        ', len(n_duplicates))\n",
    "    print('Total number of annotations for these cases:     ', len(pd.Series(n_duplicates, dtype='object').value_counts()))\n",
    "    if len(pd.Series(n_duplicates, dtype='object').value_counts()) == 0:\n",
    "        print('Maximum number of peaks with the same annotation:', 0)\n",
    "    else:\n",
    "        print('Maximum number of peaks with the same annotation:', pd.Series(n_duplicates).value_counts().iloc[0])\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data = annotated_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a686d1",
   "metadata": {},
   "source": [
    "Select if you want to perform de-duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_deduplication = True # False\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de85c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_adds = True if len(adducts_to_consider) > 1 else False\n",
    "\n",
    "if perform_deduplication:\n",
    "    annotated_data,mergings_performed,merging_situations,merge_description,merge_problems = metsta.duplicate_disambiguator(\n",
    "        annotated_data, # Our data\n",
    "        sample_cols, # Columns where the samples are\n",
    "        mcid=mcid,\n",
    "        mass_col=mass_val_col,\n",
    "        multiple_adds=multiple_adds, # If you have an m/z column\n",
    "        verbose=verbose) # If you want a more detailed output while the function runs\n",
    "else:\n",
    "    mergings_performed, merging_situations, merge_description, merge_problems = [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9906ed",
   "metadata": {},
   "source": [
    "### Seeing problems in merging\n",
    "\n",
    "**Example for this specific dataset**\n",
    "\n",
    "In this case, there are nine of them, although some are repeating. For example, the column with 0 and 5 are due to the same annotations as well as columns 1, 2, 6 and 7. So, in reality there are only 5 problems.\n",
    "\n",
    "Furthermore, columns 3 and 4 are due to different SmartFormula annotations (less reliable than annotations generally), so we can merge them by forcing the Formula to be the one from the peak with the highest average intensity.\n",
    "\n",
    "Thus we have 3 remaining problems. The problem is only really real when there are more than 2 different peaks, so in this case, only the problem with column 0 (same as with 5) should be the problem,. But, let's still see them to prove this.\n",
    "\n",
    "Let's see them individually.\n",
    "\n",
    "These potential problems should be incredibly rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2227cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_df = pd.DataFrame(merge_problems)\n",
    "problem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a00385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force merging the cases where the problem is the Formula\n",
    "# The Smart Formula that remains is the one corresponding to the  peak with the highest average intensity\n",
    "k_to_remove = []\n",
    "if len(problem_df)>0: \n",
    "    for k, v in merge_problems.items():\n",
    "        if v['Poss. Reason'] == 'Formula':\n",
    "            problem_case = v\n",
    "            if problem_case['Col Id.'] not in ['Name', 'Formula']:\n",
    "                db_problem = 'Matched '+problem_case['Col Id.']+' IDs'\n",
    "            else:\n",
    "                db_problem = problem_case['Col Id.']\n",
    "            idx_to_merge = list(k)\n",
    "\n",
    "            if len(idx_to_merge)>1:\n",
    "                annotated_data, desc = metsta.individually_merging(\n",
    "                    annotated_data, # Data\n",
    "                    idx_to_merge, # Your idx to merge\n",
    "                    sample_cols, mass_val_col, mcid, multiple_adds=multiple_adds)\n",
    "\n",
    "                desc[list(desc.keys())[0]]['Situation'] = desc[list(desc.keys())[0]]['Situation'] + '- Formula Problem'\n",
    "                # See if the description of the merging is what you wanted to achieve\n",
    "\n",
    "                # Supplementing the information to merging descriptors\n",
    "                merge_description[list(desc.keys())[0]] = desc[list(desc.keys())[0]]\n",
    "                if desc[list(desc.keys())[0]]['Situation'] in merging_situations:\n",
    "                    merging_situations[desc[list(desc.keys())[0]]['Situation']] += 1\n",
    "                else:\n",
    "                    merging_situations[desc[list(desc.keys())[0]]['Situation']] = 1\n",
    "                mergings_performed[desc[list(desc.keys())[0]]['DB']] += 1\n",
    "                k_to_remove.append(k)\n",
    "\n",
    "for k in k_to_remove:\n",
    "    merge_problems.pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a351104",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(merging_situations)>0:\n",
    "    merging_situations['Problems'] = len(merge_problems)\n",
    "problem_df = pd.DataFrame(merge_problems)\n",
    "problem_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca5e55",
   "metadata": {},
   "source": [
    "1) L-Cystathionine (columns 1, 2, 6 and 7)\n",
    "\n",
    "You can see L-Cystathionine formula is C24H48NO7P that is the annotation that leads to problems in column 6 and 7.\n",
    "\n",
    "The problem comes from an extra annotation in HMDB and LTS in one of the peaks: 'Acetamiprid' (in both cases). Different annotations so no issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data[annotated_data['Name'] == 'PC_16:1_9Z_0:0_'][meta_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894611aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ex = pd.DataFrame()\n",
    "if filename == '5yeasts_notnorm.csv':\n",
    "    ex = annotated_data[annotated_data['Name'] == 'L-Cystathionine'][meta_cols]\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aebe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.DataFrame()\n",
    "if filename == '5yeasts_notnorm.csv':\n",
    "    ex = annotated_data[annotated_data['Name'] == 'L-Cystathionine']['Matched HMDB names'].values\n",
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f5165",
   "metadata": {},
   "source": [
    "**2) PC_16:1_9Z_0:0_ (C26H52NO7P) - The major problem**\n",
    "\n",
    "Here, we have a representation of the major possible problem which hopefully you will not have to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405c2358",
   "metadata": {},
   "source": [
    "Solving the issue:\n",
    "\n",
    "- See the problem\n",
    "- See the idxs you want to manually merge (here we merge every peak other than the one with the extra LOTUS annotations since the first peak by HMDB and LOTUS has the same formula as all other peaks that do not have annotations.\n",
    "- See the DB where this problem happenned ('Name' in this case) and the annotation('PC_16:1_9Z_0:0_' in this case).\n",
    "- Use the `individually_merging` function and add the result to previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1459e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filename == '5yeasts_notnorm.csv':\n",
    "    problem_case = merge_problems[('493.3168156897 Da',\n",
    "  '493.3142206664 Da',\n",
    "  '493.3192028044 Da',\n",
    "  '493.3133493312 Da',\n",
    "  '493.3202367046 Da',\n",
    "  '493.3215300481 Da')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca86e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx_to_merge = []\n",
    "if filename == '5yeasts_notnorm.csv':\n",
    "    if problem_case['Col Id.'] not in ['Name', 'Formula']:\n",
    "        db_problem = 'Matched '+problem_case['Col Id.']+' IDs'\n",
    "    else:\n",
    "        db_problem = problem_case['Col Id.']\n",
    "\n",
    "    # Grab all the idxs of the annotation\n",
    "    idx_to_merge = list(('493.3168156897 Da','493.3142206664 Da','493.3192028044 Da','493.3133493312 Da',\n",
    "                          '493.3202367046 Da','493.3215300481 Da'))\n",
    "\n",
    "    idx_to_merge.remove('493.3192028044 Da') # Remove the one we don't want to merge in this case, the one with the extra\n",
    "    # LOTUS annotation\n",
    "\n",
    "idx_to_merge # Check if it is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cfcd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = []\n",
    "if filename == '5yeasts_notnorm.csv':\n",
    "    annotated_data, desc = metsta.individually_merging(\n",
    "        annotated_data, # Data\n",
    "        idx_to_merge, # Your idx to merge\n",
    "        sample_cols, mass_val_col, mcid, multiple_adds=True)\n",
    "\n",
    "# See if the description here is what you wanted to achieve\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if filename == '5yeasts_notnorm.csv':\n",
    "    # Supplementing the information to merging descriptors\n",
    "    merge_description[list(desc.keys())[0]] = desc[list(desc.keys())[0]]\n",
    "    if desc[list(desc.keys())[0]]['Situation'] in merging_situations:\n",
    "        merging_situations[desc[list(desc.keys())[0]]['Situation']] += 1\n",
    "    else:\n",
    "        merging_situations[desc[list(desc.keys())[0]]['Situation']] = 1\n",
    "    mergings_performed[desc[list(desc.keys())[0]]['DB']] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9d1eb",
   "metadata": {},
   "source": [
    "3) C24H48NO7P\n",
    "\n",
    "Same Formula but different MetaboScape annotations, thus no major problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d44cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex = pd.DataFrame()\n",
    "if filename == '5yeasts_notnorm.csv':\n",
    "    ex = annotated_data[annotated_data['Formula'] == 'C26H52NO7P'][meta_cols]\n",
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59579163",
   "metadata": {},
   "source": [
    "#### Example of merging\n",
    "\n",
    "See how there were 3 peaks with PE_16:1_9Z_0:0_ annotation with MetaboScape with one of them having an HMDB and Drugbank annotation in our software and another one with a LOTUS annotation. The method used was overwrite keeping the first of the three peaks as the 'true peak' and we moved the LOTUS annotation to that peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e511377",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ex = pd.DataFrame()\n",
    "if filename == '5yeasts_notnorm.csv':\n",
    "    ex = old_data.loc[[i for i in old_data.index if old_data.loc[i,'Name'] == 'PE_16:1_9Z_0:0_']][meta_cols]\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f294cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.DataFrame()\n",
    "if filename == '5yeasts_notnorm.csv':\n",
    "    ex = annotated_data.loc[[\n",
    "        i for i in annotated_data.index if annotated_data.loc[i,'Name'] == 'PE_16:1_9Z_0:0_']][meta_cols]\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.DataFrame()\n",
    "if filename == '5yeasts_notnorm.csv':\n",
    "    ex = old_data.loc[[i for i in old_data.index if old_data.loc[i,'Name'] == 'PE_16:1_9Z_0:0_']][sample_cols]\n",
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4094fc88",
   "metadata": {},
   "source": [
    "### Description of merging process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8240f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_desc = pd.DataFrame(merge_description)\n",
    "m_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(m_desc)>0:\n",
    "    print('Nº of Mergings:            ', len(m_desc.columns))\n",
    "    print('Nº of Peaks merged:        ', m_desc.loc['Nº merged peaks'].sum())\n",
    "    print('Nº of Peaks dropped:       ', m_desc.loc['Nº merged peaks'].sum() - len(m_desc.columns))\n",
    "    print('Nº of Peaks after merging: ', len(annotated_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74aa683",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergings_performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff52343",
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking all matches')\n",
    "if len(dbs) == 0:\n",
    "    if 'Name' in annotated_data.columns:\n",
    "        for i in tqdm(annotated_data.index):\n",
    "            df = annotated_data.loc[[i]]\n",
    "            hasmatch = df['Name'].notnull().values.any()\n",
    "            annotated_data.at[i, 'Has Match?'] = hasmatch\n",
    "        print('Nº of Annotated Compounds:', annotated_data[annotated_data['Has Match?'] == True].sum())\n",
    "    else:\n",
    "        print('No Check Neccessary')\n",
    "else:\n",
    "    if 'Name' in annotated_data.columns:\n",
    "        cols_to_see = ['Name'] + list(annotated_data.columns[-len(dbs)*5:])\n",
    "    else:\n",
    "        cols_to_see = list(annotated_data.columns[-len(dbs)*5:])\n",
    "    annotated_data['Has Match?'] = np.nan\n",
    "    for i in tqdm(annotated_data.index):\n",
    "        df = annotated_data.loc[[i]]\n",
    "        hasmatch = df[cols_to_see].notnull().values.any()\n",
    "        annotated_data.at[i, 'Has Match?'] = hasmatch\n",
    "    print('Nº of Annotated Compounds:', (annotated_data['Has Match?'] == True).sum())\n",
    "    print('---------------')\n",
    "\n",
    "annotated_data.info(verbose= True)\n",
    "annotated_data   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ba34a",
   "metadata": {},
   "source": [
    "# Step 2: Basic processing and pre-treatment <a class=\"anchor\" id=\"step-2\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "**Functions in metanalysis_standard!**\n",
    "\n",
    "These functions are compilations from the pre-treatments available in the **Metabolinks** Python package.\n",
    "\n",
    "Each step of this process has a different associated function that explain different methods available to do those steps that are included in the big all-including `filtering_pretreatment` function. By our experience, the default option in the different functions are the most common ones to use. There are way more options to use for all these steps, for example, for Missing Value Imputation that can be applied that are not present here and would have to be implemented.\n",
    "\n",
    "This returns four DataFrames:\n",
    "- **treated_data** - Data after filtering and pre-treatment with the samples ready for statistical analysis.\n",
    "- **processed_data** - Data after filtering and only normalization with samples and meta data used for compound finding and distinguishing between common and exclusive metabolites.\n",
    "- **univariate_data** - Data after filtering, imputation and only normalization used for fold change calculation in univariate analysis.\n",
    "- **meta_data** - Meta data with compound annotation and formulas for later.\n",
    "- **bin_data** - treated_data but with BinSim just because.\n",
    "\n",
    "**The procedures to be used need to be chosen by the user.**\n",
    "\n",
    "### Feature Filtering - `basic_feat_filtering` function\n",
    "\n",
    "This part removes the features that appear only in one sample (likely experimental artifacts and not real metabolites). If this is already done, skip this part by turning **_filt_method argument_ in `filtering_pretreatment` function to None**.\n",
    "\n",
    "**Available methods**: 'total_samples' (_default_), 'class_samples', None.\n",
    "\n",
    "**There can also be an extra step just keeping masses with annotations**: 'Formula', 'Name', None (_default_). Explained in the function.\n",
    "\n",
    "### Data Pre-Treatment\n",
    "\n",
    "There are many different ways these can be used but in general there are four categories: 'Missing Value Imputation', 'Normalization', 'Transformations' and 'Scaling' each with their options. If you do not want some types of pre-treatment, select None for that specific category (except missing value imputation, that HAS to be done).\n",
    "\n",
    "#### Note: If data was already normalized in MetaboScape, skip normalization by making _norm_ argument in `filtering_pretreatment` function to None and remember to remove Leucine Enkephalin peak (reference feature) if you have it (see cell imediately above step 1.2).\n",
    "\n",
    "Each different method for each category is explained in their respective functions. Each category has also a keyword (kw) that can be added since many methods have one parameter that can be changed. That keyword becomes that parameter.\n",
    "\n",
    "**Missing Value Imputation** (`missing_value_imputer`): 'min_sample' (_Default_), 'min_feat', 'min_data', 'zero'.\n",
    "\n",
    "**Normalization** by (`normalizer`): 'ref_feat' (_Default_), 'total_sum', 'PQN', 'Quantile', None.\n",
    "\n",
    "**Transformation** (`transformer`): 'glog' (_Default_), None.\n",
    "\n",
    "**Scaling** (`scaler`): 'pareto' (_Default_), 'mean_center', 'auto', 'range', 'vast', 'level', None.\n",
    "\n",
    "Furthermore, **Binary Simplification** (BinSim) is also returned as well and kept in bin_data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a0f68",
   "metadata": {},
   "source": [
    "#### Choose your feature filtering and data pre-treatment as you see fit \n",
    "\n",
    "##### See options for each step above and more detail in the function itself in the metanalysis_standard.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd943413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering based on number of times features appear\n",
    "filt_method='total_samples' # 'total_samples', 'class_samples', None\n",
    "filt_kw=2 # Nº of minimum samples of the dataset ('total_samples') or class ('class_samples') features have to appear in\n",
    "extra_filt=None # Filtering based on annotation of features 'Formula', 'Name' or None\n",
    "\n",
    "# Missing Value Imputations\n",
    "mvi='min_sample' # 'min_sample' (Default), 'min_feat', 'min_data', 'zero'\n",
    "mvi_kw=1/5 # Specific Keyword for MVI method\n",
    "\n",
    "# Normalization\n",
    "norm='total_sum' # 'ref_feat' (Default), 'total_sum', 'PQN', 'Quantile', None\n",
    "norm_kw='555.2692975341 Da' # Specific keyword for Normalization method\n",
    "\n",
    "# Transformation\n",
    "tf='glog' # 'glog' (Default), None\n",
    "tf_kw=None # Specific keyword for Transformation\n",
    "\n",
    "# Scaling\n",
    "scaling='pareto' # 'pareto' (Default), 'mean_center', 'auto', 'range', 'vast', 'level', None\n",
    "scaling_kw=None # Specific keyword for Scaling\n",
    "\n",
    "# Change the parameters in the variables above\n",
    "treated_data, processed_data, univariate_data, meta_data, bin_data = metsta.filtering_pretreatment(\n",
    "                  annotated_data, target,sample_cols,\n",
    "                  filt_method, filt_kw, extra_filt, # Filtering \n",
    "                  mvi, mvi_kw, # Missing value imputation\n",
    "                  norm, norm_kw, # Normalization\n",
    "                  tf, tf_kw, # Transformation\n",
    "                  scaling, scaling_kw) # Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98036b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_data.info()\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85794166",
   "metadata": {},
   "source": [
    "# Step 3: Find Common and Exclusive metabolites between the groups <a class=\"anchor\" id=\"step-3\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "First, make a dataframe for each class with only the features that appear in those classes. We will also make another set of DataFrames only considering annotated metabolites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample specific data frames\n",
    "groups = {}\n",
    "group_dfs = {}\n",
    "\n",
    "group_dfs_ids = {}\n",
    "#id_selection = \"Name\"\n",
    "\n",
    "for cl in classes:\n",
    "    groups[cl] = []\n",
    "    \n",
    "for c, t in zip(processed_data[sample_cols].columns, target):\n",
    "    for g in groups:\n",
    "        if g == t:\n",
    "            groups[g].append(c)\n",
    "            \n",
    "for g in groups:\n",
    "    for c, t in zip(processed_data[sample_cols].columns, target):\n",
    "        if g == t:\n",
    "            group_dfs[g] = processed_data.dropna(subset= groups[g], thresh=1)\n",
    "            group_dfs_ids[g] = group_dfs[g].iloc[[\n",
    "                i for i in range(len(group_dfs[g]['Has Match?'])) if group_dfs[g]['Has Match?'].iloc[i]]]\n",
    "\n",
    "for df in group_dfs:\n",
    "    print(df,  '------>', len(group_dfs[df]), 'metabolites from which', len(group_dfs_ids[df]), f'have matches')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc1358a",
   "metadata": {},
   "source": [
    "Now you have a specific dataframe for each individual group in your samples. They are all in a dictionary called group_dfs with the format name : dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed19235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example....\n",
    "print(f\"Here's the dataframe for one of the classes: {list(group_dfs.keys())[0]}\")\n",
    "group_dfs[list(group_dfs.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb7139e",
   "metadata": {},
   "source": [
    "We can now see the common and exclusive metabolites between these DataFrames.\n",
    "\n",
    "**See corresponding functions in metanalysis_standard.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common to all\n",
    "common_all = metsta.common(group_dfs.values())\n",
    "common_all_id = metsta.common(group_dfs_ids.values())\n",
    "print(len(common_all.index), f'metabolites are common to all group, {len(common_all_id.index)} with matches.')\n",
    "\n",
    "print('    ')\n",
    "\n",
    "# Common to two or more - Might become unintelligible if you have too many classes\n",
    "for n in range(2, len(group_dfs)+1):\n",
    "    for comb in itertools.combinations(group_dfs, n):\n",
    "        df_list = []\n",
    "        labels_list = []\n",
    "        df_id_list = []\n",
    "        for c in comb:\n",
    "            labels_list.append(c)\n",
    "            df = group_dfs[c]\n",
    "            df_list.append(df)\n",
    "            df_id_list.append(group_dfs_ids[c])\n",
    "        df_common = metsta.common(df_list)\n",
    "        df_id_common = metsta.common(df_id_list)\n",
    "        for s in group_dfs:\n",
    "            if s not in labels_list:\n",
    "                exclude = group_dfs[s]\n",
    "                df_common = df_common.loc[~(df_common.index.isin(exclude.index))]\n",
    "                df_id_common = df_id_common.loc[~(df_id_common.index.isin(group_dfs_ids[s].index))]\n",
    "        print(len(df_common.index), f'metabolites ({len(df_id_common.index)} with matches) are common to {comb}.') \n",
    "        \n",
    "print('     ')\n",
    "\n",
    "# Exclusive to only one group\n",
    "exclusives = metsta.exclusive(group_dfs.values())\n",
    "exclusives_id = metsta.exclusive(group_dfs_ids.values())\n",
    "exc_id = dict(zip(group_dfs, exclusives_id))\n",
    "exc = dict(zip(group_dfs, exclusives))\n",
    "for g in group_dfs:\n",
    "    print(len(exc[g].index), f'metabolites are exclusive to {g}, {len(exc_id[g].index)} with matches.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c01a88",
   "metadata": {},
   "source": [
    "**Venn Diagram**\n",
    "\n",
    "Plots made using the pyvenn git-hub repository (https://github.com/tctianchi/pyvenn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Venn diagram\n",
    "labels = venn.get_labels([group_dfs[i].index for i in group_dfs], fill=['number'])\n",
    "labels_ids = venn.get_labels([group_dfs_ids[i].index for i in group_dfs_ids], fill=['number'])\n",
    "\n",
    "labels_all = {}\n",
    "for i, j in labels.items():\n",
    "    labels_all[i] = j + f' ({labels_ids[i]})'\n",
    "    \n",
    "c = [(c[0], c[1], c[2], 0.3) for c in colours]\n",
    "\n",
    "if len(classes) == 2:\n",
    "    fig, ax = venn.venn2(labels_all, names=classes, figsize=(8,8), fontsize=11, colors=c, constrained_layout=True) # 2 Classes\n",
    "    plt.text(0.5,0, 'Nº of peaks (Nº of matched compounds)', fontsize=12, horizontalalignment='center')\n",
    "elif len(classes) == 3:\n",
    "    fig, ax = venn.venn3(labels_all, names=classes, figsize=(8,8), fontsize=11, colors=c, constrained_layout=True) # 3 Classes\n",
    "    plt.text(0.5,-0.05, 'Nº of peaks (Nº of matched compounds)', fontsize=12, horizontalalignment='center')\n",
    "elif len(classes) == 4:\n",
    "    fig, ax = venn.venn4(labels_all, names=classes, figsize=(8,8), fontsize=11, colors=c, constrained_layout=True) # 4 Classes\n",
    "    plt.text(0.5,0.05, 'Nº of peaks (Nº of matched compounds)', fontsize=12, horizontalalignment='center')\n",
    "elif len(classes) == 5:\n",
    "    fig, ax = venn.venn5(labels_all, names=classes, figsize=(8,8), fontsize=11, colors=c, constrained_layout=True) # 5 Classes\n",
    "    plt.text(0.5,0, 'Nº of peaks (Nº of matched compounds)', fontsize=12, horizontalalignment='center')\n",
    "elif len(classes) == 6:\n",
    "    fig, ax = venn.venn6(labels_all, names=classes, figsize=(8,8), fontsize=11, colors=c, constrained_layout=True) # 6 Classes\n",
    "    plt.text(0.5,0.2, 'Nº of peaks (Nº of matched compounds)', fontsize=12, horizontalalignment='center') \n",
    "else:\n",
    "    print(f'Venn Diagram can currently only be made with 2 to 6 different classes. You currently have {len(classes)} classes.')\n",
    "\n",
    "# Save the Venn Diagram\n",
    "#if len(classes) < 7:\n",
    "#    fig.savefig('VennDiagram_plot.png', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3375d1",
   "metadata": {},
   "source": [
    "**UpSetPlot** (not recommended for more than 6 classes also)\n",
    "\n",
    "UpSetPlots made using the package UpSetPlot (https://pypi.org/project/UpSetPlot/0.8.0/)\n",
    "\n",
    "See parameters two cells down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd0a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an upsetplot\n",
    "groups_dict = {}\n",
    "for df in group_dfs:\n",
    "    groups_dict[df] = group_dfs[df].index\n",
    "ups = from_contents(groups_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cdb821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "counts = True # Show absolute counts of metabolites on top of bars\n",
    "percentages = False # Show percentage of metabolites on top of bars\n",
    "include_annotated = False # Include annotated compounds as a bar of a different colour\n",
    "annotated_colour = 'Red' # Choose the color for the bar\n",
    "annotated_counts = False # Show absolute counts of annotated metabolites on top of the annotated metabolites bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08275e9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting UpSetPlot\n",
    "f,ax = plt.subplots(1,1, constrained_layout=True)\n",
    "ax.axis('Off')\n",
    "\n",
    "# Plot Main Upset Plot\n",
    "ax_dict = upsetplot.plot(ups, f, subset_size='count', show_counts=counts, show_percentages=percentages,\n",
    "                         sort_categories_by='input', include_empty_subsets=include_annotated)\n",
    "\n",
    "# Put counts of only annotated features if include_annotated = True\n",
    "if include_annotated:\n",
    "    groups_dict_id = {}\n",
    "    for df in group_dfs_ids:\n",
    "        groups_dict_id[df] = group_dfs_ids[df].index\n",
    "    ups_id = from_contents(groups_dict_id)\n",
    "    UpSet(ups_id, subset_size='count',facecolor=annotated_colour, sort_categories_by='input',\n",
    "          include_empty_subsets=include_annotated).plot_intersections(ax_dict['intersections'])\n",
    "    a=0\n",
    "    # Put the counts over the red, you might have to adjust the +15 part to something else depending on the counts you have\n",
    "    if annotated_counts:\n",
    "        for i in upsetplot.query(ups_id,sort_categories_by='input', include_empty_subsets=True).subset_sizes:\n",
    "            #print()\n",
    "            ax_dict['intersections'].text(\n",
    "                a,i+15, i, color='red', fontsize=10, zorder=15, horizontalalignment='center', weight=\"bold\")\n",
    "            a +=1\n",
    "\n",
    "# Save the UpSet Plot\n",
    "#fig.savefig('UpSetPlot_plot.png', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f978f",
   "metadata": {},
   "source": [
    "#### Setting an Excel file with the common and exclusive (to each class) annotated compounds\n",
    "\n",
    "Change **GENERATE_Excel_file** to True if you want to generate the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc722dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the excel files for exclusive compounds\n",
    "exclusive_dfs = {}\n",
    "for i in exc_id.keys():\n",
    "    df_temp = pd.DataFrame(index=exc_id[i].index)\n",
    "    df_temp['Appear in Class Samples'] = exc_id[i].loc[:, sample_cols].notnull().sum(axis=1)\n",
    "    df_temp['% of Class Samples'] = (exc_id[i].loc[:, sample_cols].notnull().sum(axis=1)) / target.count(i) * 100\n",
    "\n",
    "    if 'Name' in exc_id[i].columns:\n",
    "        df_temp['MetaboScape Match'] = exc_id[i]['Name']\n",
    "    if 'Formula' in exc_id[i].columns:\n",
    "        df_temp['MetaboScape Formula'] = exc_id[i]['Formula']\n",
    "    for col in meta_cols:\n",
    "        if col not in ['Neutral Mass', 'Probable m/z', 'm/z', 'Name', 'Formula', 'Has Match?']:\n",
    "            df_temp[col] = exc_id[i][col]\n",
    "    exclusive_dfs[i] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Exclusive df, ordered by the number of samples of that class they appear in\n",
    "print('Example for:', classes[0])\n",
    "exclusive_dfs[classes[0]].sort_values(by='Appear in Class Samples', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f21cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the excel files for common compounds\n",
    "common_temp = pd.DataFrame(index=common_all_id.index)\n",
    "common_temp['Appear in Samples'] = common_all_id.loc[:, sample_cols].notnull().sum(axis=1)\n",
    "common_temp['% of Samples'] = (common_all_id.loc[:, sample_cols].notnull().sum(axis=1)) / len(target) * 100\n",
    "if 'Name' in common_all_id.columns:\n",
    "    common_temp['MetaboScape Match'] = common_all_id['Name']\n",
    "if 'Formula' in common_all_id.columns:\n",
    "    common_temp['MetaboScape Formula'] = common_all_id['Formula']\n",
    "for col in meta_cols:\n",
    "    if col not in ['Neutral Mass', 'Probable m/z', 'm/z', 'Name', 'Formula', 'Has Match?']:\n",
    "        common_temp[col] = common_all_id[col]\n",
    "common_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d916ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_Excel_file = False # Change to True if you want to generate the file\n",
    "if GENERATE_Excel_file:\n",
    "    writer = pd.ExcelWriter('Common_Exclusive_Compounds.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    common_temp.to_excel(writer, sheet_name='Common')\n",
    "\n",
    "    text_format = writer.book.add_format({'text_wrap' : True, 'valign': 'top'})\n",
    "    for i in range(1, len(common_temp.columns)+1):\n",
    "        width=18\n",
    "        if i in [1,2]:\n",
    "            width=8\n",
    "        elif common_temp.columns[i-1].endswith('IDs'):\n",
    "            width=15\n",
    "        elif common_temp.columns[i-1].endswith('count'):\n",
    "            width=8\n",
    "        elif common_temp.columns[i-1].endswith('names') or common_temp.columns[i-1].endswith('Name'):\n",
    "            width=40\n",
    "        writer.sheets['Common'].set_column(i,i,width,text_format)\n",
    "\n",
    "    header_format = writer.book.add_format({'bold': True, 'text_wrap': True, 'valign': 'top'})\n",
    "    # Overwrite both the value and the format of each header cell\n",
    "    for col_num, value in enumerate(common_temp.columns.values):\n",
    "        writer.sheets['Common'].write(0, col_num + 1, value, header_format)\n",
    "\n",
    "    for a in exclusive_dfs.keys():\n",
    "        exclusive_dfs[a].to_excel(writer, sheet_name=str(a)+' Exclusive')\n",
    "\n",
    "        text_format = writer.book.add_format({'text_wrap' : True, 'valign': 'top'})\n",
    "        for i in range(1, len(exclusive_dfs[a].columns)+1):\n",
    "            width=18\n",
    "            if i in [1,2]:\n",
    "                width=8\n",
    "            elif exclusive_dfs[a].columns[i-1].endswith('IDs'):\n",
    "                width=15\n",
    "            elif exclusive_dfs[a].columns[i-1].endswith('count'):\n",
    "                width=8\n",
    "            elif exclusive_dfs[a].columns[i-1].endswith('names') or exclusive_dfs[a].columns[i-1].endswith('Name'):\n",
    "                width=40\n",
    "            writer.sheets[str(a)+' Exclusive'].set_column(i,i,width,text_format)\n",
    "\n",
    "        header_format = writer.book.add_format({'bold': True, 'text_wrap': True, 'valign': 'top'})\n",
    "        # Overwrite both the value and the format of each header cell\n",
    "        for col_num, value in enumerate(exclusive_dfs[a].columns.values):\n",
    "            writer.sheets[str(a)+' Exclusive'].write(0, col_num + 1, value, header_format)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d4073",
   "metadata": {},
   "source": [
    "# Step 4: Unsupervised Statistical Analysis <a class=\"anchor\" id=\"step-4\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "Unsupervised analysis means that the algorithms here do not receive the information of the different class labels.\n",
    "\n",
    "Here, we show PCA and Hierarchical Clustering (HCA) Analysis.\n",
    "\n",
    "The following functions were taken from the code git-hub repository 'binsim_paper' (from the files 'paper_binsim_data_prep.ipynb' and 'paper_binsim_unsupervised.ipynb')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6556802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA(principaldf, label_colors, components=(1,2), title=\"PCA\", ax=None):\n",
    "    \"Plot the projection of samples in the 2 main components of a PCA model.\"\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    loc_c1, loc_c2 = [c - 1 for c in components]\n",
    "    col_c1_name, col_c2_name = principaldf.columns[[loc_c1, loc_c2]]\n",
    "    \n",
    "    #ax.axis('equal')\n",
    "    ax.set_xlabel(f'{col_c1_name}')\n",
    "    ax.set_ylabel(f'{col_c2_name}')\n",
    "\n",
    "    unique_labels = principaldf['Label'].unique()\n",
    "\n",
    "    for lbl in unique_labels:\n",
    "        subset = principaldf[principaldf['Label']==lbl]\n",
    "        ax.scatter(subset[col_c1_name],\n",
    "                   subset[col_c2_name],\n",
    "                   s=50, color=label_colors[lbl], label=lbl)\n",
    "\n",
    "    #ax.legend(framealpha=1)\n",
    "    ax.set_title(title, fontsize=15)\n",
    "\n",
    "def plot_ellipses_PCA(principaldf, label_colors, components=(1,2),ax=None, q=None, nstd=2):\n",
    "    \"Plot confidence ellipses of a class' samples based on their projection in the 2 main components of a PCA model.\"\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    loc_c1, loc_c2 = [c - 1 for c in components]\n",
    "    points = principaldf.iloc[:, [loc_c1, loc_c2]]\n",
    "    \n",
    "    #ax.axis('equal')\n",
    "\n",
    "    unique_labels = principaldf['Label'].unique()\n",
    "\n",
    "    for lbl in unique_labels:\n",
    "        subset_points = points[principaldf['Label']==lbl]\n",
    "        plot_confidence_ellipse(subset_points, q, nstd, ax=ax, ec=label_colors[lbl], fc='none')\n",
    "\n",
    "def color_list_to_matrix_and_cmap(colors, ind, axis=0):\n",
    "        if any(issubclass(type(x), list) for x in colors):\n",
    "            all_colors = set(itertools.chain(*colors))\n",
    "            n = len(colors)\n",
    "            m = len(colors[0])\n",
    "        else:\n",
    "            all_colors = set(colors)\n",
    "            n = 1\n",
    "            m = len(colors)\n",
    "            colors = [colors]\n",
    "        color_to_value = dict((col, i) for i, col in enumerate(all_colors))\n",
    "\n",
    "        matrix = np.array([color_to_value[c]\n",
    "                           for color in colors for c in color])\n",
    "\n",
    "        matrix = matrix.reshape((n, m))\n",
    "        matrix = matrix[:, ind]\n",
    "        if axis == 0:\n",
    "            # row-side:\n",
    "            matrix = matrix.T\n",
    "\n",
    "        cmap = mpl.colors.ListedColormap(all_colors)\n",
    "        return matrix, cmap\n",
    "\n",
    "def plot_dendogram(Z, leaf_names, label_colors, title='', ax=None, no_labels=False, labelsize=12, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    hier.dendrogram(Z, labels=leaf_names, leaf_font_size=10, above_threshold_color='0.2', orientation='left',\n",
    "                    ax=ax, **kwargs)\n",
    "    #Coloring labels\n",
    "    #ax.set_ylabel('Distance (AU)')\n",
    "    ax.set_xlabel('Distance (AU)')\n",
    "    ax.set_title(title, fontsize = 15)\n",
    "    \n",
    "    #ax.tick_params(axis='x', which='major', pad=12)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=labelsize, pad=12)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    #xlbls = ax.get_xmajorticklabels()\n",
    "    xlbls = ax.get_ymajorticklabels()\n",
    "    rectimage = []\n",
    "    for lbl in xlbls:\n",
    "        lbl_text = lbl.get_text()\n",
    "        if type(list(label_colors)[0]) == np.float64:\n",
    "            lbl_text = float(lbl_text)\n",
    "        col = label_colors[lbl_text]\n",
    "        lbl.set_color(col)\n",
    "        #lbl.set_fontweight('bold')\n",
    "        if no_labels:\n",
    "            lbl.set_color('w')\n",
    "        rectimage.append(col)\n",
    "\n",
    "    cols, cmap = color_list_to_matrix_and_cmap(rectimage, range(len(rectimage)), axis=0)\n",
    "\n",
    "    axins = inset_axes(ax, width=\"5%\", height=\"100%\",\n",
    "                   bbox_to_anchor=(1, 0, 1, 1),\n",
    "                   bbox_transform=ax.transAxes, loc=3, borderpad=0)\n",
    "\n",
    "    axins.pcolor(cols, cmap=cmap, edgecolors='w', linewidths=1)\n",
    "    axins.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004abe3",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65884c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(6,6)) # Change the size of the figure\n",
    "\n",
    "principaldf, var, loadings = metsta.compute_df_with_PCs_VE_loadings(treated_data, \n",
    "                                       n_components=2, # Select number of components to calculate\n",
    "                                       whiten=True, labels=target, return_var_ratios_and_loadings=True)\n",
    "\n",
    "# Plot PCA\n",
    "ax.axis('equal')\n",
    "lcolors = label_colours\n",
    "\n",
    "plot_PCA(principaldf, lcolors, \n",
    "         components=(1,2), # Select components to see\n",
    "         title='', # Select title of plot\n",
    "         ax=ax)\n",
    "\n",
    "# Remove ellipses by putting a # before the next line\n",
    "plot_ellipses_PCA(principaldf, \n",
    "                  lcolors, \n",
    "                  components=(1,2), # Select components to see\n",
    "                  ax=ax, \n",
    "                  q=0.95) # Confidence ellipse with 95% (q) confidence\n",
    "\n",
    "ax.set_xlabel(f'PC 1 ({var[0] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "ax.set_ylabel(f'PC 2 ({var[1] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "\n",
    "plt.legend(fontsize=15) # Set the size of labels\n",
    "plt.grid() # If you want a grid or not\n",
    "plt.show()\n",
    "#f.savefig('Name_PCAplot.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6bbce9",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering Analysis (HCA)\n",
    "\n",
    "Performing Hierarchical Clustering.\n",
    "\n",
    "Distance metrics: 'euclidean' is the default, others are in https://docs.scipy.org/doc/scipy/reference/spatial.distance.html.\n",
    "\n",
    "Linkage metrics: **'ward', 'average'**, 'centroid', 'single', 'complete', 'weighted', 'median'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'euclidean' # Select distance metric\n",
    "method = 'ward' # Select linkage method\n",
    "\n",
    "distances = dist.pdist(treated_data, metric=metric)\n",
    "Z = hier.linkage(distances, method=method)\n",
    "\n",
    "hca_res = {'Z': Z, 'distances': distances}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot HCA\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 4), constrained_layout=True) # Set Figure Size\n",
    "    plot_dendogram(hca_res['Z'], \n",
    "                   target, ax=ax,\n",
    "                   label_colors=label_colours,\n",
    "                   title='', # Select title\n",
    "                   color_threshold=0) # Select a distance threshold from where different sets of lines are coloured\n",
    "\n",
    "    plt.show()\n",
    "    #f.savefig('Name_HCAplot.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3878de3",
   "metadata": {},
   "source": [
    "If you want a version of a dendrogram more easy to change parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "# Plotting the dendrogram, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n",
    "# For details on how you can change different aspects of the dendrograms\n",
    "dn = hier.dendrogram(hca_res['Z'], labels=target,\n",
    "                     leaf_font_size=13,\n",
    "                     above_threshold_color='b')\n",
    "# Coloring labels\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel('Distance (UA)')\n",
    "# Coloring the labels with their specific colours\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    lbl_text = lbl.get_text()\n",
    "    if type(list(label_colours)[0]) == np.float64:\n",
    "        lbl_text = float(lbl_text)\n",
    "    lbl.set_color(label_colours[lbl_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ddf141",
   "metadata": {},
   "source": [
    "# Step 5: Supervised Statistical Analysis <a class=\"anchor\" id=\"step-5\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "Supervised analysis means that the algorithms have access to label information. This means they are **not** indicated for the purpose of seeing if there are differences between classes/samples, only for seeing which metabolites are most important for those differences.\n",
    "\n",
    "The supervised statistical analysis methods currently implemented in this notebook are:\n",
    "- Random Forest Models (RFs)\n",
    "- Partial Least Squares (PLS)\n",
    "- Extreme Gradient Boosting (XGBoost)\n",
    "\n",
    "They all support both regression and classification problems, but may not be equally suitable for all use cases.\n",
    "\n",
    "XGBoost has thus far performed poorly in Binary classification problems, and both XGBoost and Random Forests may take a long time to run for regression problems, depending on the hyperparameters chosen.\n",
    "\n",
    "**Functions for this step are in metanalysis_standard.py and are an adaptation of functions in multianalysis.py (from the BinSim paper).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d120ae",
   "metadata": {},
   "source": [
    "First, you must intend if you intend to use the methods below to perform regressions or classifications. You may also change this in the parameter of individual method functions.\n",
    "\n",
    "If you pick regressions, please maake sure that the \"class\" labels are numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4e9d1",
   "metadata": {},
   "source": [
    "## Step 5.1: Random Forest <a class=\"anchor\" id=\"step-5_1\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "First: Minor optimization of the number of trees (200 is a good number to use though) - see when the accuracy of the model stops increasing and starts fluctuating around a certain value (that should be the minimum number of trees to use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random seed (number between the ()) if you don't want the results to change every time you run the code\n",
    "np.random.seed()\n",
    "\n",
    "# See maximum number of trees to search\n",
    "top_tree_in_grid=300\n",
    "\n",
    "# Vector with values for the parameter n_estimators\n",
    "# Models will be built from 10 to 300 trees in 5 tree intervals\n",
    "values = {'n_estimators': range(10,top_tree_in_grid,5)}\n",
    "\n",
    "if regression:\n",
    "    rf = skensemble.RandomForestRegressor(n_estimators=200)\n",
    "else:\n",
    "    rf = skensemble.RandomForestClassifier(n_estimators=200)\n",
    "    \n",
    "clf = GridSearchCV(rf, values, cv=3, n_jobs=-1) # Change cv to change cross-validation\n",
    "\n",
    "print('Fitting RFs...', end=' ')\n",
    "\n",
    "RF_optim = {'Treated':{}, 'BinSim':{}}\n",
    "clf.fit(treated_data, target) # Fitting the data to RF models with all the different number of trees\n",
    "\n",
    "# Storing results\n",
    "RF_optim['Treated']['scores'] = list(clf.cv_results_['mean_test_score'])\n",
    "RF_optim['Treated']['n_trees'] = list(clf.cv_results_['param_n_estimators'])\n",
    "\n",
    "# BinSim turn\n",
    "clf.fit(bin_data, target) # Fitting the data to RF models with all the different number of trees\n",
    "\n",
    "# Storing results\n",
    "RF_optim['BinSim']['scores'] = list(clf.cv_results_['mean_test_score'])\n",
    "RF_optim['BinSim']['n_trees'] = list(clf.cv_results_['param_n_estimators'])\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee46f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results and adjusting parameters of the plot\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(6,6), constrained_layout=True) # Set Figure Size\n",
    "\n",
    "        c_map = sns.color_palette('tab10', 10)\n",
    "\n",
    "        for treatment, c in zip(RF_optim.keys(), c_map):\n",
    "            ax.plot(RF_optim[treatment]['n_trees'], [s*100 for s in RF_optim[treatment]['scores']], label=treatment, color=c)\n",
    "        \n",
    "        ax.set_ylabel('Random Forest CV Mean Accuracy (%)', fontsize=15) # Set the y_label and size\n",
    "        ax.set_title('RF Optimization', fontsize=18) # Set the title and size\n",
    "        ax.set_ylim([30,101]) # Set the limits on the y axis\n",
    "\n",
    "        #f.suptitle('Optimization of the number of trees')\n",
    "        ax.legend(fontsize=15) # Set the legend and size\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d97947",
   "metadata": {},
   "source": [
    "### Fitting the RF model\n",
    "\n",
    "**See details of `RF_model` function (model fitting AND evaluation) in metanalysis_standard.py. Credit to initial function to the BinSim paper.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(df, y, regres, return_cv=True, iter_num=1, n_trees=200, cv=None, n_fold=5, \n",
    "             metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted'), **kwargs):\n",
    "    \"Fitting RF models and rturning the models and their cross-validation scores.\"\n",
    "    results = {}\n",
    "\n",
    "    if regres:\n",
    "        fitted_model = skensemble.RandomForestRegressor(n_estimators=n_trees)\n",
    "    else:\n",
    "        fitted_model = skensemble.RandomForestClassifier(n_estimators=n_trees)\n",
    "    \n",
    "    fitted_model = fitted_model.fit(df, y)\n",
    "    results['model'] = fitted_model\n",
    "\n",
    "    # Setting up variables for imp_feat storing\n",
    "    imp_feat = np.zeros((iter_num * n_fold, len(df.columns)))\n",
    "    f = 0\n",
    "\n",
    "    if not return_cv:\n",
    "        return(fitted_model)\n",
    "    if cv is None:\n",
    "        cv = sklearn.model_selection.StratifiedKFold(n_fold, shuffle=True)\n",
    "\n",
    "    if type(metrics) is str:\n",
    "        stores_res = {metrics:[]}\n",
    "    else:\n",
    "        store_res = {m:[] for m in metrics}\n",
    "\n",
    "    for _ in range(iter_num):\n",
    "        if regres:\n",
    "            rf = skensemble.RandomForestRegressor(n_estimators=n_trees)\n",
    "        else:\n",
    "            rf = skensemble.RandomForestClassifier(n_estimators=n_trees)\n",
    "        \n",
    "        cv_res = sklearn.model_selection.cross_validate(rf, df, y, cv=cv, scoring=metrics, **kwargs)\n",
    "        \n",
    "        if type(metrics) is str:\n",
    "            print(stores_res)\n",
    "            store_res[metrics].extend(cv_res['test_'+metrics])\n",
    "        else:\n",
    "            for i in metrics:\n",
    "                store_res[i].extend(cv_res['test_'+i])\n",
    "\n",
    "        for train_index, test_index in cv.split(df, y):\n",
    "            # Random Forest setup and fit\n",
    "            if regres:\n",
    "                rf = skensemble.RandomForestRegressor(n_estimators=n_trees)\n",
    "            else:\n",
    "                rf = skensemble.RandomForestClassifier(n_estimators=n_trees)\n",
    "            X_train, X_test = df.iloc[train_index, :], df.iloc[test_index, :]\n",
    "            y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "            rf.fit(X_train, y_train)\n",
    "\n",
    "            # Compute important features\n",
    "            imp_feat[f, :] = rf.feature_importances_ # Importance of each feature\n",
    "            f = f + 1\n",
    "\n",
    "    # Collect and order all important features values from each Random Forest\n",
    "    imp_feat_sum = imp_feat.sum(axis=0) / (iter_num * n_fold)\n",
    "    results['imp_feat'] = sorted(enumerate(imp_feat_sum), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    results.update(store_res)\n",
    "    return results#{'model': fitted_model, 'cv_scores': scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a number for the seed for consistent results\n",
    "np.random.seed()\n",
    "\n",
    "n_trees=200 # Number of trees in the model\n",
    "\n",
    "RF_results = metsta.RF_model(treated_data, target, regression, # Data, labels and if it's a regression or classification\n",
    "                return_cv=True, iter_num=5, # If you want cross validation results and number of iterations for it\n",
    "                n_trees=n_trees, # Number of trees in the model\n",
    "                cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "    \n",
    "        # For Classification Problems\n",
    "         metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted')) # Choose the performance metrics\n",
    "\n",
    "        # For Regression problems\n",
    "        #metrics = ('neg_mean_squared_error',), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048978b5",
   "metadata": {},
   "source": [
    "Performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84915b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in RF_results.items():\n",
    "    if k != 'model' and k != 'imp_feat':\n",
    "        rf_results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(rf_results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5aa74",
   "metadata": {},
   "source": [
    "**Important Feature analysis**\n",
    "\n",
    "See the most important features for class discrimination (sorted by importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe328269",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_rf = meta_data.copy()\n",
    "imp_feats_rf.insert(0,'Bucket label', imp_feats_rf.index)\n",
    "imp_feats_rf.insert(1,'Gini Importance', '')\n",
    "for n in range(len(RF_results['imp_feat'])):\n",
    "    imp_feats_rf['Gini Importance'].iloc[RF_results['imp_feat'][n][0]] = RF_results['imp_feat'][n][1]\n",
    "imp_feats_rf = imp_feats_rf.sort_values(by='Gini Importance', ascending=False)\n",
    "imp_feats_rf.index = range(1, len(imp_feats_rf)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91729756",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_rf.head(20) # Select number of features to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = False\n",
    "\n",
    "# Saving the most important features by their fraction 'frac_feat_impor'.\n",
    "# If None, saving the most important features based on a threshold 'VIP_Score_threshold'.\n",
    "# If also None, save the full dataset of all features\n",
    "frac_feat_impor = 0.02 # Fraction of features to save, If None the variable in the next line is used.\n",
    "score_threshold = None # Only used if variable above is None, threshold of score to consider a feature important.\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    if frac_feat_impor:\n",
    "        max_idx = int(frac_feat_impor*len(imp_feats_rf))\n",
    "        filt_imp_feats_rf = imp_feats_rf.iloc[:max_idx]\n",
    "        filt_imp_feats_rf.to_excel(f'RF_ImpFeat_{frac_feat_impor*100}%.xlsx')\n",
    "    elif score_threshold:\n",
    "        filt_imp_feats_rf = imp_feats_rf[imp_feats_rf['Gini Importance'] > score_threshold]\n",
    "        filt_imp_feats_rf.to_excel(f'RF_ImpFeat_GiniImpgreater{score_threshold}.xlsx')\n",
    "    else:\n",
    "        imp_feats_rf.to_excel(f'RF_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78821c14",
   "metadata": {},
   "source": [
    "### RF Permutation Test\n",
    "\n",
    "This is a test to observe if the model performance is significant, that is, if it is better than a random model. If it is, then the remaining results from the important features give meaningful information, if not, then you cannot use the important features results since they essentially mean nothing.\n",
    "\n",
    "The permutation test will permutate the class labels of your samples, that is, all classes will be randomized while maintaining the same number of samples per class and classes. Then, for each permutation it will see the model performance. \n",
    "\n",
    "The default metric for model performance is `accuracy`. If you have an imbalanced model, accuracy is not a good metric, so you should change to another such as `f1_weighted`.\n",
    "\n",
    "**Note: Permutation tests take a while to do, thus the default is False in the begginning so you can make a first analysis on your dataset. If you then want to use the results of a supervised model, run a permutation test to check if your model is significant.**\n",
    "\n",
    "p-value calculation: (1 + nº of times permutated model has better performance than non-permutated model)/nº of permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1938e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GENERATE = False # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random permutator)\n",
    "\n",
    "    perm_results_RF = metsta.permutation_RF(\n",
    "        treated_data, target, regression,  # data, labels and if it's a regression\n",
    "        iter_num=500, # Nº of permutations to do in your test - around 500 should be enough\n",
    "        n_trees=200, # Number of trees in the model\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        metric=('accuracy')) # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab861ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(treated_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_RF\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='RF Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('Nº of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('Random Forest Permutation Test', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_RF_PermutationTest.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8bd088",
   "metadata": {},
   "source": [
    "### ROC curves (Receiver Operating Characteristic)\n",
    "\n",
    "This basically gives you an area under curve that the closer it is to 1, the better our model. We also iterate this n_iter times so we have a softer curve and to give as a better indication of the actual area under curve (AUC). This plots the true positive rate against the false positive rate.\n",
    "\n",
    "**Only possible for when your datasets have 2 classes. Choose the class which is considered the 'positive' class.**\n",
    "\n",
    "Credit to initial function to the BinSim paper.\n",
    "\n",
    "If you do not have 2 classes, skip ahead this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_RF = metsta.RF_ROC_cv(treated_data, target, regres=regression, # Data, target and if it's a regression\n",
    "                                        pos_label=pos_label, # Positive label\n",
    "                                        n_trees=200, # Number of trees of RF\n",
    "                                        n_iter=15, # Number of iterations to repeat \n",
    "                                        cv=None, n_fold=3) # Method of CV (None is stratified cv) and the number of folds\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        # Plot the ROC curves \n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_RF\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set_title('Random Forest ROC Curve', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_RF_ROCcurve.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b1bebd",
   "metadata": {},
   "source": [
    "## Step 5.2: PLS-DA (Partial Least Squares - Discriminant Analysis) <a class=\"anchor\" id=\"step-5_2\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "First, an optimization of the number of components of PLS-DA and a **set of functions for PLS-DA - `optim_PLSDA_n_components` for example - to see in metanalysis_standard.**\n",
    "\n",
    "The VIPs scores are calculated using the function `_calculate_vips` in multianalysis.py that comes from the link https://www.researchgate.net/post/How-can-I-compute-Variable-Importance-in-Projection-VIP-in-Partial-Least-Squares-PLS as provided by Keiron Teilo O'Shea in that link.\n",
    "\n",
    "**Note: `max_comp` (maximum number of components) cannot be higher than the number of samples that will train a model minus 1. For example, if you have 15 samples and a 3-fold cross-validation each fold will have 5 samples. A training set will be comprised of two of those folds thus it will have 10 samples, thus `max_comp` (and `n_comp` later on) cannot be higher than 9. Another example if you have 22 samples and 5 folds, the folds will have 4/4/4/5/5 samples each. A training set will have four of these folds and the minimum sum of them is 4+4+4+5-1=16, thus max_comp cannot be higher than 16.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d797af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "# above is to supress PLS warnings\n",
    "\n",
    "# Set the random seed\n",
    "np.random.seed()\n",
    "\n",
    "max_comp = 9 # Max. number of components to search (the higher the more time it takes)\n",
    "\n",
    "# Store Results\n",
    "PLS_optim = metsta.optim_PLSDA_n_components(treated_data, target, regression, # Data, target and if it's a regression\n",
    "                                    encode2as1vector=True,\n",
    "                                    max_comp=max_comp, # Max. number of components to search\n",
    "                                    kf=None, n_fold=3, # Cross validation to use (none is stratified CV) and nº of folds\n",
    "                                    scale=False) # Set scale to True only if you did not do scaling in pre-treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98e38a",
   "metadata": {},
   "source": [
    "In the figure below, $R^{2}$ and $Q^{2}$ are shown. You want to choose the number of components **where $Q^{2}$ specifically** stops increasing, so, in this case, 4 components will be chosen. \n",
    "\n",
    "- $Q^{2}$ - PLS score by its mean squared error based on the test samples, thus it is ideal to test if the model will overfit. This will increase until a certain number of components that should be chosen. Then it usually stabilizes but from a certain point it might start to decrease which would mean the model is overfitting. For example, in this case, we choose 4 components based on this score, but you could choose 5 or 6 and it would not affect the model a lot.\n",
    "- $R^{2}$ - PLS score by its mean squared error based on the training samples used to make the model (it will be higher than $Q^{2}$ but it should not be used to choose the number of components. This metric always increases with the more components used which means it will overfit the model eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f54a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cols = sns.color_palette('tab10', 10) # Set the colors for the lines\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True) # Set the figure size\n",
    "        c = 0\n",
    "        for i, values in PLS_optim.items():\n",
    "            if i =='CVscores':\n",
    "                name = 'Q$^2$'\n",
    "            else:\n",
    "                name = 'R$^2$'\n",
    "            \n",
    "            ax.plot(range(1, len(values) + 1), values, label=name, color = scores_cols[c])\n",
    "            c = c+1\n",
    "        \n",
    "        ax.set(xlabel='Number of Components', # Set the label for the x axis\n",
    "                ylabel='PLS Score') # Set the label for the Y axis\n",
    "        ax.legend(loc='lower right', fontsize=15) # Set the legend\n",
    "        ax.set_ylim([0, 1.02]) # Set limits for y axis\n",
    "        ax.set_xticks(range(0, len(values), 2)) # Set ticks that appear in the bottom of x axis\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0abac6f",
   "metadata": {},
   "source": [
    "### PLS-DA model fitting\n",
    "\n",
    "**See details of `PLSDA_model_cv` function (model fitting AND evaluation) in metanalysis_standard.py as adapted from the one in the BinSim paper.**\n",
    "\n",
    "The VIPs scores are calculated using the function `_calculate_vips` in multianalysis.py that comes from the link https://www.researchgate.net/post/How-can-I-compute-Variable-Importance-in-Projection-VIP-in-Partial-Least-Squares-PLS as provided by Keiron Teilo O'Shea in that link.\n",
    "\n",
    "The function `_generate_y_PLSDA` is also present in multianalysis.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "# above is to supress PLS warnings\n",
    "\n",
    "n_comp = 9 # Number of components of PLS-DA model - very important\n",
    "\n",
    "PLSDA_results = metsta.PLSDA_model_CV(treated_data, target, regression, # Data, target and if it's a regression\n",
    "                       n_comp=n_comp, # Number of components of PLS-DA model - very important\n",
    "                       kf = None, n_fold=3, # Cross validation to use (none is stratified CV) and nº of folds\n",
    "                       iter_num=10, # Number of iterations of cross-validation to do\n",
    "                       encode2as1vector=True,\n",
    "                       scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                       feat_type='VIP') # Feature Importance Metric to use, default is VIP scores (see function for others)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab48cd5",
   "metadata": {},
   "source": [
    "**Performance analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bfd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in PLSDA_results.items():\n",
    "    if k != 'Q2' and k != 'imp_feat':\n",
    "        pls_results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(pls_results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b29742",
   "metadata": {},
   "source": [
    "**Important Feature analysis**\n",
    "\n",
    "See the most important features for class discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26929e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_plsda = meta_data.copy()\n",
    "imp_feats_plsda.insert(0,'Bucket label', imp_feats_plsda.index)\n",
    "imp_feats_plsda.insert(1,'VIP Score', '')\n",
    "for n in range(len(PLSDA_results['imp_feat'])):\n",
    "    imp_feats_plsda['VIP Score'][PLSDA_results['imp_feat'][n][0]] = PLSDA_results['imp_feat'][n][1]\n",
    "imp_feats_plsda = imp_feats_plsda.sort_values(by='VIP Score', ascending=False)\n",
    "imp_feats_plsda.index = range(1, len(imp_feats_plsda)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_plsda.head(20) # Select number of features to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd9810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = False\n",
    "\n",
    "# Saving the most important features by their fraction 'frac_feat_impor'.\n",
    "# If None, saving the most important features based on a threshold 'VIP_Score_threshold'.\n",
    "# If also None, save the full dataset of all features\n",
    "frac_feat_impor = 0.02 # Fraction of features to save, If None the variable in the next line is used.\n",
    "VIP_Score_threshold = 1 # Only used if variable above is None, threshold of score to consider a feature important.\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    if frac_feat_impor:\n",
    "        max_idx = int(frac_feat_impor*len(imp_feats_plsda))\n",
    "        filt_imp_feats_plsda = imp_feats_plsda.iloc[:max_idx]\n",
    "        filt_imp_feats_plsda.to_excel(f'PLSDA_ImpFeat_{frac_feat_impor*100}%.xlsx')\n",
    "    elif VIP_Score_threshold:\n",
    "        filt_imp_feats_plsda = imp_feats_plsda[imp_feats_plsda['VIP Score'] > VIP_Score_threshold]\n",
    "        filt_imp_feats_plsda.to_excel(f'PLSDA_ImpFeat_VIPgreater{VIP_Score_threshold}.xlsx')\n",
    "    else:\n",
    "        imp_feats_plsda.to_excel(f'PLSDA_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf968d4c",
   "metadata": {},
   "source": [
    "### Sample Projection on the two most important Components/Latent Variables of PLS models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ce809",
   "metadata": {},
   "source": [
    "**To do** See if it's worth doing this in a regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not regression:\n",
    "    n_components = 4 # Nº of componentes\n",
    "\n",
    "    model, scores = fit_PLSDA_model(treated_data, target,\n",
    "                                    n_comp=n_components, scale=False, # Only true if scaling was not done earlier\n",
    "                                    encode2as1vector=True,\n",
    "                                    lv_prefix='LV ', label_name='Label')\n",
    "\n",
    "    lcolors = label_colours\n",
    "\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "            fig, ax = plt.subplots(1,1, figsize=(6,6)) # Set up fig size\n",
    "            plot_PCA(scores, lcolors, title=\"PLS Projection\", ax=ax,\n",
    "                    components=(1,2)) # Select components to see\n",
    "            plt.title('PLS Projection', fontsize=20) # Title\n",
    "            plt.legend(loc='upper right', ncol=1, fontsize=15)  # Legend           \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            #fig.savefig('Name_PLSplot.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41da830",
   "metadata": {},
   "source": [
    "### PLS-DA Permutation Test\n",
    "\n",
    "This is a test to observe if the model performance is significant, that is, if it is better than a random model. If it is, then the remaining results from the important features give meaningful information, if not, then you cannot use the important features results since they essentially mean nothing.\n",
    "\n",
    "The permutation test will permutate the class labels of your samples, that is, all classes will be randomized while maintaining the same number of samples per class and classes. Then, for each permutation it will see the model performance. \n",
    "\n",
    "The default metric for model performance is `accuracy`. If you have an imbalanced model, accuracy is not a good metric, so you should change to another such as `f1_weighted`. Metric can only be: `accuracy`, `f1_weighted`, `recall_weighted` or `precision_weighted`.\n",
    "\n",
    "**Note: Permutation tests take a while to do, thus the default is False in the begginning so you can make a first analysis on your dataset. If you then want to use the results of a supervised model, run a permutation test to check if your model is significant.**\n",
    "\n",
    "p-value calculation: (1 + nº of times permutated model has better performance than non-permutated model)/nº of permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64768d87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GENERATE = True # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random state in the function below)\n",
    "\n",
    "    perm_results_PLSDA = metsta.permutation_PLSDA(\n",
    "        treated_data, target,  # data and labels\n",
    "        n_comp=4, # Number of components\n",
    "        iter_num=500, # Nº of permutations to do in your test - around 500 should be enough\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        encode2as1vector=True, scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "        metric='accuracy') # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(treated_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_PLSDA\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='PLS-DA Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('Nº of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('PLS-DA Permutation Test', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_PLSDA_PermutationTest.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4e7d5",
   "metadata": {},
   "source": [
    "### ROC curves (Receiver Operating Characteristic)\n",
    "\n",
    "This basically gives you an area under curve that the closer it is to 1, the better our model. We also iterate this n_iter times so we have a softer curve and to give as a better indication of the actual area under curve (AUC). This plots the true positive rate against the false positive rate.\n",
    "\n",
    "**Only possible for when your datasets have 2 classes. Choose the class which is considered the 'positive' class.**\n",
    "\n",
    "Credit to initial function to the BinSim paper.\n",
    "\n",
    "If you do not have 2 classes, skip ahead this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ccc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_PLSDA = metsta.PLSDA_ROC_cv(treated_data, target, # Data and target\n",
    "                                pos_label=pos_label, # Positive label\n",
    "                                n_comp=4, # Number of components\n",
    "                                scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                                n_iter=15, # Number of iterations to repeat \n",
    "                                cv=None, n_fold=3) # method of cross-validation (None is stratified cv) and the number of folds\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643df7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves \n",
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_PLSDA\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set(xlabel='False positive rate', ylabel='True positive rate')\n",
    "                ax.set_title('PLS-DA ROC Curve', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_PLSDA_ROCcurve.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ffb871",
   "metadata": {},
   "source": [
    "## Step 5.3: XGBoost (eXtreme Gradient Boosting) <a class=\"anchor\" id=\"step-5_3\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b7c08",
   "metadata": {},
   "source": [
    "Thhis block of code automatically selects an XGBoost objective function for your specific use case. If you want to use a different function, you may select it here, or in the 'objective' input to the functions.\n",
    "\n",
    "Some reading on objective functions:\n",
    "- https://xgboost.readthedocs.io/en/stable/parameter.html (Ctrl-F objective)\n",
    "- https://machinelearningmastery.com/xgboost-loss-functions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_analysis = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if regression:\n",
    "    objective = \"reg:squarederror\"\n",
    "else:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        print('Warning: XGBoost is currently unreliable for binary classification tasks. If you still want to use it delete xgb_analysis = False')\n",
    "        objective = \"binary:logistic\"\n",
    "        xgb_analysis = False\n",
    "    else:\n",
    "        objective = \"multi:softprob\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b9ab5",
   "metadata": {},
   "source": [
    "We first start with a brief optimization of the parameters for XGBoost training. Default is to focus only on the number of estimators (trees) and their maximum depth. However, there are other parameters that can be tweaked, simply by adding new terms to the xgb_optim_params dictionary. Please be aware that each new parameter will explonentially increase the running time of the function, and that for regression problem even just a single-parameter tuning can take very long.\n",
    "\n",
    "To 'fix' an hyperparater that you do not want to tune at a non-default value, simply add it to the XGB_optim function as **kwargs\n",
    "\n",
    "Resources on XGBoost Hyperparameters and their tuning:\n",
    "- https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "- https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning\n",
    "- https://freedium.cfd/https://towardsdatascience.com/xgboost-fine-tune-and-optimize-your-model-23d996fab663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea63679",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    # Select a random seed (number between the ()) if you don't want the results to change every time you run the code\n",
    "    np.random.seed()\n",
    "\n",
    "    xgb_max_n_estimators = 300\n",
    "\n",
    "    xgb_optim_params = {'n_estimators': range(10,xgb_max_n_estimators+1,5)} \n",
    "\n",
    "    #xgb_optim_params = {'min_child_weight': numeric_range(0,1,0.1), 'subsample': numeric_range(0,1,0.1), 'gamma': numeric_range(0,1,0.1), \n",
    "    #                    'max_depth': range(0,10,1)}\n",
    "\n",
    "    #XGB_Optim = metsta.optimise_xgb_parameters(treated_data, target, xgb_optim_params, regression, objective)\n",
    "    XGB_Optim = metsta.optimise_xgb_parameters(treated_data, target, xgb_optim_params, regression, objective, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2411847",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    param_to_plot = 'n_estimators'\n",
    "\n",
    "    # Plotting the results and adjusting parameters of the plot\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "            f, ax = plt.subplots(1, 1, figsize=(6,6), constrained_layout=True) # Set Figure Size\n",
    "\n",
    "            c_map = sns.color_palette('tab10', 10)\n",
    "\n",
    "            ax.plot(XGB_Optim.cv_results_['param_n_estimators'], [s*100 for s in XGB_Optim.cv_results_['mean_test_score']])\n",
    "            ax.set_ylabel('XGBoost CV Mean Accuracy (%)', fontsize=15) # Set the y_label and size\n",
    "            ax.set_xlabel(param_to_plot, fontsize=15)\n",
    "            ax.set_title('XGBoost', fontsize=18) # Set the title and size\n",
    "            ax.set_ylim([30,101]) # Set the limits on the y axis\n",
    "\n",
    "            #f.suptitle('Optimization of the number of trees')\n",
    "            ax.legend(fontsize=15) # Set the legend and size\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4929adf0",
   "metadata": {},
   "source": [
    "### Fitting the XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e63978",
   "metadata": {},
   "source": [
    "You may add more parameters to the function as **kwargs\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96819b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    n_estimators = 200\n",
    "\n",
    "    XGB_results = metsta.XGB_model(treated_data, target, # Data and labels\n",
    "                    regres=regression, obj=objective, # Regression or classification, and objective function\n",
    "                    return_cv=True, iter_num=5, # If you want cross validation results and number of iterations for it\n",
    "                    n_estimators=n_estimators, # Number of trees in the model\n",
    "                    cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "                    #metrics = ('neg_mean_squared_error', 'r2'), subsample=0.7)\n",
    "                    metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted')) #, gamma=0, min_child_weight=0.9, subsample=0.4), # Choose the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e774c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    results_summary = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "    for k,v in XGB_results.items():\n",
    "        if k != 'model' and k != 'imp_feat':\n",
    "            results_summary.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "    print(results_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05427ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    imp_feats_xgb = meta_data.copy()\n",
    "    imp_feats_xgb.insert(0,'Bucket label', imp_feats_xgb.index)\n",
    "    imp_feats_xgb.insert(1,'Feature Importance', '')\n",
    "    for n in range(len(XGB_results['imp_feat'])):\n",
    "        imp_feats_xgb['Feature Importance'].iloc[XGB_results['imp_feat'][n][0]] = XGB_results['imp_feat'][n][1]\n",
    "    imp_feats_xgb = imp_feats_xgb.sort_values(by='Feature Importance', ascending=False)\n",
    "    imp_feats_xgb.index = range(1, len(imp_feats_xgb)+1)\n",
    "else:\n",
    "    imp_feats_xgb = 'XGBoost analysis was not performed'\n",
    "imp_feats_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908fe4d",
   "metadata": {},
   "source": [
    "### XGBoost Permutation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE=False\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random permutator)\n",
    "\n",
    "    perm_results_XGB = metsta.permutation_XGB(\n",
    "        treated_data, target,  # data and labels\n",
    "        regres=regression, obj=objective, # regression vs classification and objective function \n",
    "        iter_num=100, # Nº of permutations to do in your test - around 500 should be enough\n",
    "        n_estimators=200, # Number of trees in the model\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        metric=('accuracy')) # Choose a metric to use to evaluate if the model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ca523",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(treated_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_XGB\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='XGBoost Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('Nº of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('XGBoost Permutation Test', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_XGB_PermutationTest.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef2e39b",
   "metadata": {},
   "source": [
    "### ROC Curves (Reveicer Operating Characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a249ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = False\n",
    "if GENERATE:\n",
    "    if regression:\n",
    "        print('You are working on a regression problem. Thus, ROC curves are not made.')\n",
    "    else:\n",
    "        if len(pd.unique(target)) == 2:\n",
    "            # Set a random seed for reproducibility\n",
    "            np.random.seed()\n",
    "            \n",
    "            # Set up positive label\n",
    "            pos_label = pd.unique(target)[0]\n",
    "\n",
    "            resROC_RF = metsta.XGB_ROC_cv(treated_data, target, # Data and target\n",
    "                                        pos_label=pos_label, obj=objective, # Positive label and objective\n",
    "                                        n_estimators=200, # Number of trees of RF\n",
    "                                        n_iter=15, # Number of iterations to repeat \n",
    "                                        cv=None, n_fold=3) # Method of CV (None is stratified cv) and the number of folds\n",
    "        else:\n",
    "            print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b39a3",
   "metadata": {},
   "source": [
    "# Step 6: Univariate Analysis and Fold-Change Analysis <a class=\"anchor\" id=\"step-6\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "In this section, both Univariate Analysis and Fold-Change analysis are performed outputting a DataFrame ordered by lowest _p_-value to highest and with the columns of Fold change and logarithmic Fold Change.\n",
    "\n",
    "The Fold change is calculated in a dataset with missing values imputed and normalized after. **This means that with our very high number of missing values in FT-ICR-MS data, it affects the calculation of the fold change a lot. Thus, take this fold changes values with a grain (or multiple grains that are actually more like rocks than grains) of salt.**\n",
    "\n",
    "Choose between the parametric **t-test** and non-parametric **Mann-Whitney test** for 2-class univariate analysis, and between **ANOVA** and **Kruskal-Wallis test** for multiclass analysis.\n",
    "\n",
    "The functions for 2-class analysis all come from the multianalysis.py file (from the BinSim paper) but most of them were slightly altered and put in the metanalysis_standard.py file to be able to specify a control and test class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8738524",
   "metadata": {},
   "source": [
    "## Step 6.1: 2-class Univariate Statistical Analysis <a class=\"anchor\" id=\"step-6_1\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603b9b5",
   "metadata": {},
   "source": [
    "Choose **control** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be06d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_class = classes[0]\n",
    "control_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a801f3",
   "metadata": {},
   "source": [
    "Choose **_p_-value significancy** threshold. Usual values are: 0.05, 0.01, 0.001. If you **do not want** to filter the data based on a _p_-value threshold, make alpha=**None**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc6264",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = None\n",
    "alpha = 0.05 # If you use Mann-Whitney with low number of samples you might have to change this alpha\n",
    "# It can be the correct appraoch with a lot of missing values though\n",
    "# With Mann-Whitney test, there will be a set of discrete p-values as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ed380",
   "metadata": {},
   "source": [
    "Choose **Fold change** threshold value.\n",
    "\n",
    "If you want to only select from the significant features, those that have a fold change greater than X, change **abs_log2FC_threshold**. This value is in **log 2 of the absolute fold change**. For example, if you want to only consider features that have a fold change greater than 2-fold (2 or 0.5), then the abs_log2FC_threshold should be 1. If you want it to be greater than 3-fold, the threshold should be np.log2(3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3211c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_log2FC_threshold = 1 # As a default, I will choose not to perform this step\n",
    "# Example for 2-fold threshold: abs_log2FC_threshold = 1 or np.log2(2)\n",
    "# Example for 3-fold threshold: abs_log2FC_threshold = np.log2(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9692c69f",
   "metadata": {},
   "source": [
    "**Perform Univariate Analysis**\n",
    "\n",
    "If you have more than 2 classes, the pre-treatment must be equal to the pre-treatment made in step 2, thus we use the same variables as before (hence the importance of choosing the pre-treatment by the variables and not in the function itself in step 2.\n",
    "\n",
    "If the filtering chosen is `total_samples` and the filt_kw is greater than 1, that is, a minimum number of samples to appear in the dataset, that number is transformed to represent the same percentage of samples in the smaller subsection of data of only the control and test classes. E.g. if the minimum nº of samples a feature must appear in a 15-sample dataset is 4, then by performing univariate analysis between 2 classes on a 6-sample subset, the minimum nº of samples allowed is (4/15) * 6 = 1.6 rounded up, that is, it has to appear in at least 2 of that 6 sample-subset (and 4 samples of the original 15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "useMW = False # Consider variance between groups as equal\n",
    "equal_var = True # Use Mann-Whitney Test or standard T-test\n",
    "\n",
    "if len(classes) == 2:\n",
    "    test_class = [cl for cl in classes if cl != control_class][0]\n",
    "    # Perform Univariate Analysis\n",
    "    univariate_results = metsta.compute_FC_pvalues_2groups(normalized=univariate_data, # Used for Fold-Change Computation\n",
    "                                  processed=treated_data, # Used for p-value computation\n",
    "                                  labels=target, # Labels of the samples\n",
    "                                  control_class=control_class, # Control class\n",
    "                                  test_class=test_class, # Non-control class\n",
    "                                  equal_var=useMW, # Consider variance between groups as equal\n",
    "                                  useMW=useMW) # Use Mann-Whitney Test or standard T-test\n",
    "    \n",
    "    # Select only Features considered significative\n",
    "    if alpha:\n",
    "        filt_uni_results = univariate_results[univariate_results['FDR adjusted p-value'] < alpha].copy()\n",
    "    else:\n",
    "        filt_uni_results = univariate_results.copy()\n",
    "    \n",
    "    # Select features that have an absolute fold change (in log2) greater than abs_log2FC_threshold\n",
    "    if abs_log2FC_threshold:\n",
    "        # Calculate absolute Log2 Fold-Change\n",
    "        filt_uni_results['abs_log2FC'] = abs(filt_uni_results['log2FC'])\n",
    "        # Select\n",
    "        filt_uni_results = filt_uni_results[filt_uni_results['abs_log2FC'] > abs_log2FC_threshold]\n",
    "        filt_uni_results = filt_uni_results.drop(columns='abs_log2FC')\n",
    "        \n",
    "    print('Univariate Analysis Done.')\n",
    "\n",
    "# More than 2 classes\n",
    "else:\n",
    "    test_classes = [cl for cl in classes if cl != control_class]\n",
    "    univariate_results = {}\n",
    "    filt_uni_results = {}\n",
    "    univariate_df = {}\n",
    "\n",
    "    for test_class in test_classes: # For each non-control class\n",
    "        # Select only the samples of the control and current test class\n",
    "        selection = [i in [control_class, test_class] for i in target]\n",
    "        target_temp = list(np.array(target)[selection])\n",
    "        \n",
    "        file_temp = annotated_data[sample_cols].copy()\n",
    "        file_temp = file_temp.loc[:, selection]\n",
    "\n",
    "        # Perform the same filtering and pre-treatments steps but using only the control and test class samples\n",
    "\n",
    "        # Transform the filt_kw if needed to match the filtering done above (as explained in the markdown cell above)\n",
    "        if filt_method == 'total_samples':\n",
    "            # Adapting the filt_kw to a smaller subset of samples\n",
    "            # Use % of the original filtering used to calculate the equivalent number of samples in subset and round UP\n",
    "            # Possible Issue - since we already used the filtered dataset (because it has annotations and de-duplications),\n",
    "            # the data filtering with 'total_samples' is not perfect - a feature must pass this data filtering but also\n",
    "            # the original data filtering made\n",
    "            if filt_kw > 1:\n",
    "                f_kw = math.ceil(filt_kw/len(sample_cols)*sum(selection))\n",
    "            else:\n",
    "                f_kw = filt_kw\n",
    "        else:\n",
    "            f_kw = filt_kw\n",
    "\n",
    "        t_data,_,filt_data,_,_ = metsta.filtering_pretreatment(\n",
    "                          file_temp, list(np.array(target)[selection]), file_temp.columns,\n",
    "           #### Everything here must be the same as in step 2 except the f_kw as explained above\n",
    "                          filt_method, f_kw, extra_filt, mvi, mvi_kw, norm, norm_kw, tf, tf_kw, scaling, scaling_kw)\n",
    "\n",
    "        univariate_df[test_class] = [t_data, target_temp]\n",
    "        \n",
    "        # Perform Univariate Analysis on this newly acquired data\n",
    "        univariate_results[test_class] = metsta.compute_FC_pvalues_2groups(\n",
    "                                  normalized=filt_data, # Used for Fold-Change Computation\n",
    "                                  processed=t_data, # Used for p-value computation\n",
    "                                  labels=target_temp, # Labels of the samples\n",
    "                                  control_class=control_class, # Control class\n",
    "                                  test_class=test_class, # Non-control class\n",
    "                                  equal_var=equal_var, # Consider variance between groups as equal\n",
    "                                  useMW=useMW) # Use Mann-Whitney Test if True or standard T-test if False\n",
    "        \n",
    "        # Select only Features considered significative\n",
    "        if alpha:\n",
    "            filt_uni_results[test_class] = univariate_results[test_class][univariate_results[test_class][\n",
    "                'FDR adjusted p-value'] < alpha].copy()\n",
    "        else:\n",
    "            filt_uni_results[test_class] = univariate_results[test_class].copy()\n",
    "        \n",
    "        # Select features that have an absolute fold change (in log2) greater than abs_log2FC_threshold\n",
    "        if abs_log2FC_threshold:\n",
    "            # Calculate absolute Log2 Fold-Change\n",
    "            filt_uni_results[test_class]['abs_log2FC'] = abs(filt_uni_results[test_class]['log2FC'])\n",
    "            # Select\n",
    "            filt_uni_results[test_class] = filt_uni_results[test_class][\n",
    "                filt_uni_results[test_class]['abs_log2FC'] > abs_log2FC_threshold]\n",
    "            filt_uni_results[test_class] = filt_uni_results[test_class].drop(columns='abs_log2FC')\n",
    "\n",
    "        print(f'Univariate Analysis {test_class} vs. {control_class} Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3508a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the meta data of each feature\n",
    "temp_meta_data = meta_data[[i for i in meta_data.columns if i not in ['Neutral Mass', 'Probable m/z', 'm/z']]]\n",
    "\n",
    "# If you have 2 classes\n",
    "if len(classes) == 2:\n",
    "    filt_uni_results = pd.concat((filt_uni_results, temp_meta_data.loc[filt_uni_results.index]), axis=1)\n",
    "\n",
    "# More than 2 classes\n",
    "else:\n",
    "    for test_class in filt_uni_results.keys():\n",
    "        filt_uni_results[test_class] = pd.concat((filt_uni_results[test_class], temp_meta_data.loc[\n",
    "            filt_uni_results[test_class].index]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe907cc",
   "metadata": {},
   "source": [
    "Get the results in an Excel if you want to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52683020",
   "metadata": {},
   "outputs": [],
   "source": [
    "Univariate_Excel = False # Change to True to have the Excels\n",
    "if Univariate_Excel:\n",
    "    if len(classes) == 2:\n",
    "        filt_uni_results.to_excel(f'UniAnalysis_pvalue{alpha}_log2FC{abs_log2FC_threshold}.xlsx')\n",
    "    else:\n",
    "        for i in filt_uni_results:\n",
    "            filt_uni_results[i].to_excel(f'UniAnalysis_class{i}_pvalue{alpha}_log2FC{abs_log2FC_threshold}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a6f37",
   "metadata": {},
   "source": [
    "### Example Results (for more than 2 classes, a random class was chosen)\n",
    "\n",
    "**This is usually just useful for 2 classes, we will leave here the visualizations for more than 2 classes as an example.** Using more than 2 classes in analysis would require the use of all possibile combinations instead of just looking at the 2 of them. For example, seeing the features which are significant in at least one of the cases.\n",
    "\n",
    "The first four columns have the results of the univariate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec1229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(classes) == 2:\n",
    "    example_results = filt_uni_results\n",
    "    example_heatmap = treated_data\n",
    "    example_target = target\n",
    "    example_nonfilt_res = univariate_results\n",
    "else:\n",
    "    example_results = filt_uni_results[test_classes[0]]\n",
    "    example_heatmap = univariate_df[test_classes[0]][0]\n",
    "    example_target = univariate_df[test_classes[0]][1]\n",
    "    example_nonfilt_res = univariate_results[test_classes[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d8439f",
   "metadata": {},
   "source": [
    "See results ordered by **_p_-value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a81f21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example_results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6071b",
   "metadata": {},
   "source": [
    "See biggest fold changes from the test class in relation to the control class (1st cell) and vice-versa (2nd cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4438292",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_results.sort_values(by='log2FC', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ac777",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_results.sort_values(by='log2FC', ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb042e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_nonfilt_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e1b67b",
   "metadata": {},
   "source": [
    "**Heatmap** of the example shown considering only the significant features from the univariate analysis (can be better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb58514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple heatmap comparing intensities in treated_data\n",
    "f, ax = plt.subplots(1,1, figsize=(5, 7), constrained_layout=True) # Set figure size\n",
    "sns.heatmap(example_heatmap.T.loc[example_results.index],\n",
    "            cmap='RdBu_r', # Select colormap to use\n",
    "            vmin=-3, vmax=3) # Adjust minimum and maximum values in the Heatmap colorbar\n",
    "ax.tick_params(left=False)\n",
    "ax.set_yticklabels('')\n",
    "ax.set_ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4adef4",
   "metadata": {},
   "source": [
    "**Volcano Plot** of the example shown considering only the significant features from the univariate analysis\n",
    "\n",
    "**Much more useful when there are only 2 classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize=(7, 6), constrained_layout=True) # Set figure size\n",
    "\n",
    "alpha # Threshold used for p-values\n",
    "abs_log2FC_threshold # Threshold used for fold changes\n",
    "\n",
    "non_sig_feat_color = 'silver'\n",
    "reduced_sig_color = 'deepskyblue'\n",
    "increased_sig_color = 'lightcoral'\n",
    "\n",
    "non_sig_feats = []\n",
    "increased_sig_feats = []\n",
    "reduced_sig_feats = []\n",
    "for i in example_nonfilt_res.index:\n",
    "    if i not in example_results.index:\n",
    "        non_sig_feats.append(i)\n",
    "    elif example_nonfilt_res.loc[i, 'log2FC'] < 0:\n",
    "        reduced_sig_feats.append(i)\n",
    "    else:\n",
    "        increased_sig_feats.append(i)\n",
    "\n",
    "ax.scatter(example_nonfilt_res.loc[non_sig_feats, 'log2FC'], \n",
    "           -np.log10(example_nonfilt_res.loc[non_sig_feats, 'FDR adjusted p-value']),\n",
    "           c=non_sig_feat_color, alpha=0.7, label='Non-Significant')\n",
    "ax.scatter(example_nonfilt_res.loc[reduced_sig_feats, 'log2FC'], \n",
    "            -np.log10(example_nonfilt_res.loc[reduced_sig_feats, 'FDR adjusted p-value']),\n",
    "            c=reduced_sig_color, alpha=0.7, label='Downregulated')\n",
    "ax.scatter(example_nonfilt_res.loc[increased_sig_feats, 'log2FC'], \n",
    "            -np.log10(example_nonfilt_res.loc[increased_sig_feats, 'FDR adjusted p-value']),\n",
    "            c=increased_sig_color, alpha=0.7, label='Upregulated')\n",
    "\n",
    "ax.axhline(-np.log10(alpha), color='black', linestyle='--')\n",
    "if abs_log2FC_threshold != None:\n",
    "    ax.axvline(abs_log2FC_threshold, color='black', linestyle='--')\n",
    "    ax.axvline(-abs_log2FC_threshold, color='black', linestyle='--')\n",
    "\n",
    "ax.set_ylabel('- log$_1$$_0$(Adjusted (Benjamini-Hochberg) p-value)', fontsize=14)\n",
    "t_class = pd.unique(example_target)[pd.unique(example_target) != control_class][0]\n",
    "ax.set_xlabel(f'log$_2$(Fold Change))', fontsize=14)\n",
    "ax.set_title(f'Volcano Plot - {t_class}/{control_class}', fontsize=18)\n",
    "ax.legend(fontsize=12, bbox_to_anchor=(1,1))\n",
    "#f.savefig('Name_UniAnalysis_VolcanoPlot.jpg', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0062bdff",
   "metadata": {},
   "source": [
    "## Step 6.2: Multi-class Univariate Statistical Analysis <a class=\"anchor\" id=\"step-6_2\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33202049",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(classes) == 2:\n",
    "    multiclass_univariate_results = 'Your data has only two classes'\n",
    "else:\n",
    "    multiclass_univariate_results = metsta.compute_pvalues_multiple_groups(treated_data, groups, \n",
    "                                            useKW=False) # Choose if you want to use Kruskal-Wallis test (non-parametric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_univariate_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291bfdbf",
   "metadata": {},
   "source": [
    "# Step 7: Make Van Krevelen Diagrams, Kendrick Mass Defect Plots and Chemical Composition series for your samples <a class=\"anchor\" id=\"step-7\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f98065",
   "metadata": {},
   "outputs": [],
   "source": [
    "SmartFormula = True # Is there a SmartFormula Annotation? Change to False if not\n",
    "#  If you have Smart Fromula, do you also want to use formulas from the annotations performed here?\n",
    "include_other_formula_cols = False\n",
    "\n",
    "if SmartFormula:\n",
    "    formula_subset = [\"Formula\",]\n",
    "    if include_other_formula_cols:\n",
    "        formula_subset.extend(meta_cols_formulas)\n",
    "else:\n",
    "    formula_subset = meta_cols_formulas\n",
    "print(formula_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34646d",
   "metadata": {},
   "source": [
    "**Van Krevelen Plots**\n",
    "\n",
    "See the options for **color_dots_by** in the beginning of the next cell.\n",
    "\n",
    "This section plots a Van Krevelen Plot for each of the classes under analysis. This is made by only considering metabolites\n",
    "(features) that appear at least in one sample of said class. Only metabolites with assigned formulas are considered and the columns with formulas considered were chosen in the previous cell (**Note: you HAVE to select at least one annotation**). **If multiple formulas can be assigned to a metabolite whether within the same database annotation or different, they are both considered and plotted in the Van Krevelen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e57b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Van Krevelen Diagrams\n",
    "color_dots_by = 'Rank' # Other option 'logInt'\n",
    "# Van Krevelen points (peaks) are coloured based on their average intensity\n",
    "# Rank - colored by the rank of their average intensity compared to others\n",
    "# logInt - colored by the logarithm of their averaged intensity compared to others\n",
    "\n",
    "midpoint = 0.75 # Marks the point where the color passes from the low intensity color to the high intensity\n",
    "# 0.75 means 75% of points will be coloured with the low intensity color (stronger the lesser the intensity)\n",
    "\n",
    "for g in group_dfs:\n",
    "    # Calculating H/C and O/C ratios\n",
    "    forms = group_dfs[g].dropna(subset=formula_subset, how='all')\n",
    "    elems = create_element_counts(forms, formula_subset=formula_subset)\n",
    "\n",
    "    f, ax = plt.subplots(1,1, figsize=(6,6)) # Setting axes for the figs\n",
    "    \n",
    "    # Make the vector that will govern the colour of the plots\n",
    "    if color_dots_by == 'Rank':\n",
    "        c = univariate_data[elems.index].loc[np.array(target) == g].mean().rank(ascending=False)\n",
    "        slope_midpoint = midpoint*len(univariate_data[elems.index].columns)\n",
    "    elif color_dots_by == 'logInt':\n",
    "        c = np.log(univariate_data[elems.index].loc[np.array(target) == g].mean())\n",
    "        slope_midpoint = c.sort_values().iloc[int(midpoint*len(elems.index))]\n",
    "    \n",
    "    if formula_subset == 'Formula':\n",
    "        y = elems['H/C'].loc[c.index]\n",
    "        x = elems['O/C'].loc[c.index]\n",
    "    else:\n",
    "        y = elems['H/C']\n",
    "        x = elems['O/C']\n",
    "    \n",
    "    plt.scatter(x, y, s=3, c=c, cmap='bwr', norm=TwoSlopeNorm(slope_midpoint))\n",
    "    plt.xlabel('O/C', fontsize=20)\n",
    "    plt.ylabel('H/C', fontsize=20)\n",
    "    ax.margins(y=.1)\n",
    "    ax.set_ylim([0.15,2.01])\n",
    "    ax.set_xlim([-0.1,2.01])\n",
    "    plt.colorbar()\n",
    "    # Hide the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_title(g, fontsize=20)\n",
    "    \n",
    "    \n",
    "    #f, ax = plt.subplots(1,1, figsize=(8,8)) # Setting axes for the figs\n",
    "    #plt.title(g, fontsize=20)\n",
    "    \n",
    "    #f.savefig('Name_VKplot_' + g + '.jpg', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc862a",
   "metadata": {},
   "source": [
    "**Kendrick Mass Defect Plots**\n",
    "\n",
    "See the options for **rounding** in the beginning of the next cell.\n",
    "\n",
    "On cases where you have **multiple formulas belonging to different chemical composition series assigned to the same _m/z_ peak**, points are marked as Ambiguous (Amb.) which has the same colour as 'No Formula Assigned' (No Form.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a51d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rounding = 'up' # 'up' or 'nearest' - how Kendrick Nominal Mass is obtained by rounding up or to the nearest integer\n",
    "\n",
    "# Put these two lines instead of the current if you want to try to put them all in the same fig, you have to adjust things\n",
    "# for that to take into especially how many panels you need (right now it is (2,3) that is 2*3=6) and the figsize.\n",
    "#f, axs = plt.subplots(2,3, figsize=(16,12))\n",
    "#for g, ax in zip(group_dfs, axs.ravel()):\n",
    "for g in group_dfs:\n",
    "    f, ax = plt.subplots(1,1, figsize=(7,6), constrained_layout=True) # Setting axes for the figs\n",
    "    \n",
    "    # Getting the classes each formula has\n",
    "    forms = group_dfs[g].dropna(subset=formula_subset, how='all')\n",
    "    elems = create_element_counts(forms, formula_subset=formula_subset)\n",
    "    \n",
    "    l = []\n",
    "    n_form_per_peak = pd.Series(elems.index).value_counts()\n",
    "\n",
    "    for i in group_dfs[g].index: # For each peak to consider\n",
    "        # If it has formula assigned by the formula columns selected\n",
    "        if i in elems.index:\n",
    "            # See if it has more than one formula\n",
    "            if n_form_per_peak.loc[i] > 1:\n",
    "                # If it has, see if they belong to the same class series or not\n",
    "                cl = set(elems.loc[i, 'Series'])\n",
    "                if len(cl) == 1: # If yes assign it\n",
    "                    l.append(elems.loc[i, 'Series'].iloc[0])\n",
    "                else: # If not, say it is Ambiguous\n",
    "                    l.append('No Form. / Amb.')\n",
    "\n",
    "            # In case it only has one formula\n",
    "            else:\n",
    "                l.append(elems['Series'].loc[i])\n",
    "\n",
    "        # If it has not formula assigned by the formula columns selected\n",
    "        else:\n",
    "            l.append('No Form. / Amb.')\n",
    "    classes_series = ['CHO', 'CHOS', 'CHON', 'CHNS', 'CHONS', 'CHOP', 'CHONP','CHONSP', 'other', 'No Form. / Amb.']\n",
    "    dict_col = {lbl: c for lbl, c in zip(classes_series, sns.color_palette('tab10', len(classes_series)))}\n",
    "    list_col = np.array([dict_col[i] for i in l])\n",
    "    \n",
    "    # Calculate points for the scatter plot, choose if rounding shouls happen to the nearest        \n",
    "    nominal, fraction = metsta.calc_kmd(group_dfs[g], rounding=rounding)\n",
    "\n",
    "    # Scatter plot\n",
    "    for cl in classes_series:\n",
    "        n = np.array(nominal)[np.array(l) == cl]\n",
    "        f = np.array(fraction)[np.array(l) == cl]\n",
    "        lc = list_col[np.array(l) == cl]\n",
    "        scatter = ax.scatter(n,f, s=6, c=lc, label=cl)\n",
    "\n",
    "    ax.set_xlabel('Kendrick Nominal Mass', fontsize=20) # Set X axis label\n",
    "    ax.set_ylabel('Kendrick Mass Defect', fontsize=20) # Set Y axis label\n",
    "    ax.set_xlim([0,1250])\n",
    "    ax.legend(fontsize=12, loc='upper left', bbox_to_anchor=(1,1)) # Set legend\n",
    "    ax.set_title(g, fontsize= 20) # Set title\n",
    "    \n",
    "    #f.savefig('Name_KMDplot_' + g + '.jpg', dpi=400) # Save the figure\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b5b53",
   "metadata": {},
   "source": [
    "**Chemical Composition Series**\n",
    "\n",
    "**If multiple formulas can be assigned to the same _m/z_ peak** whether within the same formula annotation made or between different annotations, **each one will be counted in this plot**. That is, if a peak in a class has 3 possible candidate formulas, 2 belonging to the 'CHO' series and another to the 'CHOP' series; then 2 formulas will be added to the 'CHO' series and 1 to the 'CHOP' series. Thus, we are considering that the 3 elementary formulas are represented by that peak (probably an overestimation). In all cases, it is rare to find multiple candidate formulas for the same m/z peak, especially with extreme-resolution data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5848b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_composition_series(group_dfs,\n",
    "                            series_order=('CHO', 'CHOS', 'CHON', 'CHNS', 'CHONS', 'CHOP', 'CHONP','CHONSP', 'other'),\n",
    "                            formula_col=formula_subset,\n",
    "                            label_colours=label_colours,\n",
    "                            ax=None):\n",
    "    # Chemical compostition series\n",
    "    bar_number = len(group_dfs)\n",
    "    curr_num = - len(group_dfs)/2 + 0.5\n",
    "    width = 0.8/bar_number - 0.05\n",
    "    series = pd.DataFrame()\n",
    "    \n",
    "    for g in group_dfs:\n",
    "        forms = group_dfs[g].dropna(subset=formula_subset, how='all')\n",
    "        elems = create_element_counts(forms, formula_subset=formula_subset)\n",
    "        #print('This is the chemical composition Series for', g, ':\\n')\n",
    "    \n",
    "        counts = elems['Series'].value_counts().reindex(series_order)\n",
    "        series[g] = counts # Store the counts\n",
    "        x = np.arange(len(counts))  # the label locations\n",
    "        ax.barh(x+(width+0.05)*curr_num, counts, width, label=g, color=label_colours[g])\n",
    "        curr_num = curr_num + 1\n",
    "    ax.set_yticks(x)\n",
    "    ax.set_yticklabels(counts.index)\n",
    "    ax.set_xlabel('Nº of Formulas', fontsize = 15)\n",
    "    ax.set_title('Chemical Composition Series', fontsize=15)\n",
    "    plt.grid(zorder=0)\n",
    "    plt.legend()\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize=(9,6)) # Setting axes for the figs\n",
    "chem_comp_series = plot_composition_series(group_dfs, ax=ax,label_colours=label_colours,)\n",
    "#f.savefig('Name_CCSeries.jpg', dpi=400) # Save the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45896056",
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_comp_series.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a68f5",
   "metadata": {},
   "source": [
    "#### PCA of chemical composition series per sample with Loading arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the chemical composition series for each samples\n",
    "series = pd.DataFrame()\n",
    "series_order=('CHO', 'CHOS', 'CHON', 'CHNS', 'CHONS', 'CHOP', 'CHONP','CHONSP', 'other')\n",
    "for sample in sample_cols:\n",
    "    forms = processed_data.dropna(subset=sample).dropna(subset=formula_subset, how='all')\n",
    "    elems = create_element_counts(forms, formula_subset=formula_subset)\n",
    "\n",
    "    counts = elems['Series'].value_counts().reindex(series_order)\n",
    "    series[sample] = counts # Store the counts\n",
    "series = series.replace({np.nan:0})\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8870c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA_loading_arrows(series, principaldf, loadings, var_exp,\n",
    "                            n_components, top_features=None, method='top_variance', ax=None):\n",
    "    \"\"\"Draw Loading arrows of top n features.\n",
    "     \n",
    "     Based on idea and taken from St. Ovf. thread (Qiyun Zhu answer).\n",
    "     https://stackoverflow.com/questions/39216897/plot-pca-loadings-and-loading-in-biplot-in-sklearn-like-rs-autoplot.\"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    # Taken from Stack Overflow\n",
    "    if top_features:\n",
    "        # Method 1: Find top arrows that appear the longest (i.e., furthest from the origin) in the visible plot\n",
    "        if method == 'top_longest':\n",
    "            tops = (loadings ** 2).sum(axis=1).argsort()[-top_features:]\n",
    "            loadings_to_plot = loadings[tops]\n",
    "            idxs = np.array(series.index)[tops]\n",
    "\n",
    "        # Method 2: Find top features that drive most variance in the visible PCs:\n",
    "        elif method == 'top_variance':\n",
    "            tops = (np.abs(loadings) * var_exp).sum(axis=1).argsort()[-top_features:]\n",
    "            loadings_to_plot = loadings[tops]\n",
    "            idxs = np.array(series.index)[tops]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Method is not accepted. It should be one of \"top_longest\" or \"top_variance\".')\n",
    "            \n",
    "        # Scale the loadings so they are easier to interpret sicne their absolute values have no grand meaning\n",
    "        loadings_to_plot /= np.sqrt((loadings_to_plot ** 2).sum(axis=0))\n",
    "        loadings_to_plot = loadings_to_plot * np.array(np.abs(principaldf.iloc[:,:n_components]).max(axis=0))\n",
    "\n",
    "        # Empirical formula to determine arrow width (according to St. Ovf. Answer)\n",
    "        width = -0.005 * np.min([np.subtract(*plt.xlim()), np.subtract(*plt.ylim())])\n",
    "            \n",
    "        # Draw arrows\n",
    "        for arrow in range(top_features):\n",
    "            ax.arrow(0,0, loadings_to_plot[arrow,0], loadings_to_plot[arrow,1], alpha=0.7, ec='none', width=width,\n",
    "                     color='grey', length_includes_head=True)\n",
    "            ax.text(loadings_to_plot[arrow,0]*1.04, loadings_to_plot[arrow,1]*1.04, idxs[arrow],\n",
    "                     ha='center', va='center')\n",
    "        return\n",
    "    \n",
    "    # Scale the loadings so they are easier to interpret sicne their absolute values have no grand meaning\n",
    "    loadings_to_plot = loadings * np.array(np.abs(principaldf.iloc[:,:n_components]).max(axis=0))\n",
    "    \n",
    "    # Empirical formula to determine arrow width (according to St. Ovf. Answer) but thinner\n",
    "    width = -0.005 * np.min([np.subtract(*plt.xlim()), np.subtract(*plt.ylim())])\n",
    "    \n",
    "    # Draw arrows\n",
    "    for arrow in range(len(series)):\n",
    "        ax.arrow(0,0, loadings_to_plot[arrow,0], loadings_to_plot[arrow,1], alpha=0.7, ec='none', width=width,\n",
    "                 color='grey', length_includes_head=True)\n",
    "        ax.text(loadings_to_plot[arrow,0]*1.04, loadings_to_plot[arrow,1]*1.04, series.index[arrow],\n",
    "                 ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3226a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating PCA\n",
    "n_components = 2 # Select number of components to calculate\n",
    "principaldf, var, loadings = metsta.compute_df_with_PCs_VE_loadings(transf.pareto_scale(series.T), \n",
    "                                       n_components=n_components, # Select number of components to calculate\n",
    "                                       whiten=True, labels=target, return_var_ratios_and_loadings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(6,6)) # Change the size of the figure\n",
    "# Plot PCA\n",
    "ax.axis('equal')\n",
    "lcolors = label_colours\n",
    "\n",
    "plot_PCA(principaldf, lcolors, \n",
    "         components=(1,2), # Select components to see\n",
    "         title='', # Select title of plot\n",
    "         ax=ax)\n",
    "\n",
    "# Remove ellipses by putting a # before the next line\n",
    "plot_ellipses_PCA(principaldf, \n",
    "                  lcolors, \n",
    "                  components=(1,2), # Select components to see\n",
    "                  ax=ax, \n",
    "                  q=0.95) # Confidence ellipse with 95% (q) confidence\n",
    "\n",
    "# Putting loading arrows\n",
    "plot_PCA_loading_arrows(series, principaldf, loadings, var, n_components, top_features=None, ax=ax)\n",
    "\n",
    "ax.set_xlabel(f'PC 1 ({var[0] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "ax.set_ylabel(f'PC 2 ({var[1] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "\n",
    "plt.legend(fontsize=15, loc='upper left', bbox_to_anchor=(1,1)) # Set the size of labels\n",
    "#plt.grid() # If you want a grid or not\n",
    "plt.show()\n",
    "#f.savefig('Name_CCS_PCAplot.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069fc58",
   "metadata": {},
   "source": [
    "# Step 8: Pathways Assignment of HMDB Annotated Metabolites <a class=\"anchor\" id=\"step-8\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "This section reads a pathways database build based on Ramp (https://academic.oup.com/bioinformatics/article/39/1/btac726/6827287) to use as a base to assign the pathways each compound belongs to.\n",
    "\n",
    "**It only works with HMDB identifiers and HMDB annotated compounds.**\n",
    "\n",
    "The result is a DataFrame where the index is each HMDB identifier in the `Matched_HMDB_IDs` columns of your data and the two columns represent the assigned pathways and corresponding IDs from the different databases RampID uses plus and extra column with the corresponding HMDB metabolite name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8e588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pathway database into a DataFrame\n",
    "with open('RAMP_ID_pathways_improved.pickle', 'rb') as handle:\n",
    "    pathways_db = pickle.load(handle)\n",
    "pathways_db = pathways_db[['HMDB Name', 'Pathway Name', 'Pathway ID']]\n",
    "pathways_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f6a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pathways assignment\n",
    "pathways_assignment_idx = []\n",
    "pathways_assignment_name = []\n",
    "if 'Matched HMDB IDs' in processed_data.columns:\n",
    "    for i in processed_data['Matched HMDB IDs'].dropna().index:\n",
    "        for hmdb_id in range(len(processed_data.loc[i, 'Matched HMDB IDs'])):\n",
    "            if processed_data.loc[i, 'Matched HMDB IDs'][hmdb_id] in pathways_assignment_idx:\n",
    "                continue\n",
    "            else:\n",
    "                pathways_assignment_idx.append(processed_data.loc[i, 'Matched HMDB IDs'][hmdb_id])\n",
    "                pathways_assignment_name.append(processed_data.loc[i, 'Matched HMDB names'][hmdb_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1cd629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pathways assignment dataframe\n",
    "pathways_assignment = pd.DataFrame(index=pathways_assignment_idx, columns=['Pathway Name', 'Pathway ID'])\n",
    "if 'Matched HMDB IDs' in processed_data.columns:\n",
    "    for i in pathways_assignment.index:\n",
    "        if i in pathways_db.index:\n",
    "            pathways_assignment.loc[i] = pathways_db.loc[i]\n",
    "    pathways_assignment['Matched HMDB names'] = pathways_assignment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5598a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See full pathways assignment dataframe\n",
    "pathways_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c40882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See only the HMDB that led to pathway assignments\n",
    "pathways_assignment.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a07d1",
   "metadata": {},
   "source": [
    "Select chosen list of HMDB you want to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141abd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_hmdbs = ['HMDB0000045', 'HMDB0009947', 'HMDB0000001']\n",
    "\n",
    "filtered_chosen_hmdbs = []\n",
    "for i in chosen_hmdbs:\n",
    "    if i not in pathways_assignment.index:\n",
    "        print(f'{i} was not annotated for the currently analysed data and is thus not in the pathway assignment DataFrame.')\n",
    "    else:\n",
    "        filtered_chosen_hmdbs.append(i)\n",
    "\n",
    "pathways_assignment.loc[filtered_chosen_hmdbs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d0e30e",
   "metadata": {},
   "source": [
    "# Step 9: KEGG Colour Mapping <a class=\"anchor\" id=\"step-9\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17511f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_colour = 'red'\n",
    "class_2_colour = 'blue'\n",
    "both_colour = 'purple'\n",
    "\n",
    "print('Present only in',classes[0]+':',class_1_colour)\n",
    "print('Present only in',classes[1]+':',class_2_colour)\n",
    "print('Present in both', class_1_colour, 'and', class_1_colour+':', both_colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cbcb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pd.unique(target)) == 2:\n",
    "\n",
    "    kegg_data = annotated_data.copy()\n",
    "    kegg_data = kegg_data.dropna(subset='Matched HMDB IDs')\n",
    "    kegg_data = kegg_data[sample_cols+['Matched HMDB IDs']]\n",
    "    kegg_data = kegg_data.explode('Matched HMDB IDs', ignore_index=True)\n",
    "    kegg_data['Matched KEGG'] = np.nan\n",
    "    for a in tqdm(kegg_data.index):\n",
    "        kegg_hmdb_id = kegg_data['Matched HMDB IDs'][a]\n",
    "        kegg_data['Matched KEGG'][a] = dbs['HMDB']['DB'].loc[kegg_hmdb_id]['kegg']\n",
    "    kegg_data = kegg_data.dropna(subset='Matched KEGG')\n",
    "    kegg_data['Colour'] = np.nan\n",
    "    for k in kegg_data.index:\n",
    "        k_df = kegg_data.loc[[k]]\n",
    "        if k_df[groups[classes[0]]].isnull().values.all():\n",
    "            kegg_data['Colour'][k] = class_2_colour\n",
    "        elif k_df[groups[classes[1]]].isnull().values.all():\n",
    "            kegg_data['Colour'][k] = class_1_colour\n",
    "        else:\n",
    "            kegg_data['Colour'][k] = both_colour\n",
    "    kegg_data\n",
    "else:\n",
    "    print('Your data has more than two classes. Thus, KEGG colour mapping is not performed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c75937",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_KEGG_COLOURS = True\n",
    "if len(pd.unique(target)) == 2:\n",
    "    kegg_colours = kegg_data[['Matched KEGG', 'Colour']]\n",
    "    kegg_colours = kegg_colours.set_index('Matched KEGG')\n",
    "    if SAVE_KEGG_COLOURS:\n",
    "        kegg_colours_filename = filename.split('.')[0]+'_kegg_colours.csv'\n",
    "        kegg_colours.to_csv(kegg_colours_filename, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bbcc2",
   "metadata": {},
   "source": [
    "# Step 10: BinSim Specific Analysis <a class=\"anchor\" id=\"step-10\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "All analysis done very quickly using BinSim\n",
    "- PCA\n",
    "- HCA\n",
    "- Random Forest\n",
    "- PLS-DA\n",
    "- XGBoost\n",
    "\n",
    "BinSim was performed as described in the BinSim paper as mentioned earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbbaaa3",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e390e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(6,6)) # Change the size of the figure\n",
    "\n",
    "principaldf_BinSim, var_BinSim, loadings_BinSim = metsta.compute_df_with_PCs_VE_loadings(bin_data, \n",
    "                                       n_components=2, # Select number of components to calculate\n",
    "                                       whiten=True, labels=target, return_var_ratios_and_loadings=True)\n",
    "# Plot PCA\n",
    "ax.axis('equal')\n",
    "lcolors = label_colours\n",
    "plot_PCA(principaldf_BinSim, lcolors, \n",
    "         components=(1,2), # Select components to see\n",
    "         title='', # Select title of plot\n",
    "         ax=ax)\n",
    "\n",
    "# Remove ellipses by putting a # before the next line\n",
    "plot_ellipses_PCA(principaldf_BinSim, lcolors, \n",
    "                  components=(1,2), # Select components to see\n",
    "                  ax=ax, \n",
    "                  q=0.95) # Confidence ellipse with 95% (q) confidence\n",
    "\n",
    "ax.set_xlabel(f'PC 1 ({var_BinSim[0] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "ax.set_ylabel(f'PC 2 ({var_BinSim[1] * 100:.1f} %)', size=15) # Set the size of labels\n",
    "\n",
    "plt.legend(fontsize=15) # Set the size of labels\n",
    "plt.grid() # If you want a grid or not\n",
    "plt.show()\n",
    "#f.savefig('Name_BinSim_PCAplot.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46d85f7",
   "metadata": {},
   "source": [
    "HCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing HCA \n",
    "metric = 'euclidean' # Select distance metric\n",
    "method = 'ward' # Select linkage method\n",
    "\n",
    "distances_BinSim = dist.pdist(bin_data, metric=metric)\n",
    "Z_BinSim = hier.linkage(distances_BinSim, method=method)\n",
    "\n",
    "hca_res_BinSim = {'Z': Z_BinSim, 'distances': distances_BinSim}\n",
    "\n",
    "# Plot HCA\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 4), constrained_layout=True) # Set Figure Size\n",
    "    plot_dendogram(hca_res_BinSim['Z'], \n",
    "                   target, ax=ax,\n",
    "                   label_colors=label_colours,\n",
    "                   title='', # Select title\n",
    "                   color_threshold=0) # Select a distance threshold from where different sets of lines are coloured\n",
    "\n",
    "    plt.show()\n",
    "    #f.savefig('Name_BinSim_HCAplot.png', dpi=400) # Save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de88489",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a number for the seed for consistent results\n",
    "np.random.seed()\n",
    "\n",
    "n_trees=200 # Number of trees in the model\n",
    "\n",
    "RF_results_BinSim = metsta.RF_model(bin_data, target, regres=regression, # Data and labels \n",
    "                      return_cv=True, iter_num=5, # If you want cross calidation results and number of iterations for it\n",
    "                      n_trees=n_trees, # Number of trees in the model\n",
    "                      cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the nº of folds\n",
    "        metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted')) # Choose the performance metrics\n",
    "\n",
    "rf_results_summary_BinSim = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in RF_results_BinSim.items():\n",
    "    if k != 'model' and k != 'imp_feat':\n",
    "        rf_results_summary_BinSim.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(rf_results_summary_BinSim)\n",
    "\n",
    "imp_feats_rf_BinSim = meta_data.copy()\n",
    "imp_feats_rf_BinSim.insert(0,'Bucket label', imp_feats_rf_BinSim.index)\n",
    "imp_feats_rf_BinSim.insert(1,'Gini Importance', '')\n",
    "imp_feats_rf_BinSim = imp_feats_rf_BinSim.copy()\n",
    "for n in range(len(RF_results_BinSim['imp_feat'])):\n",
    "    imp_feats_rf_BinSim['Gini Importance'].iloc[RF_results_BinSim['imp_feat'][n][0]] = RF_results_BinSim['imp_feat'][n][1]\n",
    "imp_feats_rf_BinSim = imp_feats_rf_BinSim.sort_values(by='Gini Importance', ascending=False)\n",
    "imp_feats_rf_BinSim.index = range(1, len(imp_feats_rf_BinSim)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats_rf_BinSim.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b181df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = False\n",
    "\n",
    "# Saving the most important features by their fraction 'frac_feat_impor'.\n",
    "# If None, saving the most important features based on a threshold 'VIP_Score_threshold'.\n",
    "# If also None, save the full dataset of all features\n",
    "frac_feat_impor = 0.02 # Fraction of features to save, If None the variable in the next line is used.\n",
    "score_threshold = None # Only used if variable above is None, threshold of score to consider a feature important.\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    if frac_feat_impor:\n",
    "        max_idx = int(frac_feat_impor*len(imp_feats_rf_BinSim))\n",
    "        filt_imp_feats_rf_BinSim = imp_feats_rf_BinSim.iloc[:max_idx]\n",
    "        filt_imp_feats_rf_BinSim.to_excel(f'RF_BinSim_ImpFeat_{frac_feat_impor*100}%.xlsx')\n",
    "    elif score_threshold:\n",
    "        filt_imp_feats_rf_BinSim = imp_feats_rf_BinSim[imp_feats_rf_BinSim['Gini Importance'] > score_threshold]\n",
    "        filt_imp_feats_rf_BinSim.to_excel(f'RF_BinSim_ImpFeat_GiniImpgreater{score_threshold}.xlsx')\n",
    "    else:\n",
    "        imp_feats_rf_BinSim.to_excel(f'RF_BinSim_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbbeff1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GENERATE = False # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random permutator)\n",
    "\n",
    "    perm_results_BinSim_RF = metsta.permutation_RF(\n",
    "        bin_data, target,  # Data and labels \n",
    "        iter_num=500, # Nº of permutations to do in your test - around 500 should be enough\n",
    "        n_trees=200, # Number of trees in the model\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        metric=('accuracy')) # Choose a metric to use to evaluate if the model is significant\n",
    "    \n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(bin_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_BinSim_RF\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='RF Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('Nº of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('Random Forest Permutation Test (BinSim)', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_BinSim_RF_PermutationTest.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf62ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        # Set a random seed for reproducibility\n",
    "        np.random.seed()\n",
    "        \n",
    "        # Set up positive label\n",
    "        pos_label = pd.unique(target)[0]\n",
    "\n",
    "        resROC_BinSim_RF = metsta.RF_ROC_cv(bin_data, target, regression, # Data and target\n",
    "                                    pos_label=pos_label, # Positive label\n",
    "                                    n_trees=200, # Number of trees of RF\n",
    "                                    n_iter=15, # Number of iterations to repeat \n",
    "                                    cv=None, n_fold=3) # method of CV (None is stratified cv) and the number of folds\n",
    "    \n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_BinSim_RF\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set_title('Random Forest ROC Curve (BinSim)', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_BinSim_RF_ROCcurve.jpg', dpi=400) # Save the figure\n",
    "    else:\n",
    "        print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f81904",
   "metadata": {},
   "source": [
    "PLS-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ebcc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Results\n",
    "PLS_optim_BinSim = metsta.optim_PLSDA_n_components(bin_data, target, regression, # Data and target\n",
    "                                    encode2as1vector=True,\n",
    "                                    max_comp=8, # Max. number of components to search (the higher the more time it takes)\n",
    "                                    kf=None, n_fold=3, # Cross validation to use (none is stratified CV) and nº of folds\n",
    "                                    scale=False) # Set scale to True only if you did not do scaling in pre-treatments\n",
    "\n",
    "scores_cols = sns.color_palette('tab10', 10) # Set the colors for the lines\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(4,4), constrained_layout=True) # Set the figure size\n",
    "        c = 0\n",
    "        for i, values in PLS_optim.items():\n",
    "            if i =='CVscores':\n",
    "                name = 'Q$^2$'\n",
    "            else:\n",
    "                name = 'R$^2$'\n",
    "            \n",
    "            ax.plot(range(1, len(values) + 1), values, label=name, color = scores_cols[c])\n",
    "            c = c+1\n",
    "        \n",
    "        ax.set(xlabel='Number of Components', # Set the label for the x axis\n",
    "                ylabel='PLS Score') # Set the label for the Y axis\n",
    "        ax.legend(loc='lower right', fontsize=15) # Set the legend\n",
    "        ax.set_ylim([0, 1.02]) # Set limits for y axis\n",
    "        ax.set_xticks(range(0, len(values), 2)) # Set ticks that appear in the bottom of x axis\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture --no-stdout\n",
    "# above is to supress PLS warnings\n",
    "\n",
    "n_comp = 4 # Number of components of PLS-DA model - very important\n",
    "\n",
    "PLSDA_results_BinSim = metsta.PLSDA_model_CV(bin_data, target, regression, # Data and target\n",
    "                       n_comp=n_comp, # Number of components of PLS-DA model - very important\n",
    "                       kf=None, n_fold=3, # Cross validation to use (none is stratified CV) and nº of folds\n",
    "                       iter_num=10, # Number of iterations of cross-validation to do\n",
    "                       encode2as1vector=True,\n",
    "                       scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                       feat_type='VIP') # Feature Importance Metric to use, default is VIP scores (see function for others)\n",
    "\n",
    "pls_results_summary_BinSim = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "for k,v in PLSDA_results_BinSim.items():\n",
    "    if k != 'Q2' and k != 'imp_feat':\n",
    "        pls_results_summary_BinSim.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "print(pls_results_summary_BinSim)\n",
    "\n",
    "imp_feats_plsda_BinSim = meta_data.copy()\n",
    "imp_feats_plsda_BinSim.insert(0,'Bucket label', imp_feats_plsda_BinSim.index)\n",
    "imp_feats_plsda_BinSim.insert(1,'VIP Score', '')\n",
    "for n in range(len(PLSDA_results_BinSim['imp_feat'])):\n",
    "    imp_feats_plsda_BinSim['VIP Score'][PLSDA_results_BinSim['imp_feat'][n][0]] = PLSDA_results_BinSim['imp_feat'][n][1]\n",
    "imp_feats_plsda_BinSim = imp_feats_plsda_BinSim.sort_values(by='VIP Score', ascending=False)\n",
    "imp_feats_plsda_BinSim.index = range(1, len(imp_feats_plsda_BinSim)+1)\n",
    "\n",
    "imp_feats_plsda_BinSim.head(20) # Select number of features to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Important feature dataset in an excel\n",
    "SAVE_IMP_FEAT = False\n",
    "\n",
    "# Saving the most important features by their fraction 'frac_feat_impor'.\n",
    "# If None, saving the most important features based on a threshold 'VIP_Score_threshold'.\n",
    "# If also None, save the full dataset of all features\n",
    "frac_feat_impor = 0.02 # Fraction of features to save, If None the variable in the next line is used.\n",
    "VIP_Score_threshold = 1 # Only used if variable above is None, threshold of score to consider a feature important.\n",
    "\n",
    "if SAVE_IMP_FEAT:\n",
    "    if frac_feat_impor:\n",
    "        max_idx = int(frac_feat_impor*len(imp_feats_plsda_BinSim))\n",
    "        filt_imp_feats_plsda_BinSim = imp_feats_plsda_BinSim.iloc[:max_idx]\n",
    "        filt_imp_feats_plsda_BinSim.to_excel(f'PLSDA_BinSim_ImpFeat_{frac_feat_impor*100}%.xlsx')\n",
    "    elif VIP_Score_threshold:\n",
    "        filt_imp_feats_plsda_BinSim = imp_feats_plsda_BinSim[imp_feats_plsda_BinSim['VIP Score'] > VIP_Score_threshold]\n",
    "        filt_imp_feats_plsda_BinSim.to_excel(f'PLSDA_BinSim_ImpFeat_VIPgreater{VIP_Score_threshold}.xlsx')\n",
    "    else:\n",
    "        imp_feats_plsda_BinSim.to_excel(f'PLSDA_BinSim_FeatByImportance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e87bd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GENERATE = False # True if you want to do, False if not\n",
    "if GENERATE:\n",
    "    # Set a random seed for reproducibility of cross validation\n",
    "    np.random.seed()\n",
    "    # (Random seed of labels permutations is in the random state in the function below)\n",
    "\n",
    "    perm_results_BinSim_PLSDA = metsta.permutation_PLSDA(\n",
    "        bin_data, target,  # data and labels\n",
    "        n_comp=4, # Number of components\n",
    "        iter_num=500, # Nº of permutations to do in your test - around 500 should be enough\n",
    "        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the number of folds\n",
    "        random_state=None, # Random seed given to make the permutations rng class labels\n",
    "        encode2as1vector=True, scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "        metric='accuracy') # Choose a metric to use to evaluate if the model is significant\n",
    "    \n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "        n_labels = len(treated_data.index)\n",
    "        tab20bcols = sns.color_palette('tab20b', 20)\n",
    "        perm_results = perm_results_BinSim_PLSDA\n",
    "        \n",
    "        # Histogram with performance of permutated values\n",
    "        hist_res = ax.hist(np.array(perm_results[1]), n_labels, range=(0, 1.00001), label='PLS-DA Permutations',\n",
    "                     edgecolor='black', color=tab20bcols[1], alpha = 1)\n",
    "        \n",
    "        # Plot the non-permutated model performance\n",
    "        ylim = [0, hist_res[0].max()*1.2]\n",
    "        ax.plot(2 * [perm_results[0]], ylim, '-', linewidth=3, color='darkred', #alpha = 0.5,\n",
    "                     label='p-value %.5f)' % perm_results[2], solid_capstyle='round')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_xlabel('CV Model Performance', fontsize=14)\n",
    "        ax.set_ylabel('Nº of occurrences', fontsize=14)\n",
    "        if perm_results[0] >= 0.5:\n",
    "            ax.text(perm_results[0]-0.45, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        else:\n",
    "            ax.text(perm_results[0]+0.05, hist_res[0].max()*1.1, 'p-value = %.3f' % perm_results[2], fontsize = 15)\n",
    "        ax.set_title('PLS-DA Permutation Test (BinSim)', size = 15)\n",
    "        #ax.grid()\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        #fig.savefig('Name_PLSDA_PermutationTest.jpg', dpi=400) # Save the Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "if GENERATE:\n",
    "    if len(pd.unique(target)) == 2:\n",
    "        # Set a random seed for reproducibility\n",
    "        np.random.seed()\n",
    "        \n",
    "        # Set up positive label\n",
    "        pos_label = pd.unique(target)[0]\n",
    "\n",
    "        resROC_BinSim_PLSDA = metsta.PLSDA_ROC_cv(treated_data, target, # Data and target\n",
    "                            pos_label=pos_label, # Positive label\n",
    "                            n_comp=4, # Number of components\n",
    "                            scale=False, # Set scale to True only if you did not do scaling in pre-treatments\n",
    "                            n_iter=15, # Number of iterations to repeat \n",
    "                            cv=None, n_fold=3) # Method of cross-validation (None is stratified cv) and the number of folds\n",
    "        \n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(5,5), constrained_layout=True)\n",
    "                res = resROC_BinSim_PLSDA\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                mean_fpr = [0,] + list(mean_fpr)\n",
    "                mean_tpr = [0,] + list(mean_tpr)\n",
    "                ax.plot(mean_fpr, mean_tpr,\n",
    "                       label=f'AUC = {mean_auc:.3f}',\n",
    "                       lw=2, alpha=0.8)\n",
    "                ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "                ax.legend()\n",
    "                ax.set_xlim(None, 1)\n",
    "                ax.set_ylim(0, None)\n",
    "                ax.set(xlabel='False positive rate', ylabel='True positive rate')\n",
    "                ax.set_title('PLS-DA ROC Curve (BinSim)', fontsize=15)\n",
    "\n",
    "                #f.savefig('Name_BinSim_PLSDA_ROCcurve.jpg', dpi=400) # Save the figure\n",
    "    else:\n",
    "        print('Your target has more than 2 classes. Thus, ROC curves are not made.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924e578",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16890226",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    xgb_max_n_estimators_binsim = 300\n",
    "\n",
    "    xgb_optim_params_binsim = {'n_estimators': range(10,xgb_max_n_estimators_binsim+1,5)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966fcb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "    \n",
    "    XGB_Optim_BinSim = metsta.optimise_xgb_parameters(bin_data, target, xgb_optim_params_binsim, regression, objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626033dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    param_to_plot = 'n_estimators'\n",
    "\n",
    "    # Plotting the results and adjusting parameters of the plot\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "            f, ax = plt.subplots(1, 1, figsize=(6,6), constrained_layout=True) # Set Figure Size\n",
    "\n",
    "            c_map = sns.color_palette('tab10', 10)\n",
    "\n",
    "            ax.plot(XGB_Optim_BinSim.cv_results_['param_n_estimators'], [s*100 for s in XGB_Optim_BinSim.cv_results_['mean_test_score']])\n",
    "            ax.set_ylabel('XGBoost CV Mean Accuracy (%)', fontsize=15) # Set the y_label and size\n",
    "            ax.set_xlabel(param_to_plot, fontsize=15)\n",
    "            ax.set_title('XGBoost', fontsize=18) # Set the title and size\n",
    "            ax.set_ylim([30,101]) # Set the limits on the y axis\n",
    "\n",
    "            #f.suptitle('Optimization of the number of trees')\n",
    "            ax.legend(fontsize=15) # Set the legend and size\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c780f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if xgb_analysis:\n",
    "\n",
    "    n_estimators=300 # Number of trees in the model\n",
    "\n",
    "    XGB_results_BinSim = metsta.XGB_model(bin_data, target, # Data and labels\n",
    "                        regres=regression, obj=objective, # If you're doing regression or classificattion and objective function\n",
    "                        return_cv=True, iter_num=5, # If you want cross calidation results and number of iterations for it\n",
    "                        n_estimators=n_estimators, # Number of trees in the model\n",
    "                        cv=None, n_fold=3, # Choose a method of cross-validation (None is stratified cv) and the nº of folds\n",
    "            metrics = ('accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted')) # Choose the performance metrics\n",
    "\n",
    "    XGB_results_summary_BinSim = pd.DataFrame(columns=['Value', 'Standard Deviation'])\n",
    "    for k,v in XGB_results_BinSim.items():\n",
    "        if k != 'model' and k != 'imp_feat':\n",
    "            XGB_results_summary_BinSim.loc[k] = np.mean(v), np.std(v)\n",
    "\n",
    "    print(XGB_results_summary_BinSim)\n",
    "\n",
    "    imp_feats_xgb_BinSim = meta_data.copy()\n",
    "    imp_feats_xgb_BinSim.insert(0,'Bucket label', imp_feats_xgb_BinSim.index)\n",
    "    imp_feats_xgb_BinSim.insert(1,'Feature Importance', '')\n",
    "    imp_feats_xgb_BinSim = imp_feats_xgb_BinSim.copy()\n",
    "    for n in range(len(XGB_results_BinSim['imp_feat'])):\n",
    "        imp_feats_xgb_BinSim['Feature Importance'].iloc[XGB_results_BinSim['imp_feat'][n][0]] = XGB_results_BinSim['imp_feat'][n][1]\n",
    "    imp_feats_xgb_BinSim = imp_feats_xgb_BinSim.sort_values(by='Feature Importance', ascending=False)\n",
    "    imp_feats_xgb_BinSim.index = range(1, len(imp_feats_xgb_BinSim)+1)\n",
    "else:\n",
    "    imp_feats_xgb_BinSim = \"XGBoost Analysis was not performed\"\n",
    "    \n",
    "imp_feats_xgb_BinSim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51cf66e",
   "metadata": {},
   "source": [
    "# Step 11: Find Specific Compounds <a class=\"anchor\" id=\"step-11\"></a>\n",
    "\n",
    "**Back to [Table of Contents](#toc)**\n",
    "\n",
    "This code will allow you to conveniently find specific compounds by their index, name, formula, or neutral mass / Probable _m/z_. The mass finders work even if you don't know the specific mass, as you can search only by the first few digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_type = 'name' #pick 'formula', 'name', 'Neutral Mass'/'Probable m/z', or 'index'\n",
    "find_id = 'Palmitic acid'\n",
    "if id_type == 'index':\n",
    "    finder = processed_data.loc[processed_data.index.str.startswith(find_id)]\n",
    "elif id_type in ['Neutral Mass','Probable m/z']:\n",
    "    finder = processed_data.loc[processed_data[mass_val_col].str.startswith(find_id)]\n",
    "elif id_type == 'formula':\n",
    "    index_list = []\n",
    "    for col in meta_cols_formulas:\n",
    "        temp_df = processed_data[[col]].dropna()\n",
    "        for t in temp_df.index:\n",
    "            if find_id in temp_df[col][t]:\n",
    "                index_list.append(t)\n",
    "    if 'Formula' in processed_data.columns:\n",
    "        temp_df = processed_data['Formula'].dropna()\n",
    "        for t in temp_df.index:\n",
    "            if find_id in temp_df[t]:\n",
    "                index_list.append(t)\n",
    "    finder = processed_data.loc[processed_data.index.isin(index_list)]\n",
    "elif id_type == 'name':\n",
    "    index_list = []\n",
    "    for col in meta_cols_names:\n",
    "        temp_df = processed_data[[col]].dropna()\n",
    "        for t in temp_df.index:\n",
    "            if find_id in temp_df[col][t]:\n",
    "                index_list.append(t)\n",
    "    if 'Name' in processed_data.columns:\n",
    "        temp_df = processed_data['Name'].dropna()\n",
    "        for t in temp_df.index:\n",
    "            if find_id in temp_df[t]:\n",
    "                index_list.append(t)\n",
    "    finder = processed_data.loc[processed_data.index.isin(index_list)]\n",
    "finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to see the intensities distribution (might become difficult to see with a lot of samples)\n",
    "bar_plot_info = finder.replace({np.nan:0})\n",
    "if len(bar_plot_info.index) == 1:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(16,6))\n",
    "    x = np.arange(len(bar_plot_info.columns[-len(sample_cols):]))\n",
    "    for comps in range(len(bar_plot_info.index)):\n",
    "        ax.barh(x, np.array(bar_plot_info.iloc[comps, -len(sample_cols):]), color=sample_colours)\n",
    "        ax.set_ylabel('Normalized Intensity', fontsize=15)\n",
    "        ax.set_title(find_id, fontsize=15)\n",
    "else:\n",
    "    fig, axs = plt.subplots(1,len(bar_plot_info.index), figsize=(16,6))\n",
    "\n",
    "    x = np.arange(len(bar_plot_info.columns[-len(sample_cols):]))\n",
    "    for (comps, ax) in zip(range(len(bar_plot_info.index)), axs.ravel()):\n",
    "        ax.barh(x, np.array(bar_plot_info.iloc[comps, -len(sample_cols):]), color=sample_colours)\n",
    "        ax.set_yticks([])\n",
    "        #ax.tick_params(labelleft=False)\n",
    "        ax.set_ylabel('Normalized Intensity', fontsize=13)\n",
    "        ax.set_title(find_id)\n",
    "    ax = axs[0]\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(bar_plot_info.columns[-len(sample_cols):], fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3580a",
   "metadata": {},
   "source": [
    "Search for the differences between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a8304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average intensities\n",
    "gfinder = finder.copy()\n",
    "for g in groups:\n",
    "    gfinder[g+' Average'] = gfinder[gfinder.columns.intersection(groups[g])].mean(axis=1)\n",
    "    gfinder[g+' std'] = gfinder[gfinder.columns.intersection(groups[g])].std(axis=1)\n",
    "gfinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea592461",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cols = [col for col in gfinder.columns if 'Average' in col]\n",
    "std_cols = [col for col in gfinder.columns if 'std' in col]\n",
    "group_colours = [label_colours[lbl] for lbl in classes]\n",
    "bar_plot_info = gfinder.replace({np.nan:0})\n",
    "if len(bar_plot_info.index) == 1:\n",
    "    fig, ax = plt.subplots(1,1, figsize=(10,7))\n",
    "    x = np.arange(len(avg_cols))\n",
    "    for comps in bar_plot_info.index:\n",
    "        ax.bar(x, np.array(bar_plot_info.loc[comps, avg_cols]), color=group_colours, yerr=np.array(bar_plot_info.loc[comps, std_cols]), capsize=12)\n",
    "        ax.set_ylabel('Normalized Intensity', fontsize=15)\n",
    "        ax.set_title(find_id, fontsize=15)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(groups, fontsize=12)\n",
    "else:\n",
    "    fig, axs = plt.subplots(1,len(bar_plot_info.index), figsize=(16,6))\n",
    "\n",
    "    x = np.arange(len(avg_cols))\n",
    "    for (comps, ax) in zip(bar_plot_info.index, axs.ravel()):\n",
    "        ax.bar(x, np.array(bar_plot_info.loc[comps, avg_cols]), color=group_colours, yerr=np.array(bar_plot_info.loc[comps, std_cols]), capsize=12)\n",
    "        ax.set_yticks([])\n",
    "        #ax.tick_params(labelleft=False)\n",
    "        ax.set_ylabel('Normalized Intensity', fontsize=13)\n",
    "        ax.set_title(find_id)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(groups)\n",
    "    ax = axs[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(finder.index) == 1:\n",
    "    its_list = []\n",
    "    for g in groups:\n",
    "        its = finder[finder.columns.intersection(groups[g])].T.reset_index(drop= True)\n",
    "        its_list.append(its)\n",
    "    its_df = pd.concat(its_list, axis=1)\n",
    "    its_df = its_df.set_axis(groups, axis=1)\n",
    "    fig, ax = plt.subplots(1,1, figsize=(12,7))\n",
    "    box1= ax.boxplot(its_df, labels=its_df.columns, patch_artist=True, medianprops=dict(color='black'))\n",
    "    for patch, color, lbl in zip(box1['boxes'], colours, its_df.columns):\n",
    "        patch.set_facecolor(color)\n",
    "    ax.tick_params(axis=\"x\", labelsize=25)\n",
    "    ax.tick_params(axis=\"y\", labelsize=20)\n",
    "    ax.set_title(find_id, fontsize=25)\n",
    "    plt.show()\n",
    "else:\n",
    "    fig, axs = plt.subplots(1,len(finder.index), figsize=(16,6))\n",
    "    for (comps, ax) in zip(finder.index, axs.ravel()):\n",
    "        comps_df = finder.loc[[comps]]\n",
    "        its_list = []\n",
    "        for g in groups:\n",
    "            its = comps_df[comps_df.columns.intersection(groups[g])].T.reset_index(drop= True)\n",
    "            its_list.append(its)\n",
    "        its_df = pd.concat(its_list, axis=1)\n",
    "        its_df = its_df.set_axis(groups, axis=1)\n",
    "        box1= ax.boxplot(its_df, labels=its_df.columns, patch_artist=True, medianprops=dict(color='black'))\n",
    "        for patch, color, lbl in zip(box1['boxes'], colours, its_df.columns):\n",
    "            patch.set_facecolor(color)\n",
    "        ax.set_title(find_id, fontsize=15)\n",
    "    ax = axs[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f921c",
   "metadata": {},
   "source": [
    "### Notebook made by:\n",
    "\n",
    "- FT-ICR-MS-Lisboa Laboratory Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939cca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
